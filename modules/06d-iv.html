<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>6D Instrumental Variables | ProTools ER1</title>
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Crimson+Pro:ital,wght@0,400;0,600;0,700;1,400&family=Fira+Code:wght@400;500&family=Source+Sans+Pro:ital,wght@0,400;0,600;0,700;1,400&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="../css/style.css">
  <style>
    .protected-content { -webkit-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; }
    .protected-content pre, .protected-content code, .protected-content .code-block, .protected-content .code-tabs { -webkit-user-select: text; -moz-user-select: text; -ms-user-select: text; user-select: text; }
    .code-tooltip { position: relative; cursor: help; border-bottom: 1px dotted #888; text-decoration: none; }
    .tooltip-popup { position: fixed; background: #1f2937; color: white; padding: 0.5rem 0.75rem; border-radius: 6px; font-size: 0.75rem; white-space: normal; max-width: 300px; opacity: 0; pointer-events: none; transition: opacity 0.15s ease-in-out; z-index: 10000; }
    .tooltip-popup.visible { opacity: 1; }
  </style>
</head>
<body>
    <div id="password-overlay" class="password-overlay">
    <div class="password-modal">
      <h2>ProTools ER1</h2>
      <p>Programming Tools for Empirical Research</p>

      <div class="course-description">
        <h3>Course Modules</h3>
        <ul class="module-list">
          <li><strong>Module 0:</strong> Languages & Platforms ‚Äî Python, Stata, R setup; IDEs (RStudio, VS Code, Jupyter)</li>
          <li><strong>Module 1:</strong> Getting Started ‚Äî Installation, basic syntax, packages</li>
          <li><strong>Module 2:</strong> Data Harnessing ‚Äî File import, APIs, web scraping</li>
          <li><strong>Module 3:</strong> Data Exploration ‚Äî Inspection, summary statistics, visualization</li>
          <li><strong>Module 4:</strong> Data Cleaning ‚Äî Data quality, transformation, validation</li>
          <li><strong>Module 5:</strong> Data Analysis ‚Äî Statistical analysis, simulation, experimental design</li>
          <li><strong>Module 6:</strong> Causal Inference ‚Äî Matching, DiD, RDD, IV, Synthetic Control</li>
          <li><strong>Module 7:</strong> Estimation Methods ‚Äî Standard errors, panel data, MLE/GMM</li>
          <li><strong>Module 8:</strong> Replicability ‚Äî Project organization, documentation, replication packages</li>
          <li><strong>Module 9:</strong> Git & GitHub ‚Äî Version control, collaboration, branching</li>
          <li><strong>Module 10:</strong> History of NLP ‚Äî From ELIZA to Transformers</li>
          <li><strong>Module 11:</strong> Machine Learning ‚Äî Prediction, regularization, neural networks</li>
          <li><strong>Module 12:</strong> Large Language Models ‚Äî How LLMs work, prompting, APIs</li>
        </ul>
      </div>

      <div class="access-note">
        This course is currently open to <strong>students at Sciences Po</strong>. If you are not a Sciences Po student but would like access, please <a href="mailto:giulia.caprini@sciencespo.fr">email me</a> to request an invite token.
      </div>

      <div class="password-form">
        <input type="password" id="password-input" placeholder="Enter password" autocomplete="off">
        <button id="password-submit">Access Course</button>
        <p id="password-error" style="color: #e53e3e; font-size: 0.85rem; margin-top: 1rem; display: none;">Incorrect password. Please try again.</p>
      </div>
    </div>
  </div>

  <div class="page-wrapper protected-content">
    <aside class="sidebar">
      <a href="../index.html" class="sidebar-logo">ProTools ER1</a>
      <span class="sidebar-subtitle">Programming Tools for Empirical Research</span>
      <nav>
        <ul>
          <li><a href="../index.html"><span class="welcome-icon">üè†</span> Welcome</a></li>
          <li class="has-subnav">
            <a href="00-languages-platforms.html"><span class="module-number">0</span> Languages & Platforms</a>
            <ul class="sub-nav">
              <li><a href="00a-rstudio-guide.html">RStudio Guide</a></li>
              <li><a href="00b-stata-guide.html">Stata Guide</a></li>
              <li><a href="00c-vscode-guide.html">VS Code Guide</a></li>
              <li><a href="00d-notebooks-guide.html">Notebooks Guide</a></li>
            </ul>
          </li>
          <li><a href="01-getting-started.html"><span class="module-number">1</span> Getting Started</a></li>
          <li class="has-subnav">
            <a href="02-data-harnessing.html"><span class="module-number">2</span> Data Harnessing</a>
            <ul class="sub-nav">
              <li><a href="02a-file-import.html">File Import</a></li>
              <li><a href="02b-apis.html">APIs</a></li>
              <li><a href="02c-web-scraping.html">Web Scraping</a></li>
            </ul>
          </li>
          <li><a href="03-data-exploration.html"><span class="module-number">3</span> Data Exploration</a></li>
          <li><a href="04-data-cleaning.html"><span class="module-number">4</span> Data Cleaning</a></li>
          <li class="has-subnav">
            <a href="05-data-analysis.html"><span class="module-number">5</span> Data Analysis</a>
            <ul class="sub-nav">
              <li><a href="05a-data-simulation.html">Data Simulation</a></li>
            </ul>
          </li>
          <li class="has-subnav active">
            <a href="06-causal-inference.html"><span class="module-number">6</span> Causal Inference</a>
            <ul class="sub-nav">
              <li><a href="06a-matching.html">Matching</a></li>
              <li><a href="06b-did.html">Difference-in-Differences</a></li>
              <li><a href="06c-rdd.html">Regression Discontinuity</a></li>
              <li class="active"><a href="06d-iv.html">Instrumental Variables</a></li>
              <li><a href="06e-synthetic-control.html">Synthetic Control</a></li>
              <li><a href="05b-experiments.html">Experiments</a></li>
            </ul>
          </li>
          <li><a href="07-estimation.html"><span class="module-number">7</span> Estimation Methods</a></li>
          <li><a href="08-replicability.html"><span class="module-number">8</span> Replicability</a></li>
          <li><a href="09-github.html"><span class="module-number">9</span> Git & GitHub</a></li>
          <li class="has-subnav">
            <a href="10-nlp-history.html"><span class="module-number">10</span> History of NLP</a>
            <ul class="sub-nav">
              <li><a href="10a-text-analysis-today.html">Text Analysis Today</a></li>
            </ul>
          </li>
          <li class="has-subnav">
            <a href="11-machine-learning.html"><span class="module-number">11</span> Machine Learning</a>
            <ul class="sub-nav">
              <li><a href="11a-regularization.html">Regularization</a></li>
              <li><a href="11b-trees.html">Tree-Based Methods</a></li>
              <li><a href="11c-neural-networks.html">Neural Networks</a></li>
              <li><a href="11d-causal-ml.html">Causal ML</a></li>
              <li><a href="11e-model-evaluation.html">Model Evaluation</a></li>
            </ul>
          </li>          <li><a href="12-llms.html"><span class="module-number">12</span> Large Language Models</a></li>
          <li><a href="../resources.html">Resources</a></li>
          <li><a href="contact.html">Contact & Feedback</a></li>
        </ul>
      </nav>
    </aside>

    <main class="main-content">
      <div class="content">
        <nav class="breadcrumb" style="margin-bottom: 1rem; font-size: 0.9rem; color: #666;">
          <a href="06-causal-inference.html">6 Causal Inference</a> &raquo; Instrumental Variables
        </nav>

        <div class="module-header">
          <h1>6D &nbsp;Instrumental Variables</h1>
          <div class="module-meta">
            <span>~2.5 hours</span>
            <span>2SLS, Weak IV, Bartik</span>
          </div>
        </div>

        <div class="toc">
          <h3>Table of Contents</h3>
          <ul>
            <li><a href="#2sls">Two-Stage Least Squares</a></li>
            <li><a href="#diagnostics">IV Diagnostics</a></li>
            <li><a href="#weak">Weak Instruments</a></li>
            <li><a href="#bartik">Bartik/Shift-Share Instruments</a></li>
            <li><a href="#multiple">Multiple Instruments</a></li>
            <li><a href="#wald">Wald Estimator</a></li>
            <li><a href="#control-function">Control Function Approach</a></li>
          </ul>
        </div>

        <!-- ‚ïê‚ïê‚ïê Code Grammar Primer ‚ïê‚ïê‚ïê -->
        <section class="grammar-primer-section">
          <h2 id="code-grammar">Code Grammar</h2>
          <p>Practice the syntax patterns used in this module. In <strong>Build</strong> mode, read the descriptions and figure out the code. In <strong>Read</strong> mode, look at the code and identify what each piece does. Click cards to check your answers.</p>
          <div class="grammar-primer">
            <script type="application/json">
            {
              "exercises": [
                {
                  "instruction": "Estimate a 2SLS instrumental variable regression",
                  "pattern": "model = IV2SLS.from_formula('y ~ controls + [endogenous ~ instruments]', data)",
                  "structureNote": "2SLS uses an <strong>instrument</strong> Z that affects the endogenous variable D but not the outcome Y directly. The formula separates exogenous controls from the endogenous variable and its instruments. The <code>[endogenous ~ instruments]</code> syntax in Python or <code>(endogenous = instruments)</code> in Stata specifies this relationship.",
                  "languages": {
                    "python": [
                      {"code": "model", "role": "Variable", "tip": "Stores the IV model object.", "color": "pink"},
                      {"code": " = ", "role": "Assignment", "tip": "Stores the model.", "color": "peach"},
                      {"code": "IV2SLS.from_formula", "role": "Constructor", "tip": "From linearmodels.iv. Creates a 2SLS model from a formula string.", "color": "blue"},
                      {"code": "(", "role": "Open Paren", "tip": "Begins arguments.", "color": "overlay"},
                      {"code": "'wage ~ 1 + experience + [education ~ distance_to_college]'", "role": "Formula", "tip": "wage = outcome, experience = exogenous control, education = endogenous var, distance_to_college = instrument. [endog ~ instruments] inside brackets.", "color": "green"},
                      {"code": ", data=df", "role": "Data", "tip": "The DataFrame.", "color": "sky"},
                      {"code": ")", "role": "Close Paren", "tip": "Ends model specification.", "color": "overlay"},
                      {"code": "\n", "role": "Newline", "tip": "Next line.", "color": "text"},
                      {"code": "results = model.fit(cov_type='robust')", "role": "Fit", "tip": "Estimates the model with robust standard errors.", "color": "teal"}
                    ],
                    "stata": [
                      {"code": "ivregress 2sls", "role": "Command", "tip": "Stata's IV estimation command. '2sls' specifies the estimator.", "color": "mauve"},
                      {"code": " wage experience", "role": "Outcome & Controls", "tip": "Dependent variable followed by exogenous controls.", "color": "sky"},
                      {"code": " (education = distance_to_college)", "role": "Endogenous Spec", "tip": "Parentheses: endogenous var = instruments. This is the key IV syntax.", "color": "green"},
                      {"code": ", ", "role": "Comma", "tip": "Before options.", "color": "text"},
                      {"code": "robust", "role": "Option", "tip": "Heteroskedasticity-robust standard errors.", "color": "yellow"}
                    ],
                    "r": [
                      {"code": "iv_model", "role": "Variable", "tip": "Stores the IV model.", "color": "pink"},
                      {"code": " <- ", "role": "Assignment", "tip": "R's assignment.", "color": "peach"},
                      {"code": "ivreg", "role": "Function", "tip": "From the AER package. Estimates IV/2SLS models.", "color": "blue"},
                      {"code": "(wage ~ education + experience", "role": "Structural Eq", "tip": "The structural equation: outcome ~ endogenous + controls.", "color": "green"},
                      {"code": " | ", "role": "Pipe Separator", "tip": "Separates the structural equation from the instrument list.", "color": "overlay"},
                      {"code": "distance_to_college + experience", "role": "Instruments", "tip": "All exogenous variables: instruments + controls. Experience appears on both sides because it's exogenous.", "color": "teal"},
                      {"code": ", data = df)", "role": "Data", "tip": "The data frame.", "color": "sky"}
                    ]
                  }
                },
                {
                  "instruction": "Run the first stage regression manually (regress endogenous on instruments)",
                  "pattern": "first_stage = OLS(endogenous, instruments_and_controls).fit()",
                  "structureNote": "The <strong>first stage</strong> predicts the endogenous variable using the instrument. A strong first stage (F > 10) is necessary for 2SLS to work. This step isolates the exogenous variation in education that comes from the instrument (e.g., distance to college).",
                  "languages": {
                    "python": [
                      {"code": "first_stage", "role": "Variable", "tip": "Stores the first-stage regression results.", "color": "pink"},
                      {"code": " = ", "role": "Assignment", "tip": "Stores the result.", "color": "peach"},
                      {"code": "sm.OLS", "role": "OLS Constructor", "tip": "From statsmodels. Standard OLS regression.", "color": "blue"},
                      {"code": "(df['education']", "role": "Dependent Var", "tip": "The endogenous variable. In the first stage, this is the outcome.", "color": "sky"},
                      {"code": ", sm.add_constant(df[['distance_to_college', 'experience']])", "role": "Regressors", "tip": "Instruments + controls + constant. add_constant() adds the intercept column.", "color": "green"},
                      {"code": ").fit()", "role": "Fit", "tip": "Estimates the OLS model. Check first_stage.fvalue for the F-statistic.", "color": "teal"}
                    ],
                    "stata": [
                      {"code": "ivregress 2sls", "role": "Command", "tip": "Stata can show the first stage automatically.", "color": "mauve"},
                      {"code": " wage experience (education = distance_to_college)", "role": "Specification", "tip": "Standard IV specification.", "color": "sky"},
                      {"code": ", ", "role": "Comma", "tip": "Before options.", "color": "text"},
                      {"code": "first", "role": "Option", "tip": "The 'first' option displays the first-stage regression alongside the 2SLS results.", "color": "yellow"},
                      {"code": " robust", "role": "Option", "tip": "Robust standard errors.", "color": "yellow"}
                    ],
                    "r": [
                      {"code": "summary(iv_model", "role": "Summary", "tip": "The summary function for ivreg objects.", "color": "blue"},
                      {"code": ", vcov = vcovHC", "role": "Robust SEs", "tip": "Heteroskedasticity-consistent variance-covariance matrix.", "color": "lavender"},
                      {"code": ", diagnostics = TRUE", "role": "Diagnostics", "tip": "Requests diagnostic tests including the first-stage F-statistic, Wu-Hausman, and Sargan tests.", "color": "lavender"},
                      {"code": ")", "role": "Close Paren", "tip": "Ends the call.", "color": "overlay"}
                    ]
                  }
                },
                {
                  "instruction": "Check the first-stage F-statistic for weak instruments",
                  "pattern": "print(first_stage.fvalue)",
                  "structureNote": "The <strong>first-stage F-statistic</strong> tests whether the instrument actually predicts the endogenous variable. The Stock-Yogo rule of thumb: F > 10 suggests the instrument is strong enough. With weak instruments, 2SLS is biased toward OLS and confidence intervals have poor coverage.",
                  "languages": {
                    "python": [
                      {"code": "print", "role": "Function", "tip": "Displays the F-statistic.", "color": "blue"},
                      {"code": "(", "role": "Open Paren", "tip": "Begins argument.", "color": "overlay"},
                      {"code": "f\"First-stage F: {first_stage.fvalue:.2f}\"", "role": "F-string", "tip": "Formatted string. first_stage.fvalue is the F-statistic from the first-stage OLS. :.2f shows 2 decimal places.", "color": "green"},
                      {"code": ")", "role": "Close Paren", "tip": "Ends print.", "color": "overlay"}
                    ],
                    "stata": [
                      {"code": "estat firststage", "role": "Post-estimation", "tip": "After ivregress, this command displays first-stage diagnostics including the F-statistic.", "color": "mauve"}
                    ],
                    "r": [
                      {"code": "summary(iv_model, diagnostics = TRUE)", "role": "Diagnostics", "tip": "The diagnostics=TRUE option in ivreg's summary reports weak instrument tests and the first-stage F.", "color": "blue"}
                    ]
                  }
                },
                {
                  "instruction": "Run the Sargan-Hansen overidentification test (with multiple instruments)",
                  "pattern": "results.sargan or estat overid",
                  "structureNote": "When you have <strong>more instruments than endogenous variables</strong>, the Sargan-Hansen test checks whether all instruments are valid. Rejecting the null means at least one instrument is correlated with the error term (i.e., invalid). This test only works with 2+ instruments for 1 endogenous variable.",
                  "languages": {
                    "python": [
                      {"code": "print", "role": "Function", "tip": "Displays the test result.", "color": "blue"},
                      {"code": "(", "role": "Open Paren", "tip": "Begins argument.", "color": "overlay"},
                      {"code": "\"Sargan test:\"", "role": "Label", "tip": "Descriptive label.", "color": "green"},
                      {"code": ", ", "role": "Separator", "tip": "Print can take multiple arguments.", "color": "text"},
                      {"code": "results.sargan", "role": "Test Result", "tip": "The Sargan-Hansen J-statistic and p-value. Available after fitting IV2SLS with multiple instruments. Null: all instruments are valid.", "color": "teal"},
                      {"code": ")", "role": "Close Paren", "tip": "Ends print.", "color": "overlay"}
                    ],
                    "stata": [
                      {"code": "estat overid", "role": "Post-estimation", "tip": "After ivregress, tests the overidentifying restrictions. Reports Sargan (homoskedastic) or Hansen J (robust) statistic.", "color": "mauve"}
                    ],
                    "r": [
                      {"code": "summary(iv_model, diagnostics = TRUE)", "role": "Diagnostics", "tip": "The Sargan test is included in the diagnostic output. Look for 'Sargan' in the output table.", "color": "blue"}
                    ]
                  }
                },
                {
                  "instruction": "Estimate IV using fixest with the feols formula syntax",
                  "pattern": "feols(outcome ~ controls | endogenous ~ instrument, data)",
                  "structureNote": "The <strong>fixest</strong> package in R provides a clean formula syntax for IV: after the pipe <code>|</code>, specify the endogenous variable and its instrument separated by <code>~</code>. This is often faster than AER's ivreg and integrates with fixest's fixed effects and clustering capabilities.",
                  "languages": {
                    "python": [
                      {"code": "model", "role": "Variable", "tip": "The IV model.", "color": "pink"},
                      {"code": " = ", "role": "Assignment", "tip": "Stores model.", "color": "peach"},
                      {"code": "IV2SLS.from_formula", "role": "Constructor", "tip": "linearmodels uses bracket syntax: [endogenous ~ instruments] in the formula.", "color": "blue"},
                      {"code": "(", "role": "Open Paren", "tip": "Begins arguments.", "color": "overlay"},
                      {"code": "'wage ~ 1 + experience + age + [education ~ distance_to_college]'", "role": "Formula", "tip": "Multiple controls (experience, age) with one endogenous var and one instrument.", "color": "green"},
                      {"code": ", data=df)", "role": "Data", "tip": "The DataFrame.", "color": "sky"}
                    ],
                    "stata": [
                      {"code": "ivreg2", "role": "Command", "tip": "Community-contributed IV command with richer diagnostics than ivregress. ssc install ivreg2.", "color": "mauve"},
                      {"code": " wage experience", "role": "Outcome & Controls", "tip": "Dependent variable and exogenous controls.", "color": "sky"},
                      {"code": " (education = distance_to_college)", "role": "Endogenous Spec", "tip": "Same parenthetical syntax as ivregress.", "color": "green"},
                      {"code": ", ", "role": "Comma", "tip": "Before options.", "color": "text"},
                      {"code": "robust first", "role": "Options", "tip": "robust = HC SEs, first = show first-stage. ivreg2 also auto-reports weak ID and overid tests.", "color": "yellow"}
                    ],
                    "r": [
                      {"code": "iv_model", "role": "Variable", "tip": "The IV model estimated with fixest.", "color": "pink"},
                      {"code": " <- ", "role": "Assignment", "tip": "R's assignment.", "color": "peach"},
                      {"code": "feols", "role": "Function", "tip": "fixest's main function. Handles IV with a clean formula syntax.", "color": "blue"},
                      {"code": "(wage ~ experience", "role": "Outcome & Controls", "tip": "Outcome and exogenous controls before the pipe.", "color": "green"},
                      {"code": " | ", "role": "Pipe", "tip": "Separates exogenous regressors from the IV specification.", "color": "overlay"},
                      {"code": "education ~ distance_to_college", "role": "IV Spec", "tip": "After the pipe: endogenous_var ~ instrument. fixest handles the 2SLS mechanics.", "color": "teal"},
                      {"code": ", data = df, vcov = \"hetero\")", "role": "Data & SEs", "tip": "Data and robust standard errors.", "color": "sky"}
                    ]
                  }
                }
              ]
            }
            </script>
          </div>
        </section>

        <h2 id="2sls">Two-Stage Least Squares</h2>

        <p>
          IV estimation uses an instrument Z that affects treatment D but not the outcome Y directly. The identifying assumption is that Z affects Y only through D (exclusion restriction).
        </p>

        <div class="code-tabs" data-runnable="iv-1">
          <div class="tab-buttons">
            <button class="tab-button active" data-lang="python">Python</button>
            <button class="tab-button" data-lang="stata">Stata</button>
            <button class="tab-button" data-lang="r">R</button>
          </div>
          <div class="tab-content active" data-lang="python">
<pre><code><span class="code-comment"># Python: 2SLS with linearmodels</span>
<span class="code-keyword">from</span> linearmodels.iv <span class="code-keyword">import</span> IV2SLS
<span class="code-keyword">import</span> pandas <span class="code-keyword">as</span> pd

<span class="code-comment"># Example: effect of education on wages</span>
<span class="code-comment"># Instrument: distance to college</span>

<span class="code-comment"># 2SLS estimation</span>
<span class="code-tooltip" data-tip="IV2SLS syntax: dependent ~ exogenous + [endogenous ~ instruments]">model = IV2SLS.from_formula(
    <span class="code-string">'wage ~ 1 + experience + [education ~ distance_to_college]'</span>,
    data=df
)
results = model.fit(cov_type=<span class="code-string">'robust'</span>)</span>
print(results.summary)

<span class="code-comment"># With multiple controls</span>
model = IV2SLS.from_formula(
    <span class="code-string">'wage ~ 1 + experience + age + [education ~ distance_to_college]'</span>,
    data=df
)

<span class="code-comment"># Manual 2SLS (for understanding)</span>
<span class="code-keyword">import</span> statsmodels.api <span class="code-keyword">as</span> sm

<span class="code-comment"># First stage: regress endogenous on instrument</span>
first_stage = sm.OLS(df[<span class="code-string">'education'</span>],
                     sm.add_constant(df[[<span class="code-string">'distance_to_college'</span>, <span class="code-string">'experience'</span>]])).fit()
df[<span class="code-string">'education_hat'</span>] = first_stage.fittedvalues

<span class="code-comment"># Second stage: regress outcome on predicted endogenous</span>
second_stage = sm.OLS(df[<span class="code-string">'wage'</span>],
                      sm.add_constant(df[[<span class="code-string">'education_hat'</span>, <span class="code-string">'experience'</span>]])).fit()
<span class="code-comment"># Note: SEs from manual 2SLS are wrong! Use IV2SLS for correct SEs.</span></code></pre>
            <button class="run-btn" data-lang="python">Run Code</button>
          </div>
          <div class="tab-content" data-lang="stata">
<pre><code><span class="code-comment">* Stata: 2SLS with ivregress</span>

<span class="code-comment">* Basic 2SLS</span>
<span class="code-tooltip" data-tip="ivregress 2sls: (endogenous = instruments) controls">ivregress 2sls wage experience (education = distance_to_college), robust</span>

<span class="code-comment">* With first-stage results</span>
ivregress 2sls wage experience (education = distance_to_college), first robust

<span class="code-comment">* Using ivreg2 (more diagnostics)</span>
<span class="code-comment">* ssc install ivreg2</span>
<span class="code-tooltip" data-tip="ivreg2 provides additional diagnostics: weak IV, overid tests">ivreg2 wage experience (education = distance_to_college), robust first</span>

<span class="code-comment">* With clustering</span>
ivregress 2sls wage experience (education = distance_to_college), ///
    vce(cluster state)</code></pre>
            <button class="run-btn" data-lang="stata">Run Code</button>
          </div>
          <div class="tab-content" data-lang="r">
<pre><code><span class="code-comment"># R: 2SLS with ivreg (AER package)</span>
<span class="code-keyword">library</span>(AER)
<span class="code-keyword">library</span>(sandwich)

<span class="code-comment"># 2SLS estimation</span>
<span class="code-tooltip" data-tip="ivreg syntax: outcome ~ exogenous | instruments">iv_model <- ivreg(wage ~ education + experience |
                  distance_to_college + experience,
                  data = df)</span>
summary(iv_model, vcov = vcovHC, diagnostics = TRUE)

<span class="code-comment"># Using fixest (faster, more flexible)</span>
<span class="code-keyword">library</span>(fixest)

<span class="code-tooltip" data-tip="feols with 1 specifies the endogenous and instruments">iv_model <- feols(wage ~ experience | education ~ distance_to_college,
                  data = df,
                  vcov = "hetero")</span>
summary(iv_model, stage = 1:2)  <span class="code-comment"># show both stages</span></code></pre>
            <button class="run-btn" data-lang="r">Run Code</button>
          </div>
        </div>

        <div class="output-simulation" data-output="iv-1" data-lang="python">
          <div class="output-header">
            <span>Python Output</span>
            <button class="close-output">&times;</button>
          </div>
          <div class="output-body"><pre>                          IV-2SLS Estimation Summary
==============================================================================
Dep. Variable:                   wage   R-squared:                      0.2341
Estimator:                    IV-2SLS   Adj. R-squared:                 0.2338
No. Observations:                3010   F-statistic:                    156.34
Date:                Mon, Jan 27 2026   P-value (F-stat)                0.0000
Time:                        14:23:45   Distribution:                  chi2(2)
Cov. Estimator:                robust

                             Parameter Estimates
==============================================================================
            Parameter  Std. Err.     T-stat    P-value    Lower CI    Upper CI
------------------------------------------------------------------------------
Intercept      8.2341     1.4562      5.655      0.000      5.380      11.088
experience     0.4521     0.0234     19.321      0.000      0.406       0.498
education      0.8934     0.1123      7.956      0.000      0.673       1.114
==============================================================================

Endogenous: education
Instruments: distance_to_college
Robust Covariance (Heteroskedastic)
Debiased: False</pre></div>
        </div>

        <div class="output-simulation" data-output="iv-1" data-lang="stata">
          <div class="output-header">
            <span>Stata Output</span>
            <button class="close-output">&times;</button>
          </div>
          <div class="output-body"><pre>Instrumental variables 2SLS regression               Number of obs =     3,010
                                                     Wald chi2(2)  =    312.68
                                                     Prob > chi2   =    0.0000
                                                     R-squared     =    0.2341
                                                     Root MSE      =    8.2145

------------------------------------------------------------------------------
             |               Robust
        wage |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
   education |    .893412   .1123456     7.96   0.000     .6732206    1.113604
  experience |    .452134   .0234123    19.32   0.000      .406247    .4980209
       _cons |   8.234156   1.456234     5.66   0.000     5.379959    11.08835
------------------------------------------------------------------------------
Instrumented:  education
Instruments:   experience distance_to_college

First-stage regression summary statistics
------------------------------------------------------------------------------
    Variable |    R-sq.   Adj. R-sq.  Robust F(1,3007)   Prob > F
-------------+----------------------------------------------------------------
   education |   0.0892      0.0889        42.34          0.0000
------------------------------------------------------------------------------</pre></div>
        </div>

        <div class="output-simulation" data-output="iv-1" data-lang="r">
          <div class="output-header">
            <span>R Output</span>
            <button class="close-output">&times;</button>
          </div>
          <div class="output-body"><pre>Call:
ivreg(formula = wage ~ education + experience | distance_to_college +
    experience, data = df)

Residuals:
     Min       1Q   Median       3Q      Max
-28.4521  -5.2341  -0.1234   5.1234  32.5678

Coefficients:
             Estimate Std. Err. t value Pr(>|t|)
(Intercept)   8.2341    1.4562    5.66  1.7e-08 ***
education     0.8934    0.1123    7.96  2.2e-15 ***
experience    0.4521    0.0234   19.32  < 2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 8.214 on 3007 degrees of freedom
Multiple R-Squared: 0.2341,	Adjusted R-squared: 0.2338
Wald test: 156.3 on 2 and 3007 DF,  p-value: < 2.2e-16

Diagnostic tests:
                  df1  df2 statistic p-value
Weak instruments    1 3007     42.34  <2e-16 ***
---</pre></div>
        </div>

        <h2 id="diagnostics">IV Diagnostics</h2>

        <p>
          Always report: (1) first-stage F-statistic, (2) overidentification test (with multiple instruments), (3) comparison of OLS and IV estimates.
        </p>

        <div class="code-tabs" data-runnable="iv-2">
          <div class="tab-buttons">
            <button class="tab-button active" data-lang="python">Python</button>
            <button class="tab-button" data-lang="stata">Stata</button>
            <button class="tab-button" data-lang="r">R</button>
          </div>
          <div class="tab-content active" data-lang="python">
<pre><code><span class="code-comment"># Python: IV Diagnostics</span>
<span class="code-keyword">from</span> linearmodels.iv <span class="code-keyword">import</span> IV2SLS
<span class="code-keyword">import</span> statsmodels.api <span class="code-keyword">as</span> sm

<span class="code-comment"># Estimate IV model</span>
model = IV2SLS.from_formula(
    <span class="code-string">'wage ~ 1 + experience + [education ~ z1 + z2]'</span>,
    data=df
)
results = model.fit(cov_type=<span class="code-string">'robust'</span>)

<span class="code-comment"># 1. First-stage F-statistic</span>
<span class="code-tooltip" data-tip="F > 10 is rule of thumb for strong instruments (Stock-Yogo)">first_stage = sm.OLS(df[<span class="code-string">'education'</span>],
                     sm.add_constant(df[[<span class="code-string">'z1'</span>, <span class="code-string">'z2'</span>, <span class="code-string">'experience'</span>]])).fit()
print(f<span class="code-string">"First-stage F: {first_stage.fvalue:.2f}"</span>)</span>

<span class="code-comment"># 2. Durbin-Wu-Hausman test (endogeneity test)</span>
<span class="code-tooltip" data-tip="Tests whether OLS is consistent. Reject = evidence of endogeneity">print(<span class="code-string">"Wu-Hausman test:"</span>, results.wu_hausman())</span>

<span class="code-comment"># 3. Sargan-Hansen overidentification test</span>
<span class="code-tooltip" data-tip="Tests if all instruments are valid. Reject = at least one invalid">print(<span class="code-string">"Sargan test:"</span>, results.sargan)</span></code></pre>
            <button class="run-btn" data-lang="python">Run Code</button>
          </div>
          <div class="tab-content" data-lang="stata">
<pre><code><span class="code-comment">* Stata: IV Diagnostics</span>

<span class="code-comment">* Estimate with ivreg2 for full diagnostics</span>
ivreg2 wage experience (education = z1 z2), robust first

<span class="code-comment">* Key diagnostics reported automatically:</span>
<span class="code-comment">* - Kleibergen-Paap F statistic (weak ID)</span>
<span class="code-comment">* - Hansen J statistic (overidentification)</span>
<span class="code-comment">* - Endogeneity test</span>

<span class="code-comment">* Post-estimation tests with ivregress</span>
ivregress 2sls wage experience (education = z1 z2), robust

<span class="code-comment">* First-stage F</span>
<span class="code-tooltip" data-tip="estat firststage reports partial R2 and F for each instrument">estat firststage</span>

<span class="code-comment">* Endogeneity test</span>
estat endogenous

<span class="code-comment">* Overidentification test (requires >1 instrument per endogenous)</span>
<span class="code-tooltip" data-tip="Sargan/Hansen test: fail to reject means instruments may be valid">estat overid</span></code></pre>
            <button class="run-btn" data-lang="stata">Run Code</button>
          </div>
          <div class="tab-content" data-lang="r">
<pre><code><span class="code-comment"># R: IV Diagnostics</span>
<span class="code-keyword">library</span>(AER)

<span class="code-comment"># Estimate with diagnostics</span>
iv_model <- ivreg(wage ~ education + experience |
                  z1 + z2 + experience,
                  data = df)

<span class="code-comment"># Full diagnostics</span>
<span class="code-tooltip" data-tip="diagnostics = TRUE adds weak IV, Wu-Hausman, and Sargan tests">summary(iv_model, diagnostics = TRUE)</span>

<span class="code-comment"># Components:</span>
<span class="code-comment"># - Weak instruments: F-stat on excluded instruments</span>
<span class="code-comment"># - Wu-Hausman: endogeneity test (OLS consistent?)</span>
<span class="code-comment"># - Sargan: overidentification test</span>

<span class="code-comment"># With fixest</span>
<span class="code-keyword">library</span>(fixest)
iv_model <- feols(wage ~ experience | education ~ z1 + z2,
                  data = df)
<span class="code-tooltip" data-tip="fitstat reports various diagnostic statistics">fitstat(iv_model, ~ ivf + ivwald + sargan)</span></code></pre>
            <button class="run-btn" data-lang="r">Run Code</button>
          </div>
        </div>

        <div class="output-simulation" data-output="iv-2" data-lang="python">
          <div class="output-header">
            <span>Python Output</span>
            <button class="close-output">&times;</button>
          </div>
          <div class="output-body"><pre>First-stage F: 38.42
(F > 10 indicates strong instruments - Stock & Yogo rule of thumb)

Wu-Hausman test:
  Statistic: 12.456
  P-value: 0.0004
  Conclusion: Reject null of exogeneity - OLS is inconsistent

Sargan test (overidentification):
  J-statistic: 1.234
  P-value: 0.267
  Degrees of freedom: 1
  Conclusion: Fail to reject - instruments appear valid

Summary of IV Diagnostics:
--------------------------
First-stage F-statistic:     38.42  (> 10, strong instruments)
Wu-Hausman (endogeneity):    p = 0.0004 (education is endogenous)
Sargan (overid):             p = 0.267 (instruments appear valid)</pre></div>
        </div>

        <div class="output-simulation" data-output="iv-2" data-lang="stata">
          <div class="output-header">
            <span>Stata Output</span>
            <button class="close-output">&times;</button>
          </div>
          <div class="output-body"><pre>First-stage regression summary statistics
------------------------------------------------------------------------------
                                      Adjusted      Partial
    Variable |    R-sq.     R-sq.      R-sq.     F(2,3006)    Prob > F
-------------+----------------------------------------------------------------
   education |   0.1234    0.1228     0.0892       38.42      0.0000
------------------------------------------------------------------------------

Stock-Yogo weak ID test critical values for single endogenous regressor:
                                10%    15%    20%    25%
2SLS relative bias               19.93  11.59  8.75   7.25
2SLS Size of nominal 5% test     22.30  12.83  9.54   7.80

Kleibergen-Paap rk Wald F statistic:    38.42

Endogeneity test of endogenous regressors:
  Chi-sq(1) = 12.456    P-val = 0.0004
  Reject H0: education is exogenous

Hansen J statistic (overidentification test):
  Chi-sq(1) = 1.234     P-val = 0.267
  Fail to reject H0: instruments are valid</pre></div>
        </div>

        <div class="output-simulation" data-output="iv-2" data-lang="r">
          <div class="output-header">
            <span>R Output</span>
            <button class="close-output">&times;</button>
          </div>
          <div class="output-body"><pre>Diagnostic tests:
                    df1  df2 statistic p-value
Weak instruments      2 3006     38.42  <2e-16 ***
Wu-Hausman            1 3006     12.46  0.0004 ***
Sargan                1   NA      1.23  0.2670
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Interpretation:
- Weak instruments test: F = 38.42 >> 10, instruments are strong
- Wu-Hausman test: p = 0.0004, reject exogeneity (education is endogenous)
- Sargan test: p = 0.267, fail to reject (overidentifying restrictions valid)

First-stage results (using fixest):
               Estimate Std. Error  t value   Pr(>|t|)
z1              0.4523     0.0734    6.162    <2e-16 ***
z2              0.3156     0.0812    3.887    0.0001 ***
experience      0.0234     0.0089    2.629    0.0086 **

First-stage F-stat (joint test of instruments): 38.42</pre></div>
        </div>

        <h2 id="weak">Weak Instruments</h2>

        <p>
          Weak instruments (low first-stage F) cause biased IV estimates and unreliable inference. Use weak-instrument robust methods when F &lt; 10.
        </p>

        <div class="code-tabs" data-runnable="iv-3">
          <div class="tab-buttons">
            <button class="tab-button active" data-lang="python">Python</button>
            <button class="tab-button" data-lang="stata">Stata</button>
            <button class="tab-button" data-lang="r">R</button>
          </div>
          <div class="tab-content active" data-lang="python">
<pre><code><span class="code-comment"># Python: Weak Instrument Robust Inference</span>
<span class="code-keyword">from</span> linearmodels.iv <span class="code-keyword">import</span> IV2SLS
<span class="code-keyword">import</span> numpy <span class="code-keyword">as</span> np

<span class="code-comment"># Anderson-Rubin confidence interval (weak-IV robust)</span>
<span class="code-tooltip" data-tip="AR test inverts hypothesis tests to construct CIs valid with weak IV">def anderson_rubin_ci(y, d, z, x, alpha=0.05):
    <span class="code-string">"""Compute Anderson-Rubin confidence interval."""</span>
    <span class="code-keyword">from</span> scipy import stats

    <span class="code-comment"># Grid search over beta values</span>
    betas = np.linspace(-5, 5, 1000)
    ar_stats = []

    <span class="code-keyword">for</span> beta <span class="code-keyword">in</span> betas:
        resid = y - beta * d
        <span class="code-comment"># Regress residual on z (and x)</span>
        <span class="code-keyword">import</span> statsmodels.api <span class="code-keyword">as</span> sm
        model = sm.OLS(resid, sm.add_constant(np.column_stack([z, x]))).fit()
        <span class="code-comment"># F-test that coefficients on z are jointly zero</span>
        ar_stats.append(model.fvalue)

    <span class="code-comment"># CI: betas where we fail to reject</span>
    critical = stats.f.ppf(1-alpha, dfn=z.shape[1], dfd=len(y)-z.shape[1]-x.shape[1]-1)
    ci_mask = np.array(ar_stats) < critical
    <span class="code-keyword">return</span> betas[ci_mask].min(), betas[ci_mask].max()</span></code></pre>
            <button class="run-btn" data-lang="python">Run Code</button>
          </div>
          <div class="tab-content" data-lang="stata">
<pre><code><span class="code-comment">* Stata: Weak Instrument Robust Inference</span>

<span class="code-comment">* Limited Information Maximum Likelihood (LIML)</span>
<span class="code-tooltip" data-tip="LIML is less biased than 2SLS with weak instruments">ivregress liml wage experience (education = z1 z2), robust</span>

<span class="code-comment">* Weak-IV robust confidence intervals with weakiv</span>
<span class="code-comment">* ssc install weakiv</span>
<span class="code-tooltip" data-tip="weakiv computes Anderson-Rubin and other weak-IV robust tests">weakiv ivregress 2sls wage experience (education = z1 z2)</span>

<span class="code-comment">* Check Stock-Yogo critical values</span>
ivreg2 wage experience (education = z1 z2), first
<span class="code-comment">* Compare Kleibergen-Paap F to Stock-Yogo critical values</span>

<span class="code-comment">* Continuously updating GMM (CUE) - also weak-IV robust</span>
ivreg2 wage experience (education = z1 z2), cue robust</code></pre>
            <button class="run-btn" data-lang="stata">Run Code</button>
          </div>
          <div class="tab-content" data-lang="r">
<pre><code><span class="code-comment"># R: Weak Instrument Robust Inference</span>
<span class="code-keyword">library</span>(AER)
<span class="code-keyword">library</span>(ivmodel)

<span class="code-comment"># Check first-stage F</span>
iv_model <- ivreg(wage ~ education + experience |
                  z1 + z2 + experience,
                  data = df)
summary(iv_model, diagnostics = TRUE)

<span class="code-comment"># Weak-IV robust inference with ivmodel</span>
<span class="code-tooltip" data-tip="ivmodel provides Anderson-Rubin and other weak-IV robust methods">iv_robust <- ivmodel(Y = df$wage,
                     D = df$education,
                     Z = cbind(df$z1, df$z2),
                     X = df$experience)</span>

<span class="code-comment"># Anderson-Rubin confidence interval</span>
AR.test(iv_robust)

<span class="code-comment"># LIML estimator</span>
LIML(iv_robust)</code></pre>
            <button class="run-btn" data-lang="r">Run Code</button>
          </div>
        </div>

        <div class="output-simulation" data-output="iv-3" data-lang="python">
          <div class="output-header">
            <span>Python Output</span>
            <button class="close-output">&times;</button>
          </div>
          <div class="output-body"><pre>Anderson-Rubin Confidence Interval (Weak-IV Robust)
===================================================

Testing H0: beta = beta_0 for grid of beta values...

AR 95% Confidence Interval: [0.612, 1.234]

Comparison of Methods:
                     Estimate     95% CI
2SLS                   0.893     [0.673, 1.114]
Anderson-Rubin           -       [0.612, 1.234]
LIML                   0.897     [0.665, 1.129]

Note: AR CI is wider but valid even with weak instruments.
When first-stage F > 10, 2SLS and AR CIs are similar.

Grid search details:
  Beta range searched: [-5, 5]
  Grid points: 1000
  Critical value (F, df1=2, df2=3006): 3.00
  Betas not rejected: 623 points</pre></div>
        </div>

        <div class="output-simulation" data-output="iv-3" data-lang="stata">
          <div class="output-header">
            <span>Stata Output</span>
            <button class="close-output">&times;</button>
          </div>
          <div class="output-body"><pre>LIML estimation
-------------------------------------------------------------------------------
             |               Robust
        wage |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------+-----------------------------------------------------------------
   education |    .897234   .1156789     7.76   0.000     .6704994    1.123969
  experience |    .451234   .0234567    19.23   0.000     .4052593    .4972087
       _cons |   8.156234   1.478912     5.52   0.000     5.257419    11.05505
-------------------------------------------------------------------------------

Weak-instrument-robust inference (weakiv):
Tests of H0: beta=b0

                                                   95% conf. set for beta
                   Test statistic      p-value      (robust to weak IV)
Anderson-Rubin     chi2(2)=23.45       0.0000       [0.612, 1.234]
Wald               chi2(1)=60.12       0.0000       [0.673, 1.114]

Conditional Likelihood Ratio (CLR) test:
CLR statistic:     23.12              p-value:       0.0000
95% CLR CI:        [0.628, 1.221]

Stock-Yogo critical values (2SLS, 5% maximal bias):
  # instruments = 2:  critical F = 19.93
  Actual F = 38.42 > 19.93: instruments are NOT weak</pre></div>
        </div>

        <div class="output-simulation" data-output="iv-3" data-lang="r">
          <div class="output-header">
            <span>R Output</span>
            <button class="close-output">&times;</button>
          </div>
          <div class="output-body"><pre>Anderson-Rubin Test
-------------------
AR Statistic: 23.45 on 2 and 3006 DF
p-value: < 2.2e-16

95% Anderson-Rubin Confidence Set: [0.612, 1.234]

LIML Estimator
--------------
            Estimate Std. Error   t value   Pr(>|t|)
education     0.8972     0.1157     7.757   < 2e-16 ***

Comparison of Estimators:
              Estimate        SE      95% CI
2SLS            0.8934    0.1123    [0.673, 1.114]
LIML            0.8972    0.1157    [0.670, 1.124]
Fuller(1)       0.8956    0.1142    [0.672, 1.119]

Note: LIML is median-unbiased with weak instruments,
while 2SLS bias is towards OLS.

Weak IV diagnostics:
First-stage F: 38.42
Stock-Yogo 10% maximal size: 19.93
Conclusion: F >> critical value, instruments are strong</pre></div>
        </div>

        <h2 id="bartik">Bartik/Shift-Share Instruments</h2>

        <p>
          Shift-share (Bartik) instruments interact national/sectoral shocks with local industry shares. They're widely used in labor and trade economics. Recent papers clarify when they're valid.
        </p>

        <div class="code-tabs" data-runnable="iv-4">
          <div class="tab-buttons">
            <button class="tab-button active" data-lang="python">Python</button>
            <button class="tab-button" data-lang="stata">Stata</button>
            <button class="tab-button" data-lang="r">R</button>
          </div>
          <div class="tab-content active" data-lang="python">
<pre><code><span class="code-comment"># Python: Constructing a Bartik Instrument</span>
<span class="code-keyword">import</span> pandas <span class="code-keyword">as</span> pd
<span class="code-keyword">import</span> numpy <span class="code-keyword">as</span> np

<span class="code-comment"># Components:</span>
<span class="code-comment"># - shares_{l,k}: share of industry k in location l (pre-period)</span>
<span class="code-comment"># - growth_k: national growth rate in industry k</span>

<span class="code-comment"># Step 1: Calculate industry shares by location (base period)</span>
base_year = df[df[<span class="code-string">'year'</span>] == 2000]
shares = base_year.groupby([<span class="code-string">'location'</span>, <span class="code-string">'industry'</span>])[<span class="code-string">'employment'</span>].sum()
total_emp = base_year.groupby(<span class="code-string">'location'</span>)[<span class="code-string">'employment'</span>].sum()
shares = shares / total_emp  <span class="code-comment"># shares_{l,k}</span>

<span class="code-comment"># Step 2: Calculate national growth by industry (excluding own location)</span>
<span class="code-tooltip" data-tip="Leave-one-out: exclude own location to avoid mechanical correlation">def leave_one_out_growth(row, df):
    industry = row[<span class="code-string">'industry'</span>]
    location = row[<span class="code-string">'location'</span>]
    other_locs = df[(df[<span class="code-string">'industry'</span>] == industry) & (df[<span class="code-string">'location'</span>] != location)]
    growth = other_locs[<span class="code-string">'emp_change'</span>].sum() / other_locs[<span class="code-string">'base_emp'</span>].sum()
    <span class="code-keyword">return</span> growth</span>

<span class="code-comment"># Step 3: Construct Bartik instrument</span>
<span class="code-tooltip" data-tip="Bartik = sum over industries of (share √ó national growth)">bartik = (shares * national_growth).groupby(<span class="code-string">'location'</span>).sum()</span>
df = df.merge(bartik.rename(<span class="code-string">'bartik'</span>), on=<span class="code-string">'location'</span>)

<span class="code-comment"># Use in IV regression</span>
<span class="code-keyword">from</span> linearmodels.iv <span class="code-keyword">import</span> IV2SLS
model = IV2SLS.from_formula(
    <span class="code-string">'wage ~ 1 + controls + [local_emp_growth ~ bartik]'</span>,
    data=df
)</code></pre>
            <button class="run-btn" data-lang="python">Run Code</button>
          </div>
          <div class="tab-content" data-lang="stata">
<pre><code><span class="code-comment">* Stata: Bartik Instrument</span>

<span class="code-comment">* Assume data has: location, industry, employment, year</span>

<span class="code-comment">* Step 1: Calculate base-year shares</span>
preserve
keep if year == 2000
bysort location: egen total_emp = total(employment)
gen share = employment / total_emp
keep location industry share
tempfile shares
save `shares'
restore

<span class="code-comment">* Step 2: Calculate leave-one-out national growth</span>
<span class="code-tooltip" data-tip="Leave-one-out avoids mechanical correlation from own location">bysort industry: egen nat_growth = total(emp_change)
bysort industry: egen nat_base = total(base_emp)
gen loo_growth = (nat_growth - emp_change) / (nat_base - base_emp)</span>

<span class="code-comment">* Step 3: Merge shares and compute Bartik</span>
merge m:1 location industry using `shares'
gen bartik_component = share * loo_growth
bysort location: egen bartik = total(bartik_component)

<span class="code-comment">* Step 4: Use in IV regression</span>
<span class="code-tooltip" data-tip="ssaggregate from Borusyak et al. automates this correctly">ivregress 2sls wage controls (local_emp_growth = bartik), cluster(location)</span>

<span class="code-comment">* Using ssaggregate (Borusyak, Hull, Jaravel)</span>
<span class="code-comment">* ssc install ssaggregate</span>
ssaggregate outcome treatment, ///
    shares(share) shocks(national_growth) controls(x1 x2) ///
    cluster(location)</code></pre>
            <button class="run-btn" data-lang="stata">Run Code</button>
          </div>
          <div class="tab-content" data-lang="r">
<pre><code><span class="code-comment"># R: Bartik Instrument</span>
<span class="code-keyword">library</span>(dplyr)
<span class="code-keyword">library</span>(fixest)

<span class="code-comment"># Step 1: Calculate base-year shares</span>
shares <- df %>%
  filter(year == 2000) %>%
  group_by(location, industry) %>%
  summarise(emp = sum(employment)) %>%
  group_by(location) %>%
  mutate(share = emp / sum(emp)) %>%
  select(location, industry, share)

<span class="code-comment"># Step 2: Leave-one-out national growth</span>
<span class="code-tooltip" data-tip="Exclude own location when calculating national growth">growth <- df %>%
  group_by(industry, location) %>%
  summarise(emp_change = sum(emp_change), base_emp = sum(base_emp)) %>%
  group_by(industry) %>%
  mutate(
    loo_growth = (sum(emp_change) - emp_change) / (sum(base_emp) - base_emp)
  )</span>

<span class="code-comment"># Step 3: Construct Bartik</span>
bartik <- shares %>%
  left_join(growth, by = c("location", "industry")) %>%
  mutate(component = share * loo_growth) %>%
  group_by(location) %>%
  summarise(bartik = sum(component, na.rm = TRUE))

<span class="code-comment"># Merge and estimate</span>
df <- df %>% left_join(bartik, by = "location")

<span class="code-comment"># IV regression</span>
iv_model <- feols(wage ~ controls | local_emp_growth ~ bartik,
                  data = df,
                  cluster = ~ location)</code></pre>
            <button class="run-btn" data-lang="r">Run Code</button>
          </div>
        </div>

        <div class="output-simulation" data-output="iv-4" data-lang="python">
          <div class="output-header">
            <span>Python Output</span>
            <button class="close-output">&times;</button>
          </div>
          <div class="output-body"><pre>Bartik Instrument Construction
==============================

Step 1: Industry shares (base year 2000)
Location    Manufacturing  Services  Agriculture  Finance
New York          0.234      0.456        0.012    0.298
California        0.189      0.512        0.089    0.210
Texas             0.312      0.378        0.156    0.154
...

Step 2: National industry growth (leave-one-out)
Industry        Growth Rate
Manufacturing       -0.0234
Services             0.0456
Agriculture         -0.0123
Finance              0.0312

Step 3: Bartik instrument by location
Location      Bartik
New York      0.0189
California    0.0234
Texas        -0.0056
...

IV Regression Results (using Bartik as instrument):
==============================================================================
            Parameter  Std. Err.     T-stat    P-value    Lower CI    Upper CI
------------------------------------------------------------------------------
local_emp      1.234     0.345       3.576      0.000      0.558       1.910
controls       0.456     0.123       3.707      0.000      0.215       0.697
------------------------------------------------------------------------------
First-stage F: 28.34
Clustered SEs at location level (n_clusters = 150)</pre></div>
        </div>

        <div class="output-simulation" data-output="iv-4" data-lang="stata">
          <div class="output-header">
            <span>Stata Output</span>
            <button class="close-output">&times;</button>
          </div>
          <div class="output-body"><pre>Step 1: Base-year industry shares created
  Observations: 3,200 (location x industry)
  Locations: 150
  Industries: 20

Step 2: Leave-one-out growth rates calculated
  Mean growth: 0.0234
  SD growth: 0.0456

Step 3: Bartik instrument created
  Mean Bartik: 0.0145
  SD Bartik: 0.0234

IV Regression with Bartik Instrument
(Std. Err. adjusted for 150 clusters in location)
------------------------------------------------------------------------------
             |               Robust
        wage |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
local_emp_~h |   1.234567   .3456789     3.57   0.000     .5570356    1.912098
    controls |   .4561234   .1234567     3.71   0.000     .2142044    .6980424
       _cons |  12.34567   2.345678     5.26   0.000     7.748211    16.94313
------------------------------------------------------------------------------
Instrumented:  local_emp_growth
Instruments:   controls bartik

First-stage F-statistic: 28.34
Kleibergen-Paap rk Wald F: 28.34</pre></div>
        </div>

        <div class="output-simulation" data-output="iv-4" data-lang="r">
          <div class="output-header">
            <span>R Output</span>
            <button class="close-output">&times;</button>
          </div>
          <div class="output-body"><pre>Bartik Instrument Construction
==============================

Industry shares (sample):
# A tibble: 3,000 x 3
  location   industry       share
  <chr>      <chr>          <dbl>
1 New York   Manufacturing  0.234
2 New York   Services       0.456
3 California Manufacturing  0.189
...

Bartik instrument summary:
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
-0.0456 -0.0123  0.0145  0.0178  0.0312  0.0567

IV Regression with Clustered Standard Errors
============================================
TSLS estimation, Pair(s): 1, Observations: 4,500
Cluster: location, Number of clusters: 150

                 Estimate Std. Error   t value   Pr(>|t|)
local_emp_growth   1.2346     0.3457     3.572   0.000489 ***
controls           0.4561     0.1235     3.707   0.000312 ***

First-stage statistics:
                    F-stat   p-value
local_emp_growth     28.34   < 2e-16

Partial R2 of excluded instruments: 0.0892</pre></div>
        </div>

        <div class="info-box warning">
          <div class="info-box-title">Recent Advances in Shift-Share Identification</div>
          <p>
            Recent papers provide new understanding of when Bartik instruments are valid:
          </p>
          <ul>
            <li><strong>Goldsmith-Pinkham, Sorkin, Swift (2020):</strong> Identification comes from the shares; requires shares to be exogenous</li>
            <li><strong>Borusyak, Hull, Jaravel (2022):</strong> Identification comes from the shocks; requires shocks to be as-good-as-randomly assigned</li>
            <li><strong>Ad√£o, Koles√°r, Morales (2019):</strong> Standard errors need adjustment for exposure-weighted structure</li>
          </ul>
          <p style="margin-bottom: 0;">
            Choose your identification argument and conduct appropriate diagnostics.
          </p>
        </div>

        <h2 id="multiple">Multiple Instruments</h2>

        <p>
          With multiple instruments, you can test overidentifying restrictions, but be careful of overfitting and weak-IV bias magnification.
        </p>

        <div class="code-tabs" data-runnable="iv-5">
          <div class="tab-buttons">
            <button class="tab-button active" data-lang="python">Python</button>
            <button class="tab-button" data-lang="stata">Stata</button>
            <button class="tab-button" data-lang="r">R</button>
          </div>
          <div class="tab-content active" data-lang="python">
<pre><code><span class="code-comment"># Python: Multiple Instruments</span>
<span class="code-keyword">from</span> linearmodels.iv <span class="code-keyword">import</span> IV2SLS

<span class="code-comment"># Multiple instruments for one endogenous variable</span>
model = IV2SLS.from_formula(
    <span class="code-string">'wage ~ 1 + experience + [education ~ z1 + z2 + z3]'</span>,
    data=df
)
results = model.fit(cov_type=<span class="code-string">'robust'</span>)

<span class="code-comment"># Overidentification test (Sargan-Hansen)</span>
<span class="code-tooltip" data-tip="With more instruments than endogenous vars, test if all instruments are valid">print(<span class="code-string">"Sargan J-statistic:"</span>, results.sargan.stat)
print(<span class="code-string">"p-value:"</span>, results.sargan.pval)</span>

<span class="code-comment"># Multiple endogenous variables</span>
model = IV2SLS.from_formula(
    <span class="code-string">'wage ~ 1 + age + [education + experience ~ z1 + z2 + z3 + z4]'</span>,
    data=df
)</code></pre>
            <button class="run-btn" data-lang="python">Run Code</button>
          </div>
          <div class="tab-content" data-lang="stata">
<pre><code><span class="code-comment">* Stata: Multiple Instruments</span>

<span class="code-comment">* Multiple instruments</span>
ivreg2 wage experience (education = z1 z2 z3), robust first

<span class="code-comment">* Check overidentification</span>
<span class="code-tooltip" data-tip="Hansen J: fail to reject suggests instruments are consistent with each other">estat overid</span>

<span class="code-comment">* Compare specifications with different instruments</span>
<span class="code-tooltip" data-tip="Check if estimates are stable across instrument sets">estimates store full
ivreg2 wage experience (education = z1 z2), robust
estimates store partial
estimates table full partial</span>

<span class="code-comment">* Multiple endogenous variables</span>
ivregress 2sls wage age (education experience = z1 z2 z3 z4), robust</code></pre>
            <button class="run-btn" data-lang="stata">Run Code</button>
          </div>
          <div class="tab-content" data-lang="r">
<pre><code><span class="code-comment"># R: Multiple Instruments</span>
<span class="code-keyword">library</span>(AER)
<span class="code-keyword">library</span>(fixest)

<span class="code-comment"># Multiple instruments</span>
iv_model <- ivreg(wage ~ education + experience |
                  z1 + z2 + z3 + experience,
                  data = df)
summary(iv_model, diagnostics = TRUE)

<span class="code-comment"># Sargan test for overidentification</span>
<span class="code-tooltip" data-tip="Sargan test checks if instruments are jointly valid">summary(iv_model, diagnostics = TRUE)$diagnostics["Sargan", ]</span>

<span class="code-comment"># With fixest: check stability across instrument sets</span>
iv1 <- feols(wage ~ experience | education ~ z1, data = df)
iv2 <- feols(wage ~ experience | education ~ z1 + z2, data = df)
iv3 <- feols(wage ~ experience | education ~ z1 + z2 + z3, data = df)

<span class="code-tooltip" data-tip="Compare estimates: stable across instrument sets is reassuring">etable(iv1, iv2, iv3)</span></code></pre>
            <button class="run-btn" data-lang="r">Run Code</button>
          </div>
        </div>

        <div class="output-simulation" data-output="iv-5" data-lang="python">
          <div class="output-header">
            <span>Python Output</span>
            <button class="close-output">&times;</button>
          </div>
          <div class="output-body"><pre>                          IV-2SLS Estimation Summary
==============================================================================
Dep. Variable:                   wage   R-squared:                      0.2356
Estimator:                    IV-2SLS   Adj. R-squared:                 0.2352
No. Observations:                3010   F-statistic:                    162.45
Date:                Mon, Jan 27 2026   P-value (F-stat)                0.0000

                             Parameter Estimates
==============================================================================
            Parameter  Std. Err.     T-stat    P-value    Lower CI    Upper CI
------------------------------------------------------------------------------
Intercept      8.1234     1.4123      5.752      0.000      5.355      10.892
experience     0.4534     0.0231     19.627      0.000      0.408       0.499
education      0.8823     0.1089      8.102      0.000      0.669       1.096
==============================================================================

Sargan-Hansen J-statistic: 2.345
Degrees of freedom: 2 (3 instruments - 1 endogenous)
P-value: 0.310

Interpretation: Fail to reject null hypothesis.
Overidentifying restrictions are valid - instruments are consistent.

First-stage F-statistic (joint): 32.56
Individual instrument F-stats:
  z1: 28.34
  z2: 18.92
  z3: 12.45</pre></div>
        </div>

        <div class="output-simulation" data-output="iv-5" data-lang="stata">
          <div class="output-header">
            <span>Stata Output</span>
            <button class="close-output">&times;</button>
          </div>
          <div class="output-body"><pre>IV (2SLS) estimation
--------------------
                                                     Number of obs =     3,010
                                                     F(2, 3007)    =    162.45
                                                     Prob > F      =    0.0000

------------------------------------------------------------------------------
             |               Robust
        wage |      Coef.   Std. Err.      t    P>|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
   education |   .8823456   .1089123     8.10   0.000     .6688234    1.095868
  experience |   .4534123   .0231234    19.63   0.000     .4080709    .4987537
       _cons |   8.123456   1.412345     5.75   0.000     5.354178    10.89273
------------------------------------------------------------------------------

Hansen J statistic (overidentification test of all instruments):
  Chi-sq(2) = 2.345      P-val = 0.310
  Instruments appear valid

Comparing instrument specifications:
------------------------------------------------------------------------------
    Variable |      full          partial
-------------+--------------------------------
   education |   .8823456        .8912345
             |  (.1089123)      (.1234567)
  experience |   .4534123        .4523456
             |  (.0231234)      (.0245678)
------------------------------------------------------------------------------
Note: Estimates are stable across instrument sets</pre></div>
        </div>

        <div class="output-simulation" data-output="iv-5" data-lang="r">
          <div class="output-header">
            <span>R Output</span>
            <button class="close-output">&times;</button>
          </div>
          <div class="output-body"><pre>Diagnostic tests:
                    df1  df2 statistic p-value
Weak instruments      3 3006     32.56  <2e-16 ***
Wu-Hausman            1 3006     11.89  0.0006 ***
Sargan                2   NA      2.34  0.3100
---

Sargan Test for Overidentifying Restrictions:
  J-statistic: 2.345 on 2 DF
  p-value: 0.310
  Conclusion: Fail to reject - instruments appear valid

Comparison across instrument sets (etable):
                                 iv1           iv2           iv3
Dependent Var.:                 wage          wage          wage

education                   0.9123***     0.8912***     0.8823***
                           (0.1456)      (0.1234)      (0.1089)
experience                  0.4512***     0.4523***     0.4534***
                           (0.0256)      (0.0245)      (0.0231)
Constant                    8.0123***     8.0567***     8.1234***
                           (1.5234)      (1.4678)      (1.4123)

First-stage F               18.92         25.67         32.56
Sargan J (p-val)              -           0.456         0.310
---

Estimates stable across specifications: reassuring for validity.</pre></div>
        </div>

        <h2 id="wald">Wald Estimator</h2>

        <p>
          The Wald estimator is the simplest IV estimator, applicable when the instrument Z is binary. It equals the ratio of the reduced-form effect (Z on Y) to the first-stage effect (Z on D). With a binary instrument, this is numerically identical to 2SLS and identifies the Local Average Treatment Effect (LATE) for compliers.
        </p>

        <div class="code-tabs" data-runnable="iv-wald">
          <div class="tab-buttons">
            <button class="tab-button active" data-lang="python">Python</button>
            <button class="tab-button" data-lang="stata">Stata</button>
            <button class="tab-button" data-lang="r">R</button>
          </div>
          <div class="tab-content active" data-lang="python">
<pre><code><span class="code-comment"># Python: Wald Estimator</span>
<span class="code-keyword">import</span> numpy <span class="code-keyword">as</span> np
<span class="code-keyword">from</span> linearmodels.iv <span class="code-keyword">import</span> IV2SLS

<span class="code-comment"># Manual Wald estimator with binary instrument</span>
<span class="code-comment"># Example: effect of veteran status on earnings, using draft eligibility as Z</span>

<span class="code-comment"># Reduced form: E[Y|Z=1] - E[Y|Z=0]</span>
<span class="code-tooltip" data-tip="The reduced form is the effect of the instrument on the outcome">reduced_form = (df.loc[df[<span class="code-string">'eligible'</span>]==1, <span class="code-string">'earnings'</span>].mean() -
                df.loc[df[<span class="code-string">'eligible'</span>]==0, <span class="code-string">'earnings'</span>].mean())</span>

<span class="code-comment"># First stage: E[D|Z=1] - E[D|Z=0]</span>
<span class="code-tooltip" data-tip="The first stage is the effect of the instrument on the treatment">first_stage = (df.loc[df[<span class="code-string">'eligible'</span>]==1, <span class="code-string">'veteran'</span>].mean() -
               df.loc[df[<span class="code-string">'eligible'</span>]==0, <span class="code-string">'veteran'</span>].mean())</span>

<span class="code-comment"># Wald estimate = LATE</span>
wald = reduced_form / first_stage
print(f<span class="code-string">"Reduced form: {reduced_form:.4f}"</span>)
print(f<span class="code-string">"First stage:  {first_stage:.4f}"</span>)
print(f<span class="code-string">"Wald (LATE):  {wald:.4f}"</span>)

<span class="code-comment"># Verify: matches 2SLS</span>
iv_model = IV2SLS.from_formula(
    <span class="code-string">'earnings ~ 1 + [veteran ~ eligible]'</span>, data=df
).fit(cov_type=<span class="code-string">'robust'</span>)
print(f<span class="code-string">"2SLS estimate: {iv_model.params['veteran']:.4f}"</span>)</code></pre>
            <button class="run-btn" data-lang="python">Run Code</button>
          </div>
          <div class="tab-content" data-lang="stata">
<pre><code><span class="code-comment">* Stata: Wald Estimator</span>

<span class="code-comment">* Manual Wald estimator</span>
<span class="code-tooltip" data-tip="Compute group means for the reduced form and first stage">quietly summarize earnings if eligible == 1
local y1 = r(mean)
quietly summarize earnings if eligible == 0
local y0 = r(mean)
quietly summarize veteran if eligible == 1
local d1 = r(mean)
quietly summarize veteran if eligible == 0
local d0 = r(mean)</span>

<span class="code-comment">* Wald = reduced form / first stage</span>
local reduced_form = `y1' - `y0'
local first_stage = `d1' - `d0'
local wald = `reduced_form' / `first_stage'

display "Reduced form: " `reduced_form'
display "First stage:  " `first_stage'
display "Wald (LATE):  " `wald'

<span class="code-comment">* Verify: matches 2SLS</span>
<span class="code-tooltip" data-tip="With a single binary instrument, 2SLS equals the Wald estimator">ivregress 2sls earnings (veteran = eligible), robust</span></code></pre>
            <button class="run-btn" data-lang="stata">Run Code</button>
          </div>
          <div class="tab-content" data-lang="r">
<pre><code><span class="code-comment"># R: Wald Estimator</span>

<span class="code-comment"># Manual Wald estimator with binary instrument</span>
<span class="code-comment"># Example: Angrist (1990) ‚Äî veteran status on earnings, draft eligibility as Z</span>

<span class="code-comment"># Reduced form: E[Y|Z=1] - E[Y|Z=0]</span>
<span class="code-tooltip" data-tip="The reduced form captures the total effect of the instrument on the outcome">reduced_form <- mean(df$earnings[df$eligible == 1]) -
                mean(df$earnings[df$eligible == 0])</span>

<span class="code-comment"># First stage: E[D|Z=1] - E[D|Z=0]</span>
<span class="code-tooltip" data-tip="The first stage measures how strongly the instrument shifts treatment">first_stage <- mean(df$veteran[df$eligible == 1]) -
               mean(df$veteran[df$eligible == 0])</span>

<span class="code-comment"># Wald estimate = LATE for compliers</span>
wald_estimate <- reduced_form / first_stage

cat("Reduced form:", reduced_form, "\n")
cat("First stage: ", first_stage, "\n")
cat("Wald (LATE): ", wald_estimate, "\n")

<span class="code-comment"># Verify: matches 2SLS</span>
<span class="code-keyword">library</span>(AER)
<span class="code-tooltip" data-tip="With a single binary instrument, ivreg() gives the same point estimate as the Wald ratio">iv_model <- ivreg(earnings ~ veteran | eligible, data = df)
coef(iv_model)["veteran"]  <span class="code-comment"># should match wald_estimate</span></span>

<span class="code-comment"># With robust standard errors</span>
<span class="code-keyword">library</span>(sandwich)
<span class="code-keyword">library</span>(lmtest)
coeftest(iv_model, vcov = vcovHC(iv_model, type = "HC1"))</code></pre>
            <button class="run-btn" data-lang="r">Run Code</button>
          </div>
        </div>

        <div class="output-simulation" data-output="iv-wald" data-lang="r">
          <div class="output-header"><span>R Output</span><button class="close-output">&times;</button></div>
          <div class="output-body">Reduced form: -1523.45
First stage:  0.1587
Wald (LATE):  -9598.42

> coef(iv_model)["veteran"]
  veteran
-9598.42

> coeftest(iv_model, vcov = vcovHC(iv_model, type = "HC1"))

t test of coefficients (Heteroskedasticity-consistent):

            Estimate Std. Error t value Pr(>|t|)
(Intercept) 21456.23    234.56  91.481   <2e-16 ***
veteran     -9598.42   4812.34  -1.995   0.0462 *
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</div>
        </div>

        <div class="info-box note">
          <div class="info-box-title">The Wald Estimator Identifies LATE</div>
          <p>
            The Wald estimator identifies the <strong>Local Average Treatment Effect (LATE)</strong>‚Äîthe causal effect for compliers, i.e., units whose treatment status changes because of the instrument. With draft eligibility as an instrument, the Wald estimate captures the effect of military service for those who served <em>because</em> they were drafted (compliers), not for volunteers or people who avoided service despite being eligible.
          </p>
          <p style="margin-bottom: 0;">
            Reference: Angrist, J. (1990). "Lifetime Earnings and the Vietnam Era Draft Lottery." <em>American Economic Review</em>.
          </p>
        </div>

        <h2 id="control-function">Control Function Approach</h2>

        <p>
          The control function (CF) approach is an alternative to 2SLS that works by including the first-stage residuals as an additional regressor in the outcome equation. This has two key advantages: (1) the coefficient on the residuals directly tests for endogeneity, and (2) it generalizes to nonlinear models (probit, logit) where standard 2SLS does not apply.
        </p>

        <div class="code-tabs" data-runnable="iv-cf">
          <div class="tab-buttons">
            <button class="tab-button active" data-lang="python">Python</button>
            <button class="tab-button" data-lang="stata">Stata</button>
            <button class="tab-button" data-lang="r">R</button>
          </div>
          <div class="tab-content active" data-lang="python">
<pre><code><span class="code-comment"># Python: Control Function Approach</span>
<span class="code-keyword">import</span> statsmodels.formula.api <span class="code-keyword">as</span> smf
<span class="code-keyword">import</span> numpy <span class="code-keyword">as</span> np

<span class="code-comment"># Step 1: First stage ‚Äî regress endogenous variable on instruments + controls</span>
<span class="code-tooltip" data-tip="The first stage produces residuals that capture the endogenous variation in D">first_stage = smf.ols(<span class="code-string">'education ~ distance + experience'</span>, data=df).fit()
df[<span class="code-string">'v_hat'</span>] = first_stage.resid</span>

<span class="code-comment"># Step 2: Include first-stage residuals in outcome equation</span>
<span class="code-tooltip" data-tip="The coefficient on v_hat tests endogeneity; coefficient on education is the IV estimate">cf_model = smf.ols(<span class="code-string">'wage ~ education + experience + v_hat'</span>, data=df).fit()</span>
print(cf_model.summary())

<span class="code-comment"># Endogeneity test: is v_hat significant?</span>
print(f<span class="code-string">"\nEndogeneity test (H0: education is exogenous):"</span>)
print(f<span class="code-string">"  t-stat on v_hat: {cf_model.tvalues['v_hat']:.4f}"</span>)
print(f<span class="code-string">"  p-value:         {cf_model.pvalues['v_hat']:.4f}"</span>)

<span class="code-comment"># Note: Standard errors need bootstrap correction!</span>
<span class="code-keyword">from</span> sklearn.utils <span class="code-keyword">import</span> resample

<span class="code-tooltip" data-tip="Naive SEs from two-step are incorrect; bootstrap provides valid inference">boot_coefs = []
<span class="code-keyword">for</span> _ <span class="code-keyword">in</span> range(999):
    boot_df = resample(df)
    fs = smf.ols(<span class="code-string">'education ~ distance + experience'</span>, data=boot_df).fit()
    boot_df[<span class="code-string">'v_hat'</span>] = fs.resid
    ss = smf.ols(<span class="code-string">'wage ~ education + experience + v_hat'</span>, data=boot_df).fit()
    boot_coefs.append(ss.params[<span class="code-string">'education'</span>])
print(f<span class="code-string">"Bootstrap SE for education: {np.std(boot_coefs):.4f}"</span>)</span></code></pre>
            <button class="run-btn" data-lang="python">Run Code</button>
          </div>
          <div class="tab-content" data-lang="stata">
<pre><code><span class="code-comment">* Stata: Control Function Approach</span>

<span class="code-comment">* Step 1: First stage ‚Äî get residuals</span>
<span class="code-tooltip" data-tip="Estimate the first stage and predict residuals">reg education distance experience
predict v_hat, residuals</span>

<span class="code-comment">* Step 2: Include residuals in outcome equation</span>
<span class="code-tooltip" data-tip="Coefficient on v_hat tests endogeneity; coefficient on education is the CF/IV estimate">reg wage education experience v_hat, robust</span>

<span class="code-comment">* Test endogeneity: is v_hat significant?</span>
<span class="code-comment">* If yes ‚Üí education is endogenous ‚Üí use IV</span>
test v_hat

<span class="code-comment">* Note: SEs above are incorrect (two-step problem)</span>
<span class="code-comment">* Use bootstrap for correct inference:</span>
<span class="code-tooltip" data-tip="bootstrap {} handles the two-step procedure correctly">bootstrap, reps(999) cluster(unit_id): ///
    quietly reg education distance experience; ///
    predict v_hat_b, residuals; ///
    reg wage education experience v_hat_b</span>

<span class="code-comment">* Equivalent Durbin-Wu-Hausman test via ivregress</span>
ivregress 2sls wage experience (education = distance), robust
estat endogenous</code></pre>
            <button class="run-btn" data-lang="stata">Run Code</button>
          </div>
          <div class="tab-content" data-lang="r">
<pre><code><span class="code-comment"># R: Control Function Approach</span>

<span class="code-comment"># Step 1: First stage ‚Äî regress endogenous var on instrument + controls</span>
<span class="code-tooltip" data-tip="The first-stage residuals capture the endogenous component of education">first_stage <- lm(education ~ distance + experience, data = df)
df$v_hat <- residuals(first_stage)</span>

<span class="code-comment"># Step 2: Include first-stage residuals in outcome equation</span>
<span class="code-tooltip" data-tip="In the CF approach, education's coefficient is the IV estimate; v_hat tests endogeneity">cf_model <- lm(wage ~ education + experience + v_hat, data = df)
summary(cf_model)</span>

<span class="code-comment"># Endogeneity test: is v_hat significant?</span>
<span class="code-comment"># If p-value on v_hat < 0.05 ‚Üí education is endogenous</span>
cat("Endogeneity test p-value:", summary(cf_model)$coefficients["v_hat", "Pr(>|t|)"], "\n")

<span class="code-comment"># Important: naive SEs are wrong! Use bootstrap for correct inference</span>
<span class="code-keyword">library</span>(boot)
<span class="code-tooltip" data-tip="The boot function resamples data and re-estimates the full two-step procedure each time">cf_boot <- function(data, indices) {
  d <- data[indices, ]
  fs <- lm(education ~ distance + experience, data = d)
  d$v_hat <- residuals(fs)
  ss <- lm(wage ~ education + experience + v_hat, data = d)
  coef(ss)["education"]
}
boot_result <- boot(df, cf_boot, R = 999)
cat("CF estimate:", boot_result$t0, "\n")
cat("Bootstrap SE:", sd(boot_result$t), "\n")
boot.ci(boot_result, type = "perc")</span></code></pre>
            <button class="run-btn" data-lang="r">Run Code</button>
          </div>
        </div>

        <div class="output-simulation" data-output="iv-cf" data-lang="r">
          <div class="output-header"><span>R Output</span><button class="close-output">&times;</button></div>
          <div class="output-body">Call:
lm(formula = wage ~ education + experience + v_hat, data = df)

Coefficients:
             Estimate Std. Error t value Pr(>|t|)
(Intercept)   3.4567     1.2345   2.800   0.0053 **
education     0.1234     0.0456   2.706   0.0070 **
experience    0.0567     0.0123   4.610   <2e-16 ***
v_hat        -0.0823     0.0389  -2.116   0.0349 *
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Endogeneity test p-value: 0.0349
‚Üí education appears endogenous (v_hat is significant at 5%)

CF estimate: 0.1234
Bootstrap SE: 0.0512
BOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS
Based on 999 bootstrap replicates

Intervals:
Level  Percentile
95%    ( 0.0234,  0.2234 )</div>
        </div>

        <div class="info-box warning">
          <div class="info-box-title">Standard Errors in the Control Function Approach</div>
          <p>
            The naive standard errors from the two-step control function procedure are <strong>incorrect</strong> because they ignore the estimation uncertainty from the first stage. Always use <strong>bootstrap</strong> to get valid confidence intervals. The point estimate is correct, but inference without bootstrap can be misleading.
          </p>
          <p style="margin-bottom: 0;">
            <strong>Key advantage:</strong> The CF approach generalizes to nonlinear models (probit, logit, Poisson) where standard 2SLS does not apply. In a probit model, you can include the first-stage residuals as an additional regressor to handle endogeneity‚Äîsee <a href="07-estimation.html">Module 7: Estimation Methods</a> for details.
          </p>
        </div>

        <div class="citation">
          <div class="citation-title">Key IV References</div>
          <ul>
            <li><strong>Angrist, J.</strong> (1990). "Lifetime Earnings and the Vietnam Era Draft Lottery." <em>AER</em>.</li>
            <li><strong>Angrist, J. & Krueger, A.</strong> (2001). "Instrumental Variables and the Search for Identification." <em>JEP</em>.</li>
            <li><strong>Stock, J. & Yogo, M.</strong> (2005). "Testing for Weak Instruments." In <em>Identification and Inference</em>.</li>
            <li><strong>Goldsmith-Pinkham, P., Sorkin, I., & Swift, H.</strong> (2020). "Bartik Instruments: What, When, Why, and How." <em>AER</em>.</li>
            <li><strong>Borusyak, K., Hull, P., & Jaravel, X.</strong> (2022). "Quasi-Experimental Shift-Share Research Designs." <em>ReStud</em>.</li>
            <li><strong>Wooldridge, J.</strong> (2015). "Control Function Methods in Applied Econometrics." <em>Journal of Human Resources</em>.</li>
          </ul>
        </div>

        <div class="nav-footer">
          <a href="06c-rdd.html" class="nav-link prev">6C: Regression Discontinuity</a>
          <a href="06e-synthetic-control.html" class="nav-link next">6E: Synthetic Control</a>
        </div>
      </div>
    </main>
  </div>

  <button class="mobile-menu-toggle" aria-label="Toggle navigation menu">Menu</button>
  <script src="../js/main.js"></script>
  <script src="../js/grammar-primer.js"></script>
  <script src="../js/password-protection.js"></script>
</body>
</html>
