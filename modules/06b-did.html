<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>6B Difference-in-Differences | ProTools ER1</title>
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Crimson+Pro:ital,wght@0,400;0,600;0,700;1,400&family=Fira+Code:wght@400;500&family=Source+Sans+Pro:ital,wght@0,400;0,600;0,700;1,400&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="../css/style.css">
  <style>
    .protected-content { -webkit-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; }
    .protected-content pre, .protected-content code, .protected-content .code-block, .protected-content .code-tabs { -webkit-user-select: text; -moz-user-select: text; -ms-user-select: text; user-select: text; }
    .code-tooltip { position: relative; cursor: help; border-bottom: 1px dotted #888; text-decoration: none; }
    .tooltip-popup { position: fixed; background: #1f2937; color: white; padding: 0.5rem 0.75rem; border-radius: 6px; font-size: 0.75rem; white-space: normal; max-width: 300px; opacity: 0; pointer-events: none; transition: opacity 0.15s ease-in-out; z-index: 10000; }
    .tooltip-popup.visible { opacity: 1; }
  </style>
</head>
<body>
    <div id="password-overlay" class="password-overlay">
    <div class="password-modal">
      <h2>ProTools ER1</h2>
      <p>Programming Tools for Empirical Research</p>

      <div class="course-description">
        <h3>Course Modules</h3>
        <ul class="module-list">
          <li><strong>Module 0:</strong> Languages & Platforms ‚Äî Python, Stata, R setup; IDEs (RStudio, VS Code, Jupyter)</li>
          <li><strong>Module 1:</strong> Getting Started ‚Äî Installation, basic syntax, packages</li>
          <li><strong>Module 2:</strong> Data Harnessing ‚Äî File import, APIs, web scraping</li>
          <li><strong>Module 3:</strong> Data Exploration ‚Äî Inspection, summary statistics, visualization</li>
          <li><strong>Module 4:</strong> Data Cleaning ‚Äî Data quality, transformation, validation</li>
          <li><strong>Module 5:</strong> Data Analysis ‚Äî Statistical analysis, simulation, experimental design</li>
          <li><strong>Module 6:</strong> Causal Inference ‚Äî Matching, DiD, RDD, IV, Synthetic Control</li>
          <li><strong>Module 7:</strong> Estimation Methods ‚Äî Standard errors, panel data, MLE/GMM</li>
          <li><strong>Module 8:</strong> Replicability ‚Äî Project organization, documentation, replication packages</li>
          <li><strong>Module 9:</strong> Git & GitHub ‚Äî Version control, collaboration, branching</li>
          <li><strong>Module 10:</strong> History of NLP ‚Äî From ELIZA to Transformers</li>
          <li><strong>Module 11:</strong> Machine Learning ‚Äî Prediction, regularization, neural networks</li>
          <li><strong>Module 12:</strong> Large Language Models ‚Äî How LLMs work, prompting, APIs</li>
        </ul>
      </div>

      <div class="access-note">
        This course is currently open to <strong>students at Sciences Po</strong>. If you are not a Sciences Po student but would like access, please <a href="mailto:giulia.caprini@sciencespo.fr">email me</a> to request an invite token.
      </div>

      <div class="password-form">
        <input type="password" id="password-input" placeholder="Enter password" autocomplete="off">
        <button id="password-submit">Access Course</button>
        <p id="password-error" style="color: #e53e3e; font-size: 0.85rem; margin-top: 1rem; display: none;">Incorrect password. Please try again.</p>
      </div>
    </div>
  </div>

  <div class="page-wrapper protected-content">
    <aside class="sidebar">
      <a href="../index.html" class="sidebar-logo">ProTools ER1</a>
      <span class="sidebar-subtitle">Programming Tools for Empirical Research</span>
      <nav>
        <ul>
          <li><a href="../index.html"><span class="welcome-icon">üè†</span> Welcome</a></li>
          <li class="has-subnav">
            <a href="00-languages-platforms.html"><span class="module-number">0</span> Languages & Platforms</a>
            <ul class="sub-nav">
              <li><a href="00a-rstudio-guide.html">RStudio Guide</a></li>
              <li><a href="00b-stata-guide.html">Stata Guide</a></li>
              <li><a href="00c-vscode-guide.html">VS Code Guide</a></li>
              <li><a href="00d-notebooks-guide.html">Notebooks Guide</a></li>
            </ul>
          </li>
          <li><a href="01-getting-started.html"><span class="module-number">1</span> Getting Started</a></li>
          <li class="has-subnav">
            <a href="02-data-harnessing.html"><span class="module-number">2</span> Data Harnessing</a>
            <ul class="sub-nav">
              <li><a href="02a-file-import.html">File Import</a></li>
              <li><a href="02b-apis.html">APIs</a></li>
              <li><a href="02c-web-scraping.html">Web Scraping</a></li>
            </ul>
          </li>
          <li><a href="03-data-exploration.html"><span class="module-number">3</span> Data Exploration</a></li>
          <li><a href="04-data-cleaning.html"><span class="module-number">4</span> Data Cleaning</a></li>
          <li class="has-subnav">
            <a href="05-data-analysis.html"><span class="module-number">5</span> Data Analysis</a>
            <ul class="sub-nav">
              <li><a href="05a-data-simulation.html">Data Simulation</a></li>
            </ul>
          </li>
          <li class="has-subnav active">
            <a href="06-causal-inference.html"><span class="module-number">6</span> Causal Inference</a>
            <ul class="sub-nav">
              <li><a href="06a-matching.html">Matching</a></li>
              <li class="active"><a href="06b-did.html">Difference-in-Differences</a></li>
              <li><a href="06c-rdd.html">Regression Discontinuity</a></li>
              <li><a href="06d-iv.html">Instrumental Variables</a></li>
              <li><a href="06e-synthetic-control.html">Synthetic Control</a></li>
              <li><a href="05b-experiments.html">Experiments</a></li>
            </ul>
          </li>
          <li><a href="07-estimation.html"><span class="module-number">7</span> Estimation Methods</a></li>
          <li><a href="08-replicability.html"><span class="module-number">8</span> Replicability</a></li>
          <li><a href="09-github.html"><span class="module-number">9</span> Git & GitHub</a></li>
          <li class="has-subnav">
            <a href="10-nlp-history.html"><span class="module-number">10</span> History of NLP</a>
            <ul class="sub-nav">
              <li><a href="10a-text-analysis-today.html">Text Analysis Today</a></li>
            </ul>
          </li>
          <li class="has-subnav">
            <a href="11-machine-learning.html"><span class="module-number">11</span> Machine Learning</a>
            <ul class="sub-nav">
              <li><a href="11a-regularization.html">Regularization</a></li>
              <li><a href="11b-trees.html">Tree-Based Methods</a></li>
              <li><a href="11c-neural-networks.html">Neural Networks</a></li>
              <li><a href="11d-causal-ml.html">Causal ML</a></li>
              <li><a href="11e-model-evaluation.html">Model Evaluation</a></li>
            </ul>
          </li>          <li><a href="12-llms.html"><span class="module-number">12</span> Large Language Models</a></li>
          <li><a href="../resources.html">Resources</a></li>
          <li><a href="contact.html">Contact & Feedback</a></li>
        </ul>
      </nav>
    </aside>

    <main class="main-content">
      <div class="content">
        <nav class="breadcrumb" style="margin-bottom: 1rem; font-size: 0.9rem; color: #666;">
          <a href="06-causal-inference.html">6 Causal Inference</a> &raquo; Difference-in-Differences
        </nav>

        <div class="module-header">
          <h1>6B &nbsp;Difference-in-Differences</h1>
          <div class="module-meta">
            <span>~3 hours</span>
            <span>Classic, Staggered, Event Studies</span>
          </div>
        </div>

        <div class="toc">
          <h3>Table of Contents</h3>
          <ul>
            <li><a href="#classic">Classic 2x2 DiD</a></li>
            <li><a href="#twfe">Two-Way Fixed Effects</a></li>
            <li><a href="#event-study">Event Study Design</a></li>
            <li><a href="#staggered">Staggered Adoption: The Problem</a></li>
            <li><a href="#modern">Modern DiD Estimators</a></li>
            <li><a href="#comparing">Comparing Estimators</a></li>
            <li><a href="#diagnostics">Parallel Trends Diagnostics</a></li>
            <li><a href="#goodman-bacon">Goodman-Bacon Decomposition</a></li>
            <li><a href="#twfe-weights">TWFE Weight Diagnostics</a></li>
            <li><a href="#borusyak">Borusyak et al. Imputation</a></li>
            <li><a href="#fuzzy-did">Fuzzy DiD</a></li>
            <li><a href="#honest-did">HonestDiD Sensitivity</a></li>
          </ul>
        </div>

        <!-- ‚ïê‚ïê‚ïê Code Grammar Primer ‚ïê‚ïê‚ïê -->
        <section class="grammar-primer-section">
          <h2 id="code-grammar">Code Grammar</h2>
          <p>Practice the syntax patterns used in this module. In <strong>Build</strong> mode, read the descriptions and figure out the code. In <strong>Read</strong> mode, look at the code and identify what each piece does. Click cards to check your answers.</p>
          <div class="grammar-primer">
            <script type="application/json">
            {
              "exercises": [
                {
                  "instruction": "Run a classic 2x2 DiD regression with an interaction term",
                  "pattern": "model = ols('outcome ~ group + time + group*time', data).fit()",
                  "structureNote": "The DiD regression includes three terms: <strong>group</strong> (treated vs control), <strong>time</strong> (before vs after), and their <strong>interaction</strong>. The coefficient on the interaction term IS the DiD estimate: the differential change in outcomes for the treatment group after the policy.",
                  "languages": {
                    "python": [
                      {"code": "model", "role": "Variable", "tip": "Stores the fitted regression model.", "color": "pink"},
                      {"code": " = ", "role": "Assignment", "tip": "Stores the result.", "color": "peach"},
                      {"code": "smf.ols", "role": "Function", "tip": "OLS regression from statsmodels.formula.api. The formula interface lets you specify models with R-style syntax.", "color": "blue"},
                      {"code": "(", "role": "Open Paren", "tip": "Begins arguments.", "color": "overlay"},
                      {"code": "'outcome ~ treated_group + post + treat_post'", "role": "Formula", "tip": "outcome = b0 + b1*group + b2*time + b3*interaction. b3 is the DiD estimate.", "color": "green"},
                      {"code": ", data=df", "role": "Data", "tip": "The DataFrame containing all variables.", "color": "sky"},
                      {"code": ")", "role": "Close Paren", "tip": "Ends ols().", "color": "overlay"},
                      {"code": ".fit()", "role": "Fit Method", "tip": "Estimates the model. Returns a results object with coefficients, SEs, p-values.", "color": "teal"}
                    ],
                    "stata": [
                      {"code": "reg", "role": "Command", "tip": "OLS regression. Short for 'regress'.", "color": "mauve"},
                      {"code": " outcome", "role": "Dependent Var", "tip": "The outcome variable.", "color": "sky"},
                      {"code": " i.treated_group##i.post", "role": "Factor Interaction", "tip": "i. creates factor variables. ## includes main effects AND interaction. The interaction coefficient is the DiD estimate.", "color": "green"},
                      {"code": ", ", "role": "Comma", "tip": "Before options.", "color": "text"},
                      {"code": "cluster(unit_id)", "role": "Clustering", "tip": "Clusters standard errors at the unit level. Essential for panel DiD.", "color": "yellow"}
                    ],
                    "r": [
                      {"code": "did_model", "role": "Variable", "tip": "Stores the fixest regression object.", "color": "pink"},
                      {"code": " <- ", "role": "Assignment", "tip": "R's assignment.", "color": "peach"},
                      {"code": "feols", "role": "Function", "tip": "From fixest. Fast OLS with fixed effects and clustered SEs.", "color": "blue"},
                      {"code": "(outcome ~ treated_group * post", "role": "Formula", "tip": "* in R formulas includes both main effects AND the interaction. Equivalent to treated_group + post + treated_group:post.", "color": "green"},
                      {"code": ", data = df", "role": "Data", "tip": "The data frame.", "color": "sky"},
                      {"code": ", cluster = ~ unit_id", "role": "Clustering", "tip": "~ before variable name specifies the clustering level. Uses CR1 correction by default.", "color": "lavender"},
                      {"code": ")", "role": "Close Paren", "tip": "Ends the call.", "color": "overlay"}
                    ]
                  }
                },
                {
                  "instruction": "Estimate a two-way fixed effects (TWFE) DiD with unit and time fixed effects",
                  "pattern": "panel_model with entity_effects + time_effects",
                  "structureNote": "TWFE adds <strong>unit fixed effects</strong> (controlling for all time-invariant differences between units) and <strong>time fixed effects</strong> (controlling for common shocks). This is the standard panel DiD specification. The treatment coefficient captures the within-unit, within-period treatment effect.",
                  "languages": {
                    "python": [
                      {"code": "model", "role": "Variable", "tip": "The panel regression model.", "color": "pink"},
                      {"code": " = ", "role": "Assignment", "tip": "Stores the model.", "color": "peach"},
                      {"code": "PanelOLS.from_formula", "role": "Constructor", "tip": "From linearmodels.panel. Creates a panel OLS model from a formula string.", "color": "blue"},
                      {"code": "(", "role": "Open Paren", "tip": "Begins arguments.", "color": "overlay"},
                      {"code": "'outcome ~ treated + controls'", "role": "Formula", "tip": "Only time-varying regressors. Fixed effects are specified separately.", "color": "green"},
                      {"code": ", data=df", "role": "Data", "tip": "Panel data with MultiIndex (unit_id, year).", "color": "sky"},
                      {"code": ", entity_effects=True", "role": "Unit FE", "tip": "Adds unit fixed effects. Absorbs all time-invariant differences between units.", "color": "lavender"},
                      {"code": ", time_effects=True", "role": "Time FE", "tip": "Adds time fixed effects. Controls for common shocks (e.g., recessions) affecting all units.", "color": "lavender"},
                      {"code": ")", "role": "Close Paren", "tip": "Ends the model specification.", "color": "overlay"}
                    ],
                    "stata": [
                      {"code": "xtreg", "role": "Command", "tip": "Panel data regression. Requires prior xtset to declare panel structure.", "color": "mauve"},
                      {"code": " outcome treated", "role": "Variables", "tip": "Dependent variable followed by regressors.", "color": "sky"},
                      {"code": " i.year", "role": "Time FE", "tip": "i.year creates year dummies (time fixed effects). Unit FE are handled by the 'fe' option.", "color": "green"},
                      {"code": ", ", "role": "Comma", "tip": "Before options.", "color": "text"},
                      {"code": "fe", "role": "Fixed Effects", "tip": "Specifies the within (fixed effects) estimator. Absorbs unit-level fixed effects.", "color": "yellow"},
                      {"code": " cluster(unit_id)", "role": "Clustering", "tip": "Clusters standard errors at the unit level.", "color": "yellow"}
                    ],
                    "r": [
                      {"code": "twfe_model", "role": "Variable", "tip": "The TWFE model object.", "color": "pink"},
                      {"code": " <- ", "role": "Assignment", "tip": "R's assignment.", "color": "peach"},
                      {"code": "feols", "role": "Function", "tip": "fixest's workhorse function. Handles fixed effects absorption efficiently.", "color": "blue"},
                      {"code": "(outcome ~ treated", "role": "Formula", "tip": "Only include time-varying regressors before the pipe.", "color": "green"},
                      {"code": " | unit_id + year", "role": "Fixed Effects", "tip": "The | pipe separates regressors from absorbed fixed effects. unit_id = unit FE, year = time FE.", "color": "teal"},
                      {"code": ", data = df", "role": "Data", "tip": "The panel data frame.", "color": "sky"},
                      {"code": ", cluster = ~ unit_id", "role": "Clustering", "tip": "Clusters SEs at the unit level.", "color": "lavender"},
                      {"code": ")", "role": "Close Paren", "tip": "Ends the call.", "color": "overlay"}
                    ]
                  }
                },
                {
                  "instruction": "Estimate an event study with leads and lags relative to treatment",
                  "pattern": "regression with period dummies relative to treatment timing",
                  "structureNote": "An event study estimates <strong>separate treatment effects for each period</strong> relative to treatment. Pre-treatment coefficients should be near zero (parallel trends test). Post-treatment coefficients show how the effect evolves over time. One period (usually t=-1) is omitted as the reference.",
                  "languages": {
                    "python": [
                      {"code": "# Create relative time dummies", "role": "Comment", "tip": "First, create indicator variables for each period relative to treatment.", "color": "text"},
                      {"code": "\n", "role": "Newline", "tip": "Next line.", "color": "text"},
                      {"code": "for k in range(-4, 5):", "role": "Loop", "tip": "Creates dummies for periods -4 to +4 relative to treatment.", "color": "mauve"},
                      {"code": "\n    ", "role": "Indent", "tip": "Inside the loop.", "color": "text"},
                      {"code": "df[f'rel_{k}'] = (df['rel_time'] == k).astype(int)", "role": "Dummy Creation", "tip": "Creates a 0/1 indicator for each relative time period. Drop one (k=-1) as reference.", "color": "blue"},
                      {"code": "\n", "role": "Newline", "tip": "Then fit the model.", "color": "text"},
                      {"code": "model = PanelOLS.from_formula('outcome ~ ' + ' + '.join(rel_cols), data=df, entity_effects=True, time_effects=True)", "role": "Event Study Model", "tip": "Include all relative time dummies (except reference period) with unit and time fixed effects.", "color": "teal"}
                    ],
                    "stata": [
                      {"code": "reghdfe", "role": "Command", "tip": "Regression with high-dimensional fixed effects. Faster than xtreg for multiple FE levels.", "color": "mauve"},
                      {"code": " outcome", "role": "Dependent Var", "tip": "The outcome variable.", "color": "sky"},
                      {"code": " ib(-1).rel_time", "role": "Event Study Dummies", "tip": "i. creates dummies for each value of rel_time. b(-1) sets period -1 as the omitted reference.", "color": "green"},
                      {"code": ", ", "role": "Comma", "tip": "Before options.", "color": "text"},
                      {"code": "absorb(unit_id year)", "role": "Fixed Effects", "tip": "Absorbs unit and year fixed effects. More efficient than including as dummies.", "color": "yellow"},
                      {"code": " cluster(unit_id)", "role": "Clustering", "tip": "Clusters standard errors at the unit level.", "color": "yellow"}
                    ],
                    "r": [
                      {"code": "es_model", "role": "Variable", "tip": "The event study model.", "color": "pink"},
                      {"code": " <- ", "role": "Assignment", "tip": "R's assignment.", "color": "peach"},
                      {"code": "feols", "role": "Function", "tip": "fixest handles event studies natively with i() syntax.", "color": "blue"},
                      {"code": "(outcome ~ i(rel_time, ref = -1)", "role": "Formula", "tip": "i() creates treatment-time interactions. ref=-1 sets the reference period (omitted category).", "color": "green"},
                      {"code": " | unit_id + year", "role": "Fixed Effects", "tip": "Unit and time fixed effects after the pipe.", "color": "teal"},
                      {"code": ", data = df, cluster = ~ unit_id)", "role": "Data & Clustering", "tip": "Data and clustered SEs.", "color": "sky"}
                    ]
                  }
                },
                {
                  "instruction": "Create the interaction term for a DiD manually",
                  "pattern": "interaction = group_indicator * time_indicator",
                  "structureNote": "The <strong>interaction term</strong> is the product of the group indicator (1 if treated) and the time indicator (1 if post-treatment). It equals 1 only for treated units in the post period. The coefficient on this term is the DiD estimate: the causal effect under the parallel trends assumption.",
                  "languages": {
                    "python": [
                      {"code": "df", "role": "DataFrame", "tip": "Your panel dataset.", "color": "pink"},
                      {"code": "[", "role": "Open Bracket", "tip": "Column selection/creation.", "color": "overlay"},
                      {"code": "'treat_post'", "role": "New Column", "tip": "Name for the interaction term. Descriptive: treatment x post-period.", "color": "green"},
                      {"code": "]", "role": "Close Bracket", "tip": "Ends column name.", "color": "overlay"},
                      {"code": " = ", "role": "Assignment", "tip": "Creates the new column.", "color": "peach"},
                      {"code": "df['treated_group']", "role": "Group Indicator", "tip": "1 for treatment group, 0 for control. Time-invariant.", "color": "sky"},
                      {"code": " * ", "role": "Multiplication", "tip": "Element-wise multiplication. 1*1=1, 1*0=0, 0*1=0, 0*0=0.", "color": "overlay"},
                      {"code": "df['post']", "role": "Time Indicator", "tip": "1 for post-treatment period, 0 for pre-treatment. The product is 1 only for treated-post observations.", "color": "sky"}
                    ],
                    "stata": [
                      {"code": "gen", "role": "Command", "tip": "Creates a new variable.", "color": "mauve"},
                      {"code": " treat_post", "role": "Variable Name", "tip": "The interaction variable.", "color": "pink"},
                      {"code": " = ", "role": "Assignment", "tip": "Assigns the computed value.", "color": "peach"},
                      {"code": "treated_group * post", "role": "Interaction", "tip": "Product of group and time indicators. Or use ## in the regression formula to skip manual creation.", "color": "blue"}
                    ],
                    "r": [
                      {"code": "df$treat_post", "role": "New Column", "tip": "$ accesses/creates a column in the data frame.", "color": "pink"},
                      {"code": " <- ", "role": "Assignment", "tip": "R's assignment.", "color": "peach"},
                      {"code": "df$treated_group", "role": "Group Indicator", "tip": "The treatment group indicator.", "color": "sky"},
                      {"code": " * ", "role": "Multiplication", "tip": "Element-wise multiplication of the two indicators.", "color": "overlay"},
                      {"code": "df$post", "role": "Time Indicator", "tip": "Post-treatment indicator. Or just use * in the formula (R creates the interaction automatically).", "color": "sky"}
                    ]
                  }
                },
                {
                  "instruction": "Visualize an event study plot with confidence intervals",
                  "pattern": "plot coefficients with error bars by relative time",
                  "structureNote": "The event study plot is the <strong>key diagnostic</strong> for DiD. Pre-treatment coefficients near zero support parallel trends. Post-treatment coefficients show the treatment effect dynamics. Error bars (95% CIs) that cross zero indicate insignificance.",
                  "languages": {
                    "python": [
                      {"code": "coefs", "role": "Coefficients", "tip": "Extract the event study coefficients from the results object.", "color": "pink"},
                      {"code": " = results.params[rel_cols]", "role": "Extraction", "tip": "Gets the estimated coefficients for each relative time period.", "color": "teal"},
                      {"code": "\n", "role": "Newline", "tip": "Next line.", "color": "text"},
                      {"code": "ses", "role": "Std Errors", "tip": "Standard errors for constructing confidence intervals.", "color": "pink"},
                      {"code": " = results.std_errors[rel_cols]", "role": "Extraction", "tip": "Gets SEs for the same coefficients.", "color": "teal"},
                      {"code": "\n", "role": "Newline", "tip": "Next line.", "color": "text"},
                      {"code": "plt.errorbar(periods, coefs, yerr=1.96*ses, fmt='o-')", "role": "Error Bar Plot", "tip": "Plots point estimates with 95% confidence intervals. fmt='o-' = circle markers connected by lines.", "color": "blue"},
                      {"code": "\n", "role": "Newline", "tip": "Next line.", "color": "text"},
                      {"code": "plt.axhline(y=0, color='red', linestyle='--')", "role": "Zero Line", "tip": "Horizontal line at zero. Coefficients crossing this line are statistically insignificant.", "color": "blue"}
                    ],
                    "stata": [
                      {"code": "eventdd", "role": "Command", "tip": "Automates event study estimation and plotting. ssc install eventdd.", "color": "mauve"},
                      {"code": " outcome", "role": "Dependent Var", "tip": "The outcome variable.", "color": "sky"},
                      {"code": ", timevar(rel_time)", "role": "Time Variable", "tip": "The relative time variable (periods since treatment).", "color": "yellow"},
                      {"code": " method(hdfe, absorb(unit_id year))", "role": "Method", "tip": "Uses reghdfe with unit and year fixed effects.", "color": "lavender"},
                      {"code": " cluster(unit_id)", "role": "Clustering", "tip": "Clusters standard errors.", "color": "yellow"},
                      {"code": " graph", "role": "Plot Option", "tip": "Produces the event study figure automatically.", "color": "yellow"}
                    ],
                    "r": [
                      {"code": "iplot", "role": "Function", "tip": "fixest's built-in event study plotting function. Creates publication-ready plots.", "color": "blue"},
                      {"code": "(es_model", "role": "Model", "tip": "The event study model fitted with feols() and i() syntax.", "color": "pink"},
                      {"code": ", xlab = \"Periods Relative to Treatment\"", "role": "X Label", "tip": "Label for the x-axis.", "color": "green"},
                      {"code": ", main = \"Event Study\"", "role": "Title", "tip": "Plot title.", "color": "green"},
                      {"code": ")", "role": "Close Paren", "tip": "Ends the call. Automatically adds CIs and reference line at zero.", "color": "overlay"}
                    ]
                  }
                }
              ]
            }
            </script>
          </div>
        </section>

        <h2 id="classic">Classic 2x2 DiD</h2>

        <p>
          The simplest DiD compares changes in outcomes between a treatment group and control group before and after a policy change.
        </p>

        <div class="code-tabs" data-runnable="did-1">
          <div class="tab-buttons">
            <button class="tab-button active" data-lang="python">Python</button>
            <button class="tab-button" data-lang="stata">Stata</button>
            <button class="tab-button" data-lang="r">R</button>
          </div>
          <div class="tab-content active" data-lang="python">
<pre><code><span class="code-comment"># Python: Classic 2x2 DiD</span>
<span class="code-keyword">import</span> pandas <span class="code-keyword">as</span> pd
<span class="code-keyword">import</span> statsmodels.formula.api <span class="code-keyword">as</span> smf

<span class="code-comment"># Data structure: unit, time, treated_group, post, outcome</span>
<span class="code-comment"># treated_group = 1 if unit is in treatment group</span>
<span class="code-comment"># post = 1 if period is after treatment</span>

<span class="code-comment"># Create interaction term</span>
df[<span class="code-string">'treat_post'</span>] = df[<span class="code-string">'treated_group'</span>] * df[<span class="code-string">'post'</span>]

<span class="code-comment"># DiD regression</span>
<span class="code-tooltip" data-tip="The coefficient on treat_post is the DiD estimate: the treatment effect">model = smf.ols(<span class="code-string">'outcome ~ treated_group + post + treat_post'</span>, data=df).fit()
print(model.summary())</span>

<span class="code-comment"># With clustered standard errors</span>
<span class="code-tooltip" data-tip="Cluster at the unit level for panel data to account for serial correlation">model_clustered = smf.ols(<span class="code-string">'outcome ~ treated_group + post + treat_post'</span>,
                          data=df).fit(cov_type=<span class="code-string">'cluster'</span>,
                                       cov_kwds={<span class="code-string">'groups'</span>: df[<span class="code-string">'unit_id'</span>]})</span></code></pre>
            <button class="run-btn" data-lang="python">Run Code</button>
          </div>
          <div class="tab-content" data-lang="stata">
<pre><code><span class="code-comment">* Stata: Classic 2x2 DiD</span>

<span class="code-comment">* Basic DiD regression</span>
<span class="code-tooltip" data-tip="The coefficient on the interaction term (c.treated#c.post) is the DiD estimate">reg outcome i.treated_group##i.post, cluster(unit_id)</span>

<span class="code-comment">* Equivalent with manually created interaction</span>
gen treat_post = treated_group * post
reg outcome treated_group post treat_post, cluster(unit_id)

<span class="code-comment">* With controls</span>
reg outcome i.treated_group##i.post age income, cluster(unit_id)</code></pre>
            <button class="run-btn" data-lang="stata">Run Code</button>
          </div>
          <div class="tab-content" data-lang="r">
<pre><code><span class="code-comment"># R: Classic 2x2 DiD</span>
<span class="code-keyword">library</span>(fixest)

<span class="code-comment"># Basic DiD</span>
<span class="code-tooltip" data-tip="The interaction treated_group:post gives the DiD estimate">did_model <- feols(outcome ~ treated_group * post,
                   data = df,
                   cluster = ~ unit_id)</span>
summary(did_model)

<span class="code-comment"># Using lm with sandwich standard errors</span>
<span class="code-keyword">library</span>(sandwich)
<span class="code-keyword">library</span>(lmtest)
model <- lm(outcome ~ treated_group * post, data = df)
coeftest(model, vcov = vcovCL, cluster = ~ unit_id)</code></pre>
            <button class="run-btn" data-lang="r">Run Code</button>
          </div>
        </div>

        <div class="output-simulation" data-output="did-1" data-lang="python">
          <div class="output-header"><span>Python Output</span><button class="close-output">&times;</button></div>
          <div class="output-body">                            OLS Regression Results
==============================================================================
Dep. Variable:                outcome   R-squared:                       0.312
Model:                            OLS   Adj. R-squared:                  0.309
Method:                 Least Squares   F-statistic:                     89.23
Date:                Mon, 27 Jan 2026   Prob (F-statistic):           1.23e-45
Time:                        14:32:18   Log-Likelihood:                -1234.5
No. Observations:                1000   AIC:                             2477.
Df Residuals:                     996   BIC:                             2497.
Df Model:                           3
==============================================================================
                    coef    std err          t      P>|t|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept         3.2456      0.089     36.467      0.000       3.071       3.420
treated_group     0.1234      0.126      0.979      0.328      -0.124       0.371
post              0.4567      0.126      3.624      0.000       0.210       0.704
treat_post        0.5823      0.178      3.271      0.001       0.233       0.932
==============================================================================

DiD Estimate: 0.582 (SE: 0.178, p < 0.01)
Interpretation: Treatment increased outcome by 0.58 units</div>
        </div>

        <div class="output-simulation" data-output="did-1" data-lang="stata">
          <div class="output-header"><span>Stata Output</span><button class="close-output">&times;</button></div>
          <div class="output-body">Linear regression                               Number of obs     =      1,000
                                                F(3, 49)          =      42.17
                                                Prob > F          =     0.0000
                                                R-squared         =     0.3124
                                                Root MSE          =     1.2345

                             (Std. Err. adjusted for 50 clusters in unit_id)
------------------------------------------------------------------------------
             |               Robust
     outcome |      Coef.   Std. Err.      t    P>|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
1.treated_~p |   .1234567   .1456789     0.85   0.401    -.1693456    .4162590
      1.post |   .4567891   .1234567     3.70   0.001     .2085234    .7050548
             |
treated_g~p#|
       post |
        1 1 |   .5823456   .1789012     3.26   0.002     .2227890    .9419022
             |
       _cons |   3.245678   .1023456    31.71   0.000     3.039765    3.451591
------------------------------------------------------------------------------

DiD Estimate (1.treated_group#1.post): 0.582 (p = 0.002)</div>
        </div>

        <div class="output-simulation" data-output="did-1" data-lang="r">
          <div class="output-header"><span>R Output</span><button class="close-output">&times;</button></div>
          <div class="output-body">OLS estimation, Dep. Var.: outcome
Observations: 1,000
Standard-errors: Clustered (unit_id)
                        Estimate Std. Error   t value  Pr(>|t|)
(Intercept)              3.24568    0.10235   31.7134  < 2e-16 ***
treated_group            0.12346    0.14568    0.8474   0.4012
post                     0.45679    0.12346    3.6997   0.0005 ***
treated_group:post       0.58235    0.17890    3.2551   0.0020 **
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
RMSE: 1.234   Adj. R2: 0.309

DiD Estimate: 0.582
  95% CI: [0.223, 0.942]
  Interpretation: Treatment effect = 0.58 units (p = 0.002)</div>
        </div>

        <h2 id="twfe">Two-Way Fixed Effects</h2>

        <p>
          With panel data, use unit and time fixed effects to control for time-invariant unit characteristics and common time shocks.
        </p>

        <div class="code-tabs" data-runnable="did-2">
          <div class="tab-buttons">
            <button class="tab-button active" data-lang="python">Python</button>
            <button class="tab-button" data-lang="stata">Stata</button>
            <button class="tab-button" data-lang="r">R</button>
          </div>
          <div class="tab-content active" data-lang="python">
<pre><code><span class="code-comment"># Python: Two-Way Fixed Effects</span>
<span class="code-keyword">import</span> pandas <span class="code-keyword">as</span> pd
<span class="code-keyword">from</span> linearmodels.panel <span class="code-keyword">import</span> PanelOLS

<span class="code-comment"># Set panel index</span>
df = df.set_index([<span class="code-string">'unit_id'</span>, <span class="code-string">'year'</span>])

<span class="code-comment"># TWFE regression</span>
<span class="code-tooltip" data-tip="entity_effects=True adds unit FE, time_effects=True adds year FE">model = PanelOLS.from_formula(
    <span class="code-string">'outcome ~ treated + controls'</span>,
    data=df,
    entity_effects=True,
    time_effects=True
)
results = model.fit(cov_type=<span class="code-string">'clustered'</span>, cluster_entity=True)</span>
print(results.summary)</code></pre>
            <button class="run-btn" data-lang="python">Run Code</button>
          </div>
          <div class="tab-content" data-lang="stata">
<pre><code><span class="code-comment">* Stata: Two-Way Fixed Effects</span>

<span class="code-comment">* Set panel structure</span>
xtset unit_id year

<span class="code-comment">* TWFE with xtreg</span>
<span class="code-tooltip" data-tip="xtreg fe adds unit fixed effects. i.year adds time fixed effects.">xtreg outcome treated i.year, fe cluster(unit_id)</span>

<span class="code-comment">* Alternative: reghdfe (faster, more FE options)</span>
<span class="code-comment">* ssc install reghdfe</span>
<span class="code-tooltip" data-tip="reghdfe efficiently absorbs high-dimensional fixed effects">reghdfe outcome treated, absorb(unit_id year) cluster(unit_id)</span></code></pre>
            <button class="run-btn" data-lang="stata">Run Code</button>
          </div>
          <div class="tab-content" data-lang="r">
<pre><code><span class="code-comment"># R: Two-Way Fixed Effects with fixest</span>
<span class="code-keyword">library</span>(fixest)

<span class="code-comment"># TWFE regression</span>
<span class="code-tooltip" data-tip="| unit_id + year adds unit and time fixed effects">twfe_model <- feols(outcome ~ treated | unit_id + year,
                    data = df,
                    cluster = ~ unit_id)</span>
summary(twfe_model)

<span class="code-comment"># With covariates</span>
twfe_model <- feols(outcome ~ treated + age + income | unit_id + year,
                    data = df,
                    cluster = ~ unit_id)</code></pre>
            <button class="run-btn" data-lang="r">Run Code</button>
          </div>
        </div>

        <div class="output-simulation" data-output="did-2" data-lang="python">
          <div class="output-header"><span>Python Output</span><button class="close-output">&times;</button></div>
          <div class="output-body">                          PanelOLS Estimation Summary
================================================================================
Dep. Variable:                outcome   R-squared:                        0.4523
Estimator:                   PanelOLS   R-squared (Between):              0.3245
No. Observations:               5000   R-squared (Within):               0.4523
Date:                Mon, Jan 27 2026   R-squared (Overall):              0.3891
Time:                        14:35:22   Log-likelihood                   -6234.5
Cov. Estimator:             Clustered
                                        F-statistic:                      156.78
Entities:                         500   P-value                           0.0000
Avg Obs:                       10.000   Distribution:                  F(2,4498)
Min Obs:                       10.000
Max Obs:                       10.000   F-statistic (robust):             89.234
                                        P-value                           0.0000
Time periods:                      10   Distribution:                  F(2,4498)
Avg Obs:                      500.00
Min Obs:                      500.00
Max Obs:                      500.00

                             Parameter Estimates
================================================================================
            Parameter  Std. Err.     T-stat    P-value    Lower CI    Upper CI
--------------------------------------------------------------------------------
treated        0.5234     0.0912     5.7391     0.0000      0.3446      0.7022
controls       0.0345     0.0123     2.8049     0.0051      0.0104      0.0586
================================================================================

F-test for entity effects: 12.34 (p = 0.0000)
F-test for time effects: 8.91 (p = 0.0000)</div>
        </div>

        <div class="output-simulation" data-output="did-2" data-lang="stata">
          <div class="output-header"><span>Stata Output</span><button class="close-output">&times;</button></div>
          <div class="output-body">. xtset unit_id year
       panel variable:  unit_id (strongly balanced)
        time variable:  year, 2010 to 2019
                delta:  1 unit

. reghdfe outcome treated, absorb(unit_id year) cluster(unit_id)
(MWFE estimator converged in 2 iterations)

HDFE Linear regression                          Number of obs     =      5,000
Absorbing 2 HDFE groups                         F(1, 499)         =      32.89
Statistics robust to heteroskedasticity         Prob > F          =     0.0000
                                                R-squared         =     0.4523
                                                Adj R-squared     =     0.3891
                                                Within R-sq.      =     0.0234
Number of clusters (unit_id) =       500        Root MSE          =     0.8912

                           (Std. Err. adjusted for 500 clusters in unit_id)
------------------------------------------------------------------------------
             |               Robust
     outcome |      Coef.   Std. Err.      t    P>|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
     treated |   .5234123   .0912456     5.74   0.000     .3440234    .7028012
       _cons |   3.456789   .0456123    75.79   0.000     3.367123    3.546455
------------------------------------------------------------------------------

Absorbed degrees of freedom:
-----------------------------------------------------+
 Absorbed FE | Categories  - Loss  Coverage  Dups.
-------------+---------------------------------------+
     unit_id |       500       500     99.8%       0
        year |        10        10    100.0%       0
-----------------------------------------------------+</div>
        </div>

        <div class="output-simulation" data-output="did-2" data-lang="r">
          <div class="output-header"><span>R Output</span><button class="close-output">&times;</button></div>
          <div class="output-body">OLS estimation, Dep. Var.: outcome
Observations: 5,000
Fixed-effects: unit_id: 500,  year: 10
Standard-errors: Clustered (unit_id)
         Estimate Std. Error  t value   Pr(>|t|)
treated   0.52341    0.09125   5.7389  1.67e-08 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
RMSE: 0.891     Adj. R2: 0.389
               Within R2: 0.023

Wald test for joint significance of FEs:
  Unit FEs: F(499, 4490) = 12.34, p < 0.001
  Time FEs: F(9, 4490) = 8.91, p < 0.001</div>
        </div>

        <h2 id="event-study">Event Study Design</h2>

        <p>
          Event studies estimate treatment effects for each period relative to treatment, allowing you to visualize pre-trends and dynamic effects.
        </p>

        <div class="code-tabs" data-runnable="did-3">
          <div class="tab-buttons">
            <button class="tab-button active" data-lang="python">Python</button>
            <button class="tab-button" data-lang="stata">Stata</button>
            <button class="tab-button" data-lang="r">R</button>
          </div>
          <div class="tab-content active" data-lang="python">
<pre><code><span class="code-comment"># Python: Event Study</span>
<span class="code-keyword">import</span> pandas <span class="code-keyword">as</span> pd
<span class="code-keyword">import</span> numpy <span class="code-keyword">as</span> np
<span class="code-keyword">import</span> matplotlib.pyplot <span class="code-keyword">as</span> plt
<span class="code-keyword">from</span> linearmodels.panel <span class="code-keyword">import</span> PanelOLS

<span class="code-comment"># Create relative time variable</span>
<span class="code-tooltip" data-tip="rel_time = current year - year of treatment. Negative = before, positive = after.">df[<span class="code-string">'rel_time'</span>] = df[<span class="code-string">'year'</span>] - df[<span class="code-string">'treatment_year'</span>]</span>

<span class="code-comment"># Create dummies for each relative time (excluding -1 as reference)</span>
rel_time_dummies = pd.get_dummies(df[<span class="code-string">'rel_time'</span>], prefix=<span class="code-string">'rel'</span>)
rel_time_dummies = rel_time_dummies.drop(<span class="code-string">'rel_-1'</span>, axis=1)  <span class="code-comment"># reference period</span>
df = pd.concat([df, rel_time_dummies], axis=1)

<span class="code-comment"># Event study regression</span>
rel_cols = [c <span class="code-keyword">for</span> c <span class="code-keyword">in</span> df.columns <span class="code-keyword">if</span> c.startswith(<span class="code-string">'rel_'</span>)]
formula = <span class="code-string">'outcome ~ '</span> + <span class="code-string">' + '</span>.join(rel_cols)

df_panel = df.set_index([<span class="code-string">'unit_id'</span>, <span class="code-string">'year'</span>])
model = PanelOLS.from_formula(formula, data=df_panel,
                              entity_effects=True, time_effects=True)
results = model.fit(cov_type=<span class="code-string">'clustered'</span>, cluster_entity=True)

<span class="code-comment"># Plot event study coefficients</span>
<span class="code-tooltip" data-tip="Plot coefficients with 95% CIs. Pre-treatment coefficients should be near zero.">coefs = results.params[rel_cols]
ses = results.std_errors[rel_cols]

plt.figure(figsize=(10, 6))
plt.errorbar(range(len(coefs)), coefs, yerr=1.96*ses, fmt=<span class="code-string">'o'</span>, capsize=3)
plt.axhline(y=0, color=<span class="code-string">'r'</span>, linestyle=<span class="code-string">'--'</span>)
plt.axvline(x=coefs.index.get_loc(<span class="code-string">'rel_0'</span>)-0.5, color=<span class="code-string">'gray'</span>, linestyle=<span class="code-string">':'</span>)
plt.xlabel(<span class="code-string">'Periods Relative to Treatment'</span>)
plt.ylabel(<span class="code-string">'Coefficient'</span>)
plt.title(<span class="code-string">'Event Study'</span>)
plt.show()</span></code></pre>
            <button class="run-btn" data-lang="python">Run Code</button>
          </div>
          <div class="tab-content" data-lang="stata">
<pre><code><span class="code-comment">* Stata: Event Study</span>

<span class="code-comment">* Create relative time</span>
gen rel_time = year - treatment_year

<span class="code-comment">* Event study with factor variables</span>
<span class="code-tooltip" data-tip="ib(-1) sets -1 as the reference period (omitted category)">reghdfe outcome ib(-1).rel_time, absorb(unit_id year) cluster(unit_id)</span>

<span class="code-comment">* Using eventdd (event study visualization)</span>
<span class="code-comment">* ssc install eventdd</span>
<span class="code-tooltip" data-tip="eventdd automates event study estimation and produces publication-ready plots">eventdd outcome, timevar(rel_time) ///
    method(hdfe, absorb(unit_id year)) ///
    cluster(unit_id) graph</span>

<span class="code-comment">* Alternative: coefplot for manual plotting</span>
reghdfe outcome ib(-1).rel_time, absorb(unit_id year) cluster(unit_id)
coefplot, keep(*.rel_time) vertical yline(0) xline(10.5)</code></pre>
            <button class="run-btn" data-lang="stata">Run Code</button>
          </div>
          <div class="tab-content" data-lang="r">
<pre><code><span class="code-comment"># R: Event Study with fixest</span>
<span class="code-keyword">library</span>(fixest)

<span class="code-comment"># Create relative time</span>
df$rel_time <- df$year - df$treatment_year

<span class="code-comment"># Event study with i() syntax</span>
<span class="code-tooltip" data-tip="i(rel_time, ref = -1) creates dummies with -1 as reference">es_model <- feols(outcome ~ i(rel_time, ref = -1) | unit_id + year,
                  data = df,
                  cluster = ~ unit_id)</span>
summary(es_model)

<span class="code-comment"># Built-in event study plot</span>
<span class="code-tooltip" data-tip="iplot() creates publication-ready event study plots">iplot(es_model,
      xlab = "Periods Relative to Treatment",
      main = "Event Study")</span>

<span class="code-comment"># Customized plot</span>
iplot(es_model,
      ci.col = "steelblue",
      pt.pch = 19,
      grid = TRUE)</code></pre>
            <button class="run-btn" data-lang="r">Run Code</button>
          </div>
        </div>

        <div class="output-simulation" data-output="did-3" data-lang="python">
          <div class="output-header"><span>Python Output</span><button class="close-output">&times;</button></div>
          <div class="output-body">Event Study Coefficients (reference: t = -1)
============================================
Period    Coef.    Std.Err.    95% CI
------    -----    --------    ------
t-5      -0.023     0.089    [-0.198, 0.152]
t-4       0.012     0.087    [-0.159, 0.183]
t-3      -0.045     0.091    [-0.223, 0.133]
t-2       0.034     0.088    [-0.138, 0.206]
t-1       [reference period]
t=0       0.312     0.095    [ 0.126, 0.498] **
t+1       0.456     0.098    [ 0.264, 0.648] ***
t+2       0.523     0.102    [ 0.323, 0.723] ***
t+3       0.578     0.108    [ 0.366, 0.790] ***
t+4       0.612     0.115    [ 0.387, 0.837] ***
t+5       0.634     0.121    [ 0.397, 0.871] ***

Pre-trend test (H0: all pre-treatment coefs = 0):
  F(4, 4490) = 0.89, p = 0.469
  [No evidence of differential pre-trends]

[Event Study Plot displayed showing flat pre-trend, positive post-treatment effects]</div>
        </div>

        <div class="output-simulation" data-output="did-3" data-lang="stata">
          <div class="output-header"><span>Stata Output</span><button class="close-output">&times;</button></div>
          <div class="output-body">. reghdfe outcome ib(-1).rel_time, absorb(unit_id year) cluster(unit_id)

HDFE Linear regression                          Number of obs     =      5,000
Absorbing 2 HDFE groups                         F(10, 499)        =      18.23
                                                Prob > F          =     0.0000
                                                R-squared         =     0.4891
                                                Adj R-squared     =     0.4234
Number of clusters (unit_id) =       500        Root MSE          =     0.8456

                           (Std. Err. adjusted for 500 clusters in unit_id)
------------------------------------------------------------------------------
             |               Robust
     outcome |      Coef.   Std. Err.      t    P>|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
    rel_time |
         -5  |  -.0234567   .0891234    -0.26   0.793    -.1986234    .1517100
         -4  |   .0123456   .0875123     0.14   0.888    -.1596234    .1843146
         -3  |  -.0456789   .0912345    -0.50   0.617    -.2250234    .1336656
         -2  |   .0345678   .0878912     0.39   0.694    -.1381234    .2072590
         -1  |          0  (omitted)
          0  |   .3123456   .0951234     3.28   0.001     .1254234    .4992678
          1  |   .4567891   .0978123     4.67   0.000     .2646234    .6489548
          2  |   .5234567   .1023456     5.11   0.000     .3224234    .7244900
          3  |   .5789012   .1078912     5.37   0.000     .3670234    .7907790
          4  |   .6123456   .1145678     5.34   0.000     .3873234    .8373678
          5  |   .6345678   .1212345     5.23   0.000     .3964234    .8727122
             |
       _cons |   3.234567   .0567891    56.96   0.000     3.123234    3.345900
------------------------------------------------------------------------------

. testparm L(-5/-2).rel_time
 ( 1)  -5.rel_time = 0
 ( 2)  -4.rel_time = 0
 ( 3)  -3.rel_time = 0
 ( 4)  -2.rel_time = 0
       F(  4,   499) =    0.89
            Prob > F =    0.4692</div>
        </div>

        <div class="output-simulation" data-output="did-3" data-lang="r">
          <div class="output-header"><span>R Output</span><button class="close-output">&times;</button></div>
          <div class="output-body">OLS estimation, Dep. Var.: outcome
Observations: 5,000
Fixed-effects: unit_id: 500,  year: 10
Standard-errors: Clustered (unit_id)
              Estimate Std. Error   t value   Pr(>|t|)
rel_time::-5  -0.02346    0.08912   -0.2632    0.7926
rel_time::-4   0.01235    0.08751    0.1411    0.8878
rel_time::-3  -0.04568    0.09123   -0.5007    0.6168
rel_time::-2   0.03457    0.08789    0.3932    0.6943
rel_time::0    0.31235    0.09512    3.2838    0.0011 **
rel_time::1    0.45679    0.09781    4.6700    < 1e-5 ***
rel_time::2    0.52346    0.10235    5.1145    < 1e-6 ***
rel_time::3    0.57890    0.10789    5.3656    < 1e-7 ***
rel_time::4    0.61235    0.11457    5.3448    < 1e-7 ***
rel_time::5    0.63457    0.12123    5.2346    < 1e-6 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
RMSE: 0.846

Joint test of pre-treatment coefficients:
  F(4, 499) = 0.89, p = 0.469

[iplot() displays event study figure with flat pre-trends and
positive, increasing post-treatment effects]</div>
        </div>

        <h2 id="staggered">Staggered Adoption: The Problem</h2>

        <p>
          When units are treated at different times, standard TWFE can produce biased estimates because it uses already-treated units as controls. Recent econometric research has shown this can lead to wrong signs and magnitudes.
        </p>

        <div class="info-box warning">
          <div class="info-box-title">The TWFE Problem with Staggered Treatment</div>
          <p>
            Standard TWFE implicitly compares:
          </p>
          <ul>
            <li>Newly-treated vs. never-treated (good)</li>
            <li>Newly-treated vs. not-yet-treated (good)</li>
            <li>Newly-treated vs. already-treated (problematic!)</li>
          </ul>
          <p style="margin-bottom: 0;">
            The third comparison can produce negative weights, causing bias when treatment effects are heterogeneous across time or units.
          </p>
        </div>

        <h2 id="modern">Modern DiD Estimators</h2>

        <p>
          Several new estimators address the staggered treatment problem. They differ in assumptions and aggregation methods but all avoid the negative weighting issue.
        </p>

        <h3>Callaway-Sant'Anna (2021)</h3>

        <div class="code-tabs" data-runnable="did-4">
          <div class="tab-buttons">
            <button class="tab-button active" data-lang="python">Python</button>
            <button class="tab-button" data-lang="stata">Stata</button>
            <button class="tab-button" data-lang="r">R</button>
          </div>
          <div class="tab-content active" data-lang="python">
<pre><code><span class="code-comment"># Python: Callaway-Sant'Anna with csdid</span>
<span class="code-comment"># pip install csdid</span>
<span class="code-keyword">from</span> csdid <span class="code-keyword">import</span> ATTgt

<span class="code-comment"># Estimate group-time ATTs</span>
<span class="code-tooltip" data-tip="ATTgt estimates treatment effects for each cohort-time combination">att_gt = ATTgt(
    data=df,
    yname=<span class="code-string">'outcome'</span>,
    tname=<span class="code-string">'year'</span>,
    idname=<span class="code-string">'unit_id'</span>,
    gname=<span class="code-string">'first_treat'</span>,  <span class="code-comment"># year of first treatment (0 if never)</span>
    control_group=<span class="code-string">'nevertreated'</span>  <span class="code-comment"># or 'notyettreated'</span>
)</span>
results = att_gt.fit()

<span class="code-comment"># Aggregate to overall ATT</span>
agg_overall = results.aggregate(<span class="code-string">'simple'</span>)
print(agg_overall)

<span class="code-comment"># Aggregate to event-study</span>
agg_event = results.aggregate(<span class="code-string">'event'</span>)
agg_event.plot()</code></pre>
            <button class="run-btn" data-lang="python">Run Code</button>
          </div>
          <div class="tab-content" data-lang="stata">
<pre><code><span class="code-comment">* Stata: Callaway-Sant'Anna</span>
<span class="code-comment">* ssc install csdid</span>

<span class="code-comment">* Basic estimation</span>
<span class="code-tooltip" data-tip="ivar() is unit ID, time() is time, gvar() is first treatment period">csdid outcome, ivar(unit_id) time(year) gvar(first_treat)</span>

<span class="code-comment">* Aggregate to overall ATT</span>
csdid_stats simple

<span class="code-comment">* Event study aggregation</span>
csdid_stats event

<span class="code-comment">* Plot event study</span>
csdid_plot, style(rcap)</code></pre>
            <button class="run-btn" data-lang="stata">Run Code</button>
          </div>
          <div class="tab-content" data-lang="r">
<pre><code><span class="code-comment"># R: Callaway-Sant'Anna with did package</span>
<span class="code-keyword">library</span>(did)

<span class="code-comment"># Estimate group-time ATTs</span>
<span class="code-tooltip" data-tip="att_gt() estimates ATT(g,t) for each group g in period t">out <- att_gt(
  yname = "outcome",
  tname = "year",
  idname = "unit_id",
  gname = "first_treat",
  data = df,
  control_group = "nevertreated"  <span class="code-comment"># or "notyettreated"</span>
)</span>
summary(out)

<span class="code-comment"># Aggregate to simple ATT</span>
agg_simple <- aggte(out, type = "simple")
summary(agg_simple)

<span class="code-comment"># Event study aggregation</span>
agg_es <- aggte(out, type = "dynamic")
ggdid(agg_es)</code></pre>
            <button class="run-btn" data-lang="r">Run Code</button>
          </div>
        </div>

        <div class="output-simulation" data-output="did-4" data-lang="python">
          <div class="output-header"><span>Python Output</span><button class="close-output">&times;</button></div>
          <div class="output-body">Callaway-Sant'Anna (2021) Group-Time ATT Estimates
==================================================
Control Group: Never Treated
Anticipation Periods: 0
Estimation Method: Doubly Robust (DR)

Group-Time Average Treatment Effects:
-------------------------------------
 Group | Time |   ATT   |  Std.Err |   [95% CI]
-------|------|---------|----------|-------------
  2014 | 2014 |  0.298  |   0.112  | [0.078, 0.518]
  2014 | 2015 |  0.412  |   0.098  | [0.220, 0.604]
  2014 | 2016 |  0.489  |   0.105  | [0.283, 0.695]
  2015 | 2015 |  0.267  |   0.108  | [0.055, 0.479]
  2015 | 2016 |  0.378  |   0.095  | [0.192, 0.564]
  2016 | 2016 |  0.234  |   0.115  | [0.009, 0.459]

Aggregated Treatment Effects:
-----------------------------
Simple ATT: 0.346 (SE: 0.089)
  95% CI: [0.172, 0.520]
  p-value: 0.0001

[Event study plot shows cohort-specific treatment effects]</div>
        </div>

        <div class="output-simulation" data-output="did-4" data-lang="stata">
          <div class="output-header"><span>Stata Output</span><button class="close-output">&times;</button></div>
          <div class="output-body">. csdid outcome, ivar(unit_id) time(year) gvar(first_treat)

Callaway and Sant'Anna (2021)
Doubly Robust DiD Estimator

Control Group: Never Treated
------------------------------------------------------------------------------
             |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
  g2014 t2014|   .2978123   .1123456     2.65   0.008     .0776234    .5180012
  g2014 t2015|   .4123456   .0981234     4.20   0.000     .2200234    .6046678
  g2014 t2016|   .4891234   .1052345     4.65   0.000     .2828678    .6953790
  g2015 t2015|   .2671234   .1081234     2.47   0.014     .0552012    .4790456
  g2015 t2016|   .3781234   .0952345     3.97   0.000     .1914678    .5647790
  g2016 t2016|   .2341234   .1152345     2.03   0.042     .0082678    .4599790
------------------------------------------------------------------------------

. csdid_stats simple

ATT Aggregation: Simple
------------------------------------------------------------------------------
             |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
         ATT |   .3462345   .0891234     3.88   0.000     .1715567    .5209123
------------------------------------------------------------------------------

. csdid_stats event, window(-5 5)

[Event study table with coefficients for each relative time period]</div>
        </div>

        <div class="output-simulation" data-output="did-4" data-lang="r">
          <div class="output-header"><span>R Output</span><button class="close-output">&times;</button></div>
          <div class="output-body">Call:
att_gt(yname = "outcome", tname = "year", idname = "unit_id",
    gname = "first_treat", data = df, control_group = "nevertreated")

Group-Time Average Treatment Effects:
 Group Time    ATT    SE [95% Pointwise   Conf. Band]
  2014 2014 0.2978 0.1123    [0.0777, 0.5180]
  2014 2015 0.4123 0.0981    [0.2200, 0.6047]
  2014 2016 0.4891 0.1052    [0.2829, 0.6954]
  2015 2015 0.2671 0.1081    [0.0552, 0.4790]
  2015 2016 0.3781 0.0952    [0.1915, 0.5648]
  2016 2016 0.2341 0.1152    [0.0083, 0.4600]

Signif. codes: `*' confidence band does not cover 0

P-value for pre-test of parallel trends assumption:  0.523
Control Group:  Never Treated
Anticipation Periods:  0
Estimation Method:  Doubly Robust

> summary(agg_simple)

Call:
aggte(MP = out, type = "simple")

Overall ATT:
      ATT    SE     [95%   CI]
   0.3462 0.0891 [0.1716, 0.5209] *

[ggdid() displays event study plot with proper aggregation]</div>
        </div>

        <h3>de Chaisemartin-D'Haultfoeuille (2020)</h3>

        <div class="code-tabs" data-runnable="did-5">
          <div class="tab-buttons">
            <button class="tab-button active" data-lang="stata">Stata</button>
            <button class="tab-button" data-lang="r">R</button>
          </div>
          <div class="tab-content active" data-lang="stata">
<pre><code><span class="code-comment">* Stata: de Chaisemartin-D'Haultfoeuille</span>
<span class="code-comment">* ssc install did_multiplegt</span>

<span class="code-comment">* Basic estimation</span>
<span class="code-tooltip" data-tip="did_multiplegt handles binary and continuous treatments, and switching treatments">did_multiplegt outcome unit_id year treatment, ///
    robust_dynamic dynamic(5) placebo(3) ///
    cluster(unit_id) breps(100)</span>

<span class="code-comment">* With controls</span>
did_multiplegt outcome unit_id year treatment, ///
    robust_dynamic dynamic(5) placebo(3) ///
    controls(age income) cluster(unit_id)</code></pre>
            <button class="run-btn" data-lang="stata">Run Code</button>
          </div>
          <div class="tab-content" data-lang="r">
<pre><code><span class="code-comment"># R: de Chaisemartin-D'Haultfoeuille with DIDmultiplegt</span>
<span class="code-keyword">library</span>(DIDmultiplegt)

<span class="code-comment"># Basic estimation</span>
<span class="code-tooltip" data-tip="did_multiplegt handles heterogeneous effects and staggered adoption">result <- did_multiplegt(
  df = df,
  Y = "outcome",
  G = "unit_id",
  T = "year",
  D = "treatment",
  dynamic = 5,
  placebo = 3,
  cluster = "unit_id"
)</span>
summary(result)

<span class="code-comment"># Plot results</span>
did_multiplegt_plot(result)</code></pre>
            <button class="run-btn" data-lang="r">Run Code</button>
          </div>
        </div>

        <div class="output-simulation" data-output="did-5" data-lang="stata">
          <div class="output-header"><span>Stata Output</span><button class="close-output">&times;</button></div>
          <div class="output-body">. did_multiplegt outcome unit_id year treatment, ///
>     robust_dynamic dynamic(5) placebo(3) cluster(unit_id) breps(100)

de Chaisemartin and D'Haultfoeuille (2020) Estimator
Robust to heterogeneous treatment effects

Treatment is first switched on at some point during the panel

Effect at time of treatment switch-on
------------------------------------------------------------------------------
             |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
    Effect_0 |   .3123456   .0912345     3.42   0.001     .1335291    .4911621
------------------------------------------------------------------------------

Dynamic effects
------------------------------------------------------------------------------
    Effect_1 |   .4234567   .0978123     4.33   0.000     .2317478    .6151656
    Effect_2 |   .4891234   .1023456     4.78   0.000     .2885295    .6897173
    Effect_3 |   .5234567   .1089123     4.81   0.000     .3099923    .7369211
    Effect_4 |   .5567891   .1145678     4.86   0.000     .3322403    .7813379
    Effect_5 |   .5789012   .1198234     4.83   0.000     .3440516    .8137508
------------------------------------------------------------------------------

Placebo tests (pre-treatment effects should be zero)
------------------------------------------------------------------------------
  Placebo_1 |  -.0123456   .0856789    -0.14   0.885    -.1802722    .1555810
  Placebo_2 |   .0234567   .0891234     0.26   0.792    -.1512220    .1981354
  Placebo_3 |  -.0345678   .0923456    -0.37   0.708    -.2155618    .1464262
------------------------------------------------------------------------------

Joint test for placebos: chi2(3) = 0.78, p = 0.854</div>
        </div>

        <div class="output-simulation" data-output="did-5" data-lang="r">
          <div class="output-header"><span>R Output</span><button class="close-output">&times;</button></div>
          <div class="output-body">de Chaisemartin and D'Haultfoeuille (2020) Estimator
====================================================

Instantaneous effect at treatment switch-on:
  Effect_0: 0.3123 (SE: 0.0912)
    95% CI: [0.134, 0.491]
    p-value: 0.0006

Dynamic effects (periods after treatment):
  Effect | Estimate |   SE   |    95% CI
  -------|----------|--------|---------------
       1 |   0.4235 | 0.0978 | [0.232, 0.615]
       2 |   0.4891 | 0.1023 | [0.289, 0.690]
       3 |   0.5235 | 0.1089 | [0.310, 0.737]
       4 |   0.5568 | 0.1146 | [0.332, 0.781]
       5 |   0.5789 | 0.1198 | [0.344, 0.814]

Placebo tests (pre-treatment periods):
  Placebo |  Estimate |   SE   |    95% CI
  --------|-----------|--------|---------------
       -1 |   -0.0123 | 0.0857 | [-0.180, 0.156]
       -2 |    0.0235 | 0.0891 | [-0.151, 0.198]
       -3 |   -0.0346 | 0.0923 | [-0.216, 0.146]

Joint test for placebos: chi2(3) = 0.78, p = 0.854
  [No evidence against parallel trends]

[did_multiplegt_plot() shows event study figure]</div>
        </div>

        <h3>Sun-Abraham (2021)</h3>

        <div class="code-tabs" data-runnable="did-6">
          <div class="tab-buttons">
            <button class="tab-button active" data-lang="stata">Stata</button>
            <button class="tab-button" data-lang="r">R</button>
          </div>
          <div class="tab-content active" data-lang="stata">
<pre><code><span class="code-comment">* Stata: Sun-Abraham Interaction-Weighted Estimator</span>
<span class="code-comment">* ssc install eventstudyinteract</span>

<span class="code-comment">* Create cohort variable and relative time dummies</span>
gen cohort = first_treat
gen never_treat = (first_treat == 0)

<span class="code-comment">* Sun-Abraham estimator</span>
<span class="code-tooltip" data-tip="eventstudyinteract implements the interaction-weighted estimator">eventstudyinteract outcome rel_time_*, ///
    cohort(cohort) control_cohort(never_treat) ///
    absorb(unit_id year) vce(cluster unit_id)</span></code></pre>
            <button class="run-btn" data-lang="stata">Run Code</button>
          </div>
          <div class="tab-content" data-lang="r">
<pre><code><span class="code-comment"># R: Sun-Abraham with fixest</span>
<span class="code-keyword">library</span>(fixest)

<span class="code-comment"># Create cohort indicator</span>
df$cohort <- df$first_treat

<span class="code-comment"># Sun-Abraham estimator using sunab()</span>
<span class="code-tooltip" data-tip="sunab() implements Sun-Abraham within fixest's efficient framework">sa_model <- feols(outcome ~ sunab(cohort, year) | unit_id + year,
                  data = df,
                  cluster = ~ unit_id)</span>
summary(sa_model)

<span class="code-comment"># Aggregate and plot</span>
summary(sa_model, agg = "ATT")
iplot(sa_model)</code></pre>
            <button class="run-btn" data-lang="r">Run Code</button>
          </div>
        </div>

        <div class="output-simulation" data-output="did-6" data-lang="stata">
          <div class="output-header"><span>Stata Output</span><button class="close-output">&times;</button></div>
          <div class="output-body">. eventstudyinteract outcome rel_time_*, ///
>     cohort(cohort) control_cohort(never_treat) ///
>     absorb(unit_id year) vce(cluster unit_id)

Sun and Abraham (2021) Interaction-Weighted Estimator
Control cohort: never_treat

IW estimates by relative time to treatment
------------------------------------------------------------------------------
             |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
  rel_time_5 |  -.0178234   .0892345    -0.20   0.842    -.1927199    .1570731
  rel_time_4 |   .0089123   .0878912     0.10   0.919    -.1633513    .1811759
  rel_time_3 |  -.0312456   .0912345    -0.34   0.732    -.2100621    .1475709
  rel_time_2 |   .0234567   .0891234     0.26   0.792    -.1512220    .1981354
  rel_time_1 |          0  (reference)
  rel_time0  |   .2891234   .0912456     3.17   0.002     .1102853    .4679615
  rel_time1  |   .4123456   .0956789     4.31   0.000     .2248173    .5998739
  rel_time2  |   .4789123   .0998234     4.80   0.000     .2832620    .6745626
  rel_time3  |   .5234567   .1045678     5.01   0.000     .3185074    .7284060
  rel_time4  |   .5567891   .1098234     5.07   0.000     .3415391    .7720391
  rel_time5  |   .5812345   .1145678     5.07   0.000     .3566857    .8057833
------------------------------------------------------------------------------

Average ATT across all post-treatment periods: 0.4736 (SE: 0.0923)</div>
        </div>

        <div class="output-simulation" data-output="did-6" data-lang="r">
          <div class="output-header"><span>R Output</span><button class="close-output">&times;</button></div>
          <div class="output-body">OLS estimation, Dep. Var.: outcome
Observations: 5,000
Fixed-effects: unit_id: 500,  year: 10
Standard-errors: Clustered (unit_id)
Sun and Abraham (2021) estimation using cohort-specific effects

               Estimate Std. Error   t value   Pr(>|t|)
cohort::2014:-5 -0.0178    0.0892   -0.1996    0.8419
cohort::2014:-4  0.0089    0.0879    0.1014    0.9193
cohort::2014:-3 -0.0312    0.0912   -0.3426    0.7320
cohort::2014:-2  0.0235    0.0891    0.2632    0.7925
cohort::2014:0   0.2891    0.0912    3.1696    0.0016 **
cohort::2014:1   0.4123    0.0957    4.3101    < 1e-4 ***
cohort::2014:2   0.4789    0.0998    4.7978    < 1e-5 ***
cohort::2015:-4 -0.0145    0.0901   -0.1609    0.8723
...
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Aggregated ATT (average post-treatment effect):
   ATT    SE     [95%   CI]
0.4736 0.0923 [0.2927, 0.6545] ***

[iplot() shows Sun-Abraham event study with cohort-weighted estimates]</div>
        </div>

        <h3 id="comparing">Comparing All Estimators</h3>

        <p>
          A powerful robustness check is to plot multiple DiD estimators on the same figure, as in <a href="https://doi.org/10.1257/aer.20211218" target="_blank">Braghieri, Levy, and Makarin (2022)</a> on social media and mental health. If estimators disagree substantially, this signals potential heterogeneity or specification concerns.
        </p>

        <div class="info-box tip">
          <div class="info-box-title">Why Compare Estimators?</div>
          <p>Different estimators make different assumptions:</p>
          <ul style="margin-top: 0.5rem;">
            <li><strong>TWFE</strong>: Assumes homogeneous treatment effects (can be biased with staggered adoption)</li>
            <li><strong>Callaway-Sant'Anna</strong>: Uses never-treated or not-yet-treated as controls</li>
            <li><strong>Sun-Abraham</strong>: Interaction-weighted approach with cohort-specific effects</li>
            <li><strong>de Chaisemartin-D'Haultfoeuille</strong>: Robust to heterogeneous effects and switching treatments</li>
            <li><strong>Borusyak et al.</strong>: Imputation approach using only untreated observations for counterfactuals</li>
          </ul>
          <p style="margin-bottom: 0;">When all estimators agree, this strengthens your causal claims. When they diverge, investigate why.</p>
        </div>

        <div class="code-tabs" data-runnable="did-compare">
          <div class="tab-buttons">
            <button class="tab-button active" data-lang="python">Python</button>
            <button class="tab-button" data-lang="stata">Stata</button>
            <button class="tab-button" data-lang="r">R</button>
          </div>
          <div class="tab-content active" data-lang="python">
<pre><code><span class="code-comment"># Python: Multi-Estimator Comparison Plot (Braghieri et al. style)</span>
<span class="code-keyword">import</span> pandas <span class="code-keyword">as</span> pd
<span class="code-keyword">import</span> numpy <span class="code-keyword">as</span> np
<span class="code-keyword">import</span> matplotlib.pyplot <span class="code-keyword">as</span> plt
<span class="code-keyword">from</span> matplotlib.lines <span class="code-keyword">import</span> Line2D

<span class="code-comment"># After running each estimator, collect the event-study coefficients</span>
<span class="code-comment"># Example structure: dict with estimator -> (rel_time, coef, ci_lower, ci_upper)</span>

<span class="code-tooltip" data-tip="Store results from each estimator with relative time, coefficient, and confidence intervals">results = {
    <span class="code-string">'TWFE'</span>: {<span class="code-string">'rel_time'</span>: rel_times, <span class="code-string">'coef'</span>: twfe_coefs, <span class="code-string">'ci_lo'</span>: twfe_ci_lo, <span class="code-string">'ci_hi'</span>: twfe_ci_hi},
    <span class="code-string">'Callaway-Sant\'Anna'</span>: {<span class="code-string">'rel_time'</span>: rel_times, <span class="code-string">'coef'</span>: cs_coefs, <span class="code-string">'ci_lo'</span>: cs_ci_lo, <span class="code-string">'ci_hi'</span>: cs_ci_hi},
    <span class="code-string">'Sun-Abraham'</span>: {<span class="code-string">'rel_time'</span>: rel_times, <span class="code-string">'coef'</span>: sa_coefs, <span class="code-string">'ci_lo'</span>: sa_ci_lo, <span class="code-string">'ci_hi'</span>: sa_ci_hi},
    <span class="code-string">'de Chaisemartin-D\'H'</span>: {<span class="code-string">'rel_time'</span>: rel_times, <span class="code-string">'coef'</span>: dcdh_coefs, <span class="code-string">'ci_lo'</span>: dcdh_ci_lo, <span class="code-string">'ci_hi'</span>: dcdh_ci_hi},
}</span>

<span class="code-comment"># Create comparison plot</span>
<span class="code-tooltip" data-tip="Use offsets so confidence intervals don't overlap visually">fig, ax = plt.subplots(figsize=(12, 7))

colors = [<span class="code-string">'#1f77b4'</span>, <span class="code-string">'#ff7f0e'</span>, <span class="code-string">'#2ca02c'</span>, <span class="code-string">'#d62728'</span>]
markers = [<span class="code-string">'o'</span>, <span class="code-string">'s'</span>, <span class="code-string">'^'</span>, <span class="code-string">'D'</span>]
offsets = [-0.15, -0.05, 0.05, 0.15]  <span class="code-comment"># Horizontal jitter</span>

<span class="code-keyword">for</span> i, (name, data) <span class="code-keyword">in</span> enumerate(results.items()):
    x = np.array(data[<span class="code-string">'rel_time'</span>]) + offsets[i]
    y = data[<span class="code-string">'coef'</span>]
    yerr = [np.array(y) - np.array(data[<span class="code-string">'ci_lo'</span>]),
            np.array(data[<span class="code-string">'ci_hi'</span>]) - np.array(y)]

    ax.errorbar(x, y, yerr=yerr, fmt=markers[i], color=colors[i],
                capsize=3, capthick=1.5, label=name, markersize=8, linewidth=1.5)</span>

<span class="code-comment"># Add reference lines</span>
ax.axhline(y=0, color=<span class="code-string">'black'</span>, linestyle=<span class="code-string">'-'</span>, linewidth=0.8)
ax.axvline(x=-0.5, color=<span class="code-string">'gray'</span>, linestyle=<span class="code-string">'--'</span>, linewidth=1, alpha=0.7)

<span class="code-comment"># Formatting</span>
ax.set_xlabel(<span class="code-string">'Periods Relative to Treatment'</span>, fontsize=12)
ax.set_ylabel(<span class="code-string">'Treatment Effect Estimate'</span>, fontsize=12)
ax.set_title(<span class="code-string">'DiD Estimator Comparison'</span>, fontsize=14, fontweight=<span class="code-string">'bold'</span>)
ax.legend(loc=<span class="code-string">'upper left'</span>, framealpha=0.9)
ax.set_xticks(range(min(rel_times), max(rel_times)+1))

plt.tight_layout()
plt.savefig(<span class="code-string">'estimator_comparison.png'</span>, dpi=300, bbox_inches=<span class="code-string">'tight'</span>)
plt.show()</code></pre>
            <button class="run-btn" data-lang="python">Run Code</button>
          </div>
          <div class="tab-content" data-lang="stata">
<pre><code><span class="code-comment">* Stata: Multi-Estimator Comparison Plot (Braghieri et al. style)</span>
<span class="code-comment">* Run each estimator and store results, then combine in one figure</span>

<span class="code-comment">* 1. Run TWFE event study</span>
reghdfe outcome ib-1.rel_time, absorb(unit_id year) cluster(unit_id)
parmest, saving(twfe_results, replace)

<span class="code-comment">* 2. Run Callaway-Sant'Anna</span>
csdid outcome, ivar(unit_id) time(year) gvar(first_treat)
csdid_stats event
<span class="code-comment">* Export results manually or use csdid's stored matrices</span>

<span class="code-comment">* 3. Run Sun-Abraham</span>
eventstudyinteract outcome rel_time_*, cohort(cohort) ///
    control_cohort(never_treat) absorb(unit_id year) cluster(unit_id)
<span class="code-tooltip" data-tip="Store matrices e(b_iw) and e(V_iw) for Sun-Abraham coefficients">matrix sa_coef = e(b_iw)
matrix sa_var = e(V_iw)</span>

<span class="code-comment">* 4. Run de Chaisemartin-D'Haultfoeuille</span>
did_multiplegt outcome unit_id year treatment, ///
    robust_dynamic dynamic(5) placebo(3) cluster(unit_id)

<span class="code-comment">* Combine results into one dataset for plotting</span>
<span class="code-tooltip" data-tip="Create a combined dataset with estimator, rel_time, coef, ci_lo, ci_hi">clear
input str30 estimator rel_time coef ci_lo ci_hi
<span class="code-comment">* ... manually enter or append saved results ...</span>
end</span>

<span class="code-comment">* Create the comparison plot</span>
<span class="code-tooltip" data-tip="Use separate() to create different markers/colors by estimator">twoway (rcap ci_lo ci_hi rel_time if estimator=="TWFE", ///
           lcolor(navy) lwidth(medium)) ///
       (scatter coef rel_time if estimator=="TWFE", ///
           mcolor(navy) msymbol(O) msize(medium)) ///
       (rcap ci_lo ci_hi rel_time if estimator=="CS", ///
           lcolor(cranberry) lwidth(medium)) ///
       (scatter coef rel_time if estimator=="CS", ///
           mcolor(cranberry) msymbol(S) msize(medium)) ///
       (rcap ci_lo ci_hi rel_time if estimator=="SA", ///
           lcolor(forest_green) lwidth(medium)) ///
       (scatter coef rel_time if estimator=="SA", ///
           mcolor(forest_green) msymbol(T) msize(medium)) ///
       (rcap ci_lo ci_hi rel_time if estimator=="dCDH", ///
           lcolor(dkorange) lwidth(medium)) ///
       (scatter coef rel_time if estimator=="dCDH", ///
           mcolor(dkorange) msymbol(D) msize(medium)), ///
       xline(-0.5, lcolor(gray) lpattern(dash)) ///
       yline(0, lcolor(black)) ///
       legend(order(2 "TWFE" 4 "Callaway-Sant'Anna" ///
                    6 "Sun-Abraham" 8 "de Chaisemartin-D'H") ///
              rows(1) position(6)) ///
       xtitle("Periods Relative to Treatment") ///
       ytitle("Treatment Effect Estimate") ///
       title("DiD Estimator Comparison")

graph export "estimator_comparison.png", replace width(1200)</span></code></pre>
            <button class="run-btn" data-lang="stata">Run Code</button>
          </div>
          <div class="tab-content" data-lang="r">
<pre><code><span class="code-comment"># R: Multi-Estimator Comparison Plot (Braghieri et al. style)</span>
<span class="code-keyword">library</span>(tidyverse)
<span class="code-keyword">library</span>(fixest)
<span class="code-keyword">library</span>(did)

<span class="code-comment"># Run each estimator and extract event-study coefficients</span>

<span class="code-comment"># 1. TWFE</span>
twfe_model <- feols(outcome ~ i(rel_time, ref = -1) | unit_id + year,
                    data = df, cluster = ~unit_id)

<span class="code-comment"># 2. Callaway-Sant'Anna</span>
cs_out <- att_gt(yname = "outcome", tname = "year", idname = "unit_id",
                 gname = "first_treat", data = df, control_group = "nevertreated")
cs_agg <- aggte(cs_out, type = "dynamic")

<span class="code-comment"># 3. Sun-Abraham</span>
sa_model <- feols(outcome ~ sunab(first_treat, year) | unit_id + year,
                  data = df, cluster = ~unit_id)

<span class="code-comment"># Extract coefficients into a tidy data frame</span>
<span class="code-tooltip" data-tip="Create a combined data frame with all estimators for ggplot">extract_coefs <- function(model, name) {
  coefs <- coef(model)
  se <- sqrt(diag(vcov(model)))
  tibble(
    estimator = name,
    rel_time = parse_number(names(coefs)),
    coef = coefs,
    ci_lo = coefs - 1.96 * se,
    ci_hi = coefs + 1.96 * se
  )
}

all_results <- bind_rows(
  extract_coefs(twfe_model, "TWFE"),
  tibble(
    estimator = "Callaway-Sant'Anna",
    rel_time = cs_agg$egt,
    coef = cs_agg$att.egt,
    ci_lo = cs_agg$att.egt - 1.96 * cs_agg$se.egt,
    ci_hi = cs_agg$att.egt + 1.96 * cs_agg$se.egt
  ),
  extract_coefs(sa_model, "Sun-Abraham"),
  tibble(
    estimator = "Borusyak et al.",
    rel_time = did_imp_es$term,
    coef = did_imp_es$estimate,
    ci_lo = did_imp_es$conf.low,
    ci_hi = did_imp_es$conf.high
  )
)</span>

<span class="code-comment"># Create the comparison plot</span>
<span class="code-tooltip" data-tip="Use position_dodge to offset estimators horizontally so CIs don't overlap">ggplot(all_results, aes(x = rel_time, y = coef, color = estimator, shape = estimator)) +
  geom_hline(yintercept = 0, color = "black", linewidth = 0.5) +
  geom_vline(xintercept = -0.5, color = "gray", linetype = "dashed") +
  geom_errorbar(aes(ymin = ci_lo, ymax = ci_hi),
                width = 0.2, linewidth = 0.8,
                position = position_dodge(width = 0.3)) +
  geom_point(size = 3, position = position_dodge(width = 0.3)) +
  scale_color_manual(values = c("TWFE" = "#1f77b4",
                                "Callaway-Sant'Anna" = "#ff7f0e",
                                "Sun-Abraham" = "#2ca02c",
                                "de Chaisemartin-D'H" = "#d62728",
                                "Borusyak et al." = "#9467bd")) +
  scale_shape_manual(values = c("TWFE" = 16,
                                "Callaway-Sant'Anna" = 15,
                                "Sun-Abraham" = 17,
                                "de Chaisemartin-D'H" = 18,
                                "Borusyak et al." = 8)) +
  labs(x = "Periods Relative to Treatment",
       y = "Treatment Effect Estimate",
       title = "DiD Estimator Comparison",
       color = "Estimator", shape = "Estimator") +
  theme_minimal(base_size = 12) +
  theme(legend.position = "bottom",
        panel.grid.minor = element_blank())

ggsave("estimator_comparison.png", width = 10, height = 6, dpi = 300)</span></code></pre>
            <button class="run-btn" data-lang="r">Run Code</button>
          </div>
        </div>

        <div class="output-simulation" data-output="did-compare" data-lang="python">
          <div class="output-header"><span>Python Output</span><button class="close-output">&times;</button></div>
          <div class="output-body">[Figure: DiD Estimator Comparison]

A plot showing four different estimators (TWFE, Callaway-Sant'Anna,
Sun-Abraham, de Chaisemartin-D'Haultfoeuille) with their point estimates
and 95% confidence intervals across relative time periods.

Key observations:
- Pre-treatment coefficients (t < 0): All estimators show coefficients
  near zero, supporting parallel trends assumption
- Post-treatment coefficients (t ‚â• 0):
  * All estimators show positive, significant effects
  * TWFE estimates may be slightly attenuated due to negative weights
  * Modern estimators (CS, SA, dCDH) show consistent, similar magnitudes
- The agreement across estimators strengthens the causal interpretation

Saved as: estimator_comparison.png</div>
        </div>

        <div class="output-simulation" data-output="did-compare" data-lang="stata">
          <div class="output-header"><span>Stata Output</span><button class="close-output">&times;</button></div>
          <div class="output-body">[Figure: DiD Estimator Comparison]

Four estimators plotted with different colors and markers:
- Navy circles: TWFE (traditional two-way fixed effects)
- Cranberry squares: Callaway-Sant'Anna (2021)
- Forest green triangles: Sun-Abraham (2021)
- Orange diamonds: de Chaisemartin-D'Haultfoeuille (2020)

Results:
- Pre-period (t = -5 to -1): All estimators centered around zero
  with overlapping confidence intervals
- Treatment period (t = 0): Jump in estimates for all methods
- Post-period (t = 1 to 5): Persistent effects, slight divergence
  between TWFE and robust estimators

Graph saved as: estimator_comparison.png</div>
        </div>

        <div class="output-simulation" data-output="did-compare" data-lang="r">
          <div class="output-header"><span>R Output</span><button class="close-output">&times;</button></div>
          <div class="output-body">[ggplot2 Figure: DiD Estimator Comparison]

Event study plot comparing TWFE, Callaway-Sant'Anna, and Sun-Abraham estimators.

Visual summary:
- Horizontal line at y = 0 for reference
- Vertical dashed line at t = -0.5 marks treatment onset
- Position dodge prevents overlapping confidence intervals

Interpretation:
- Parallel pre-trends: Estimates at t = -5, -4, -3, -2 are
  statistically indistinguishable from zero across all estimators
- Treatment effect onset: Clear jump at t = 0
- Effect persistence: Treatment effects remain elevated through t = 5
- Estimator agreement: All three methods yield qualitatively similar
  results, though TWFE is slightly smaller in post-periods (consistent
  with attenuation bias from staggered adoption)

Saved: estimator_comparison.png (10" x 6", 300 dpi)</div>
        </div>

        <div class="citation">
          <div class="citation-title">Reference</div>
          <ul>
            <li>Braghieri, L., Levy, R., & Makarin, A. (2022). Social Media and Mental Health. <em>American Economic Review</em>, 112(11), 3660-3693. <a href="https://doi.org/10.1257/aer.20211218" target="_blank">doi:10.1257/aer.20211218</a></li>
          </ul>
        </div>

        <h2 id="diagnostics">Parallel Trends Diagnostics</h2>

        <p>
          The parallel trends assumption is untestable, but you can provide supporting evidence by checking pre-treatment trends.
        </p>

        <div class="code-tabs" data-runnable="did-7">
          <div class="tab-buttons">
            <button class="tab-button active" data-lang="python">Python</button>
            <button class="tab-button" data-lang="stata">Stata</button>
            <button class="tab-button" data-lang="r">R</button>
          </div>
          <div class="tab-content active" data-lang="python">
<pre><code><span class="code-comment"># Python: Parallel Trends Check</span>
<span class="code-keyword">import</span> matplotlib.pyplot <span class="code-keyword">as</span> plt

<span class="code-comment"># Plot mean outcomes by group over time</span>
<span class="code-tooltip" data-tip="Visual check: do treated and control groups have parallel trends before treatment?">fig, ax = plt.subplots(figsize=(10, 6))

for treated, group_df <span class="code-keyword">in</span> df.groupby(<span class="code-string">'treated_group'</span>):
    yearly_means = group_df.groupby(<span class="code-string">'year'</span>)[<span class="code-string">'outcome'</span>].mean()
    label = <span class="code-string">'Treated'</span> <span class="code-keyword">if</span> treated == 1 <span class="code-keyword">else</span> <span class="code-string">'Control'</span>
    ax.plot(yearly_means.index, yearly_means.values, marker=<span class="code-string">'o'</span>, label=label)

ax.axvline(x=treatment_year, color=<span class="code-string">'r'</span>, linestyle=<span class="code-string">'--'</span>, label=<span class="code-string">'Treatment'</span>)
ax.legend()
ax.set_xlabel(<span class="code-string">'Year'</span>)
ax.set_ylabel(<span class="code-string">'Mean Outcome'</span>)
plt.show()</span>

<span class="code-comment"># Statistical test: pre-treatment coefficients = 0</span>
<span class="code-comment"># (from event study, test joint significance of pre-treatment dummies)</span></code></pre>
            <button class="run-btn" data-lang="python">Run Code</button>
          </div>
          <div class="tab-content" data-lang="stata">
<pre><code><span class="code-comment">* Stata: Parallel Trends Diagnostics</span>

<span class="code-comment">* Visual check</span>
<span class="code-tooltip" data-tip="Plot mean outcomes for treatment and control groups over time">collapse (mean) outcome, by(year treated_group)
twoway (connected outcome year if treated_group==1) ///
       (connected outcome year if treated_group==0), ///
       xline(2015, lpattern(dash)) ///
       legend(label(1 "Treated") label(2 "Control"))</span>

<span class="code-comment">* Test pre-treatment coefficients jointly = 0</span>
reghdfe outcome ib(-1).rel_time, absorb(unit_id year) cluster(unit_id)
<span class="code-tooltip" data-tip="Test that all pre-treatment event study coefficients are jointly zero">testparm *rel_time#*  <span class="code-comment">// for negative rel_time values</span></span>

<span class="code-comment">* Placebo test: fake treatment timing</span>
gen fake_post = (year >= 2013)  <span class="code-comment">// true treatment in 2015</span>
gen fake_treat_post = treated_group * fake_post
reg outcome treated_group fake_post fake_treat_post if year < 2015</code></pre>
            <button class="run-btn" data-lang="stata">Run Code</button>
          </div>
          <div class="tab-content" data-lang="r">
<pre><code><span class="code-comment"># R: Parallel Trends Diagnostics</span>
<span class="code-keyword">library</span>(ggplot2)
<span class="code-keyword">library</span>(dplyr)

<span class="code-comment"># Visual check</span>
<span class="code-tooltip" data-tip="Plot mean outcomes for treatment and control groups over time">df %>%
  group_by(year, treated_group) %>%
  summarise(mean_outcome = mean(outcome)) %>%
  ggplot(aes(x = year, y = mean_outcome, color = factor(treated_group))) +
  geom_line() +
  geom_point() +
  geom_vline(xintercept = 2015, linetype = "dashed") +
  labs(color = "Group", y = "Mean Outcome")</span>

<span class="code-comment"># Test pre-treatment coefficients</span>
es_model <- feols(outcome ~ i(rel_time, ref = -1) | unit_id + year,
                  data = df, cluster = ~ unit_id)

<span class="code-comment"># F-test for pre-treatment coefficients = 0</span>
<span class="code-tooltip" data-tip="wald() tests joint significance of pre-treatment coefficients">pretreat_coefs <- grep("rel_time::-", names(coef(es_model)), value = TRUE)
wald(es_model, pretreat_coefs)</span></code></pre>
            <button class="run-btn" data-lang="r">Run Code</button>
          </div>
        </div>

        <div class="output-simulation" data-output="did-7" data-lang="python">
          <div class="output-header"><span>Python Output</span><button class="close-output">&times;</button></div>
          <div class="output-body">Parallel Trends Diagnostic
==========================

Mean Outcomes by Group and Year:
       Treated    Control    Difference
2010     3.12       3.08        0.04
2011     3.25       3.21        0.04
2012     3.38       3.33        0.05
2013     3.51       3.47        0.04
2014     3.64       3.59        0.05
-------- TREATMENT (2015) --------
2015     4.21       3.72        0.49
2016     4.35       3.84        0.51
2017     4.48       3.96        0.52
2018     4.61       4.09        0.52
2019     4.73       4.21        0.52

Pre-treatment difference is stable (~0.04-0.05)
Post-treatment gap widens to ~0.50

Joint test of pre-treatment coefficients:
  F(4, 495) = 0.76
  p-value = 0.552
  Conclusion: Cannot reject parallel pre-trends

[Plot shows parallel lines pre-2015, diverging after treatment]</div>
        </div>

        <div class="output-simulation" data-output="did-7" data-lang="stata">
          <div class="output-header"><span>Stata Output</span><button class="close-output">&times;</button></div>
          <div class="output-body">. testparm L(-5/-2).rel_time

 ( 1)  -5.rel_time = 0
 ( 2)  -4.rel_time = 0
 ( 3)  -3.rel_time = 0
 ( 4)  -2.rel_time = 0

       F(  4,   499) =    0.76
            Prob > F =    0.5523

Conclusion: Cannot reject H0 that all pre-treatment coefficients = 0
            This supports (but does not prove) parallel trends

. reg outcome treated_group fake_post fake_treat_post if year < 2015

      Source |       SS           df       MS      Number of obs   =     2,500
-------------+----------------------------------   F(3, 2496)      =      0.89
       Model |   2.34567891         3  .781892970   Prob > F        =    0.4456
    Residual |   2189.12345     2,496  .877244171   R-squared       =    0.0011
-------------+----------------------------------   Adj R-squared   =    -0.0001
       Total |   2191.46913     2,499  .876939227   Root MSE        =    .93662

------------------------------------------------------------------------------
     outcome |      Coef.   Std. Err.      t    P>|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
treated_gr~p |   .0412345   .0456789     0.90   0.367    -.0483456    .1308146
   fake_post |   .1234567   .0478912     2.58   0.010     .0295234    .2173900
fake_treat~t |   .0078912   .0567891     0.14   0.889    -.1034567    .1192391
       _cons |   3.123456   .0345678    90.35   0.000     3.055678    3.191234
------------------------------------------------------------------------------

Placebo DiD estimate: 0.008 (p = 0.889)
  [No spurious "effect" in pre-treatment period]</div>
        </div>

        <div class="output-simulation" data-output="did-7" data-lang="r">
          <div class="output-header"><span>R Output</span><button class="close-output">&times;</button></div>
          <div class="output-body"># Visual inspection shows parallel pre-trends
# (Plot displayed with parallel lines before treatment year)

Wald test for joint significance of pre-treatment coefficients:
  H0: All pre-treatment coefficients = 0

  Tested coefficients:
    rel_time::-5, rel_time::-4, rel_time::-3, rel_time::-2

  Wald stat: 3.04 on 4 df
  p-value: 0.5510

  Conclusion: Cannot reject H0 (parallel trends assumption supported)

Note: This test has limited power. Even with p > 0.05:
  - Parallel trends could be violated
  - Small violations may be economically meaningful
  - Consider sensitivity analysis (Rambachan & Roth, 2023)

Pre-treatment coefficient magnitudes:
  All coefficients < 0.05 in absolute value
  All 95% CIs include zero
  No evidence of differential pre-trends</div>
        </div>

        <!-- ============================================================ -->
        <!-- SECTION 1: Goodman-Bacon Decomposition                       -->
        <!-- ============================================================ -->

        <h2 id="goodman-bacon">Goodman-Bacon Decomposition</h2>

        <p>
          TWFE DiD with staggered adoption is a weighted average of all possible 2&times;2 DiD comparisons. Goodman-Bacon (2021) decomposes the TWFE estimate into three types of comparisons: (1) earlier-treated vs. later-treated, (2) later-treated vs. earlier-treated, and (3) treated vs. never-treated. The problematic comparisons are those that use already-treated units as controls. Visualizing the weights vs. estimates by comparison type reveals whether bias is likely.
        </p>

        <div class="code-tabs" data-runnable="did-bacon">
          <div class="tab-buttons">
            <button class="tab-button active" data-lang="python">Python</button>
            <button class="tab-button" data-lang="stata">Stata</button>
            <button class="tab-button" data-lang="r">R</button>
          </div>
          <div class="tab-content active" data-lang="python">
<pre><code><span class="code-comment"># Python: No direct package, but can implement manually</span>
<span class="code-comment"># or use R via rpy2. Conceptual implementation:</span>
<span class="code-keyword">import</span> pandas <span class="code-keyword">as</span> pd
<span class="code-keyword">import</span> numpy <span class="code-keyword">as</span> np
<span class="code-keyword">import</span> matplotlib.pyplot <span class="code-keyword">as</span> plt

<span class="code-comment"># Get unique treatment cohorts</span>
<span class="code-tooltip" data-tip="Identify the year each unit was first treated to define cohorts">cohorts = df[df[<span class="code-string">'treatment'</span>] == 1].groupby(<span class="code-string">'unit_id'</span>)[<span class="code-string">'year'</span>].min().unique()</span>

<span class="code-comment"># For each pair of cohorts, compute 2x2 DiD</span>
<span class="code-comment"># (Simplified ‚Äî full implementation requires careful timing)</span>
<span class="code-comment"># In practice, use R's bacondecomp or Stata's bacondecomp</span>

<span class="code-comment"># Visualization of results (after computing in R/Stata)</span>
<span class="code-comment"># bacon_df = pd.read_csv('bacon_decomposition.csv')</span>
<span class="code-comment"># plt.scatter(bacon_df['weight'], bacon_df['estimate'],</span>
<span class="code-comment">#             c=bacon_df['type'].map(color_map))</span>
<span class="code-comment"># plt.xlabel('Weight'); plt.ylabel('2x2 DiD Estimate')</span>
<span class="code-comment"># plt.axhline(y=0, linestyle='--', color='gray')</span>
<span class="code-comment"># plt.title('Goodman-Bacon Decomposition')</span>
<span class="code-comment"># plt.show()</span></code></pre>
            <button class="run-btn" data-lang="python">Run Code</button>
          </div>
          <div class="tab-content" data-lang="stata">
<pre><code><span class="code-comment">* Install: ssc install bacondecomp</span>
<span class="code-comment">* Goodman-Bacon decomposition</span>
<span class="code-tooltip" data-tip="Decomposes the TWFE DiD estimate into all 2x2 comparisons with weights">bacondecomp outcome treatment, id(unit_id) time(year)</span>

<span class="code-comment">* The command automatically produces:</span>
<span class="code-comment">* - Table with 2x2 estimates, weights, and comparison types</span>
<span class="code-comment">* - Scatter plot of weight vs estimate</span></code></pre>
            <button class="run-btn" data-lang="stata">Run Code</button>
          </div>
          <div class="tab-content" data-lang="r">
<pre><code><span class="code-keyword">library</span>(bacondecomp)
<span class="code-comment"># Goodman-Bacon decomposition of TWFE</span>
<span class="code-tooltip" data-tip="Decomposes the overall TWFE estimate into weighted 2x2 DiD comparisons">bacon_out <- <span class="code-function">bacon</span>(outcome ~ treatment, data = df,
                   id_var = <span class="code-string">"unit_id"</span>, time_var = <span class="code-string">"year"</span>)</span>
<span class="code-comment"># View decomposition</span>
print(bacon_out)

<span class="code-comment"># Visualization: weight vs estimate by comparison type</span>
<span class="code-keyword">library</span>(ggplot2)
<span class="code-function">ggplot</span>(bacon_out, <span class="code-function">aes</span>(x = weight, y = estimate,
                       shape = type, color = type)) +
  <span class="code-function">geom_point</span>(size = 3) +
  <span class="code-function">geom_hline</span>(yintercept = 0, linetype = <span class="code-string">"dashed"</span>) +
  <span class="code-function">labs</span>(x = <span class="code-string">"Weight"</span>, y = <span class="code-string">"2x2 DiD Estimate"</span>,
       title = <span class="code-string">"Goodman-Bacon Decomposition"</span>,
       color = <span class="code-string">"Comparison Type"</span>, shape = <span class="code-string">"Comparison Type"</span>) +
  <span class="code-function">theme_minimal</span>()

<span class="code-comment"># Weighted average = TWFE coefficient</span>
cat(<span class="code-string">"TWFE estimate:"</span>, <span class="code-function">sum</span>(bacon_out$estimate * bacon_out$weight), <span class="code-string">"\n"</span>)</code></pre>
            <button class="run-btn" data-lang="r">Run Code</button>
          </div>
        </div>

        <div class="output-simulation" data-output="did-bacon" data-lang="python">
          <div class="output-header"><span>Python Output</span><button class="close-output">&times;</button></div>
          <div class="output-body">Goodman-Bacon Decomposition (conceptual output)
=================================================

Note: Use R's bacondecomp or Stata's bacondecomp for full results.
Python implementation requires manual computation of all 2x2 DiD pairs.

Treatment cohorts identified: [2012, 2014, 2016]
Number of 2x2 comparisons: 6

[Scatter plot: Weight (x-axis) vs. 2x2 DiD Estimate (y-axis)
 - Blue triangles: Treated vs. Never-Treated (large weights, positive estimates)
 - Red circles: Earlier vs. Later Treated (moderate weights, positive estimates)
 - Orange squares: Later vs. Earlier Treated (small weights, negative estimates)
 - Dashed horizontal line at y=0]</div>
        </div>

        <div class="output-simulation" data-output="did-bacon" data-lang="stata">
          <div class="output-header"><span>Stata Output</span><button class="close-output">&times;</button></div>
          <div class="output-body">. bacondecomp outcome treatment, id(unit_id) time(year)

Bacon Decomposition
====================

Overall TWFE estimate:  0.4523

----------------------------------------------------------------------
                  Type         |   Estimate     Weight     Wt. Avg.
-------------------------------+--------------------------------------
 Treated vs Never Treated      |    0.5823      0.6120      0.3564
 Earlier Treated vs Later (T)  |    0.3456      0.2340      0.0809
 Later Treated vs Earlier (T)  |   -0.1234      0.1540     -0.0190
-------------------------------+--------------------------------------
                        Total  |                1.0000      0.4183

Note: TWFE estimate (0.4523) is close to the weighted average (0.4183).
      Later-vs-Earlier comparisons produce negative estimates,
      indicating already-treated units are poor controls.

[Scatter plot displayed: Weight vs 2x2 DiD Estimate by comparison type]</div>
        </div>

        <div class="output-simulation" data-output="did-bacon" data-lang="r">
          <div class="output-header"><span>R Output</span><button class="close-output">&times;</button></div>
          <div class="output-body">           type                   estimate     weight
1  Treated vs Never Treated        0.58235    0.61200
2  Earlier vs Later Treated        0.34561    0.23400
3  Later vs Earlier Treated       -0.12340    0.15400

TWFE estimate: 0.4523

[ggplot scatter: Weight (x) vs 2x2 DiD Estimate (y)
 Points colored by comparison type:
 - "Treated vs Never Treated": blue, largest weights (~0.6), positive estimates
 - "Earlier vs Later Treated": green, moderate weights (~0.2), positive estimates
 - "Later vs Earlier Treated": red, small weights (~0.15), negative estimates
 Dashed horizontal line at y = 0]

Note: The negative estimate for "Later vs Earlier" comparisons
reveals that already-treated units are contaminated controls.</div>
        </div>

        <div class="citation">
          <div class="citation-title">Reference</div>
          <ul>
            <li>Goodman-Bacon, A. (2021). "Difference-in-Differences with Variation in Treatment Timing." <em>Journal of Econometrics</em>, 225(2), 254-277.</li>
          </ul>
        </div>

        <!-- ============================================================ -->
        <!-- SECTION 2: TWFE Weight Diagnostics                           -->
        <!-- ============================================================ -->

        <h2 id="twfe-weights">TWFE Weight Diagnostics</h2>

        <p>
          de Chaisemartin &amp; D'Haultfoeuille (2020) show that TWFE weights can be negative. When weights are negative and treatment effects are heterogeneous, TWFE can be severely biased&mdash;even producing wrong signs. The <code>twowayfeweights</code> command computes and visualizes these weights. If many weights are negative, use robust estimators instead.
        </p>

        <div class="code-tabs" data-runnable="did-weights">
          <div class="tab-buttons">
            <button class="tab-button active" data-lang="python">Python</button>
            <button class="tab-button" data-lang="stata">Stata</button>
            <button class="tab-button" data-lang="r">R</button>
          </div>
          <div class="tab-content active" data-lang="python">
<pre><code><span class="code-comment"># Python: Use R via rpy2 or implement manually</span>
<span class="code-comment"># The key insight is computing the regression weights</span>
<span class="code-comment"># from the TWFE regression and checking for negatives</span>

<span class="code-comment"># Conceptual check using fixest residualization</span>
<span class="code-keyword">import</span> statsmodels.api <span class="code-keyword">as</span> sm

<span class="code-comment"># Demean by unit and time (TWFE residualization)</span>
<span class="code-tooltip" data-tip="TWFE is equivalent to OLS on demeaned data; the implicit weights on each observation can be negative">df[<span class="code-string">'outcome_dm'</span>] = df.groupby(<span class="code-string">'unit_id'</span>)[<span class="code-string">'outcome'</span>].transform(<span class="code-string">'demean'</span>)
df[<span class="code-string">'outcome_dm'</span>] -= df.groupby(<span class="code-string">'year'</span>)[<span class="code-string">'outcome_dm'</span>].transform(<span class="code-string">'mean'</span>)
df[<span class="code-string">'treatment_dm'</span>] = df.groupby(<span class="code-string">'unit_id'</span>)[<span class="code-string">'treatment'</span>].transform(<span class="code-string">'demean'</span>)
df[<span class="code-string">'treatment_dm'</span>] -= df.groupby(<span class="code-string">'year'</span>)[<span class="code-string">'treatment_dm'</span>].transform(<span class="code-string">'mean'</span>)</span>

<span class="code-comment"># The implicit weight on each observation is proportional to treatment_dm</span>
<span class="code-comment"># Negative treatment_dm for treated observations ‚Üí negative weights</span>
print(<span class="code-string">"Observations with negative implicit weights:"</span>,
      (df.loc[df[<span class="code-string">'treatment'</span>]==1, <span class="code-string">'treatment_dm'</span>] &lt; 0).sum())</code></pre>
            <button class="run-btn" data-lang="python">Run Code</button>
          </div>
          <div class="tab-content" data-lang="stata">
<pre><code><span class="code-comment">* Install: ssc install twowayfeweights</span>
<span class="code-comment">* Compute TWFE weights</span>
<span class="code-tooltip" data-tip="Reports the number and sum of negative weights in the TWFE regression">twowayfeweights outcome unit_id year treatment, type(feTR)</span>

<span class="code-comment">* The command reports:</span>
<span class="code-comment">* - Number of positive and negative weights</span>
<span class="code-comment">* - Sum of negative weights (measure of potential bias)</span>
<span class="code-comment">* - Under what assumptions TWFE is valid</span>

<span class="code-comment">* With sensitivity analysis</span>
twowayfeweights outcome unit_id year treatment, type(feTR) ///
    summary_measures</code></pre>
            <button class="run-btn" data-lang="stata">Run Code</button>
          </div>
          <div class="tab-content" data-lang="r">
<pre><code><span class="code-keyword">library</span>(TwoWayFEWeights)
<span class="code-comment"># Compute TWFE weights</span>
<span class="code-tooltip" data-tip="Computes the weights that TWFE implicitly assigns to each group-time cell">weights_out <- <span class="code-function">twowayfeweights</span>(df, <span class="code-string">"outcome"</span>, <span class="code-string">"unit_id"</span>, <span class="code-string">"year"</span>, <span class="code-string">"treatment"</span>,
                                type = <span class="code-string">"feTR"</span>)</span>
<span class="code-function">summary</span>(weights_out)

<span class="code-comment"># Check for negative weights</span>
neg_weights <- weights_out$weights[weights_out$weights &lt; 0]
cat(<span class="code-string">"Number of negative weights:"</span>, <span class="code-function">length</span>(neg_weights), <span class="code-string">"\n"</span>)
cat(<span class="code-string">"Sum of negative weights:"</span>, <span class="code-function">sum</span>(neg_weights), <span class="code-string">"\n"</span>)

<span class="code-comment"># Histogram of weights</span>
<span class="code-function">hist</span>(weights_out$weights, breaks = 30, main = <span class="code-string">"TWFE Weights Distribution"</span>,
     xlab = <span class="code-string">"Weight"</span>, col = <span class="code-function">ifelse</span>(weights_out$weights &lt; 0, <span class="code-string">"red"</span>, <span class="code-string">"steelblue"</span>))
<span class="code-function">abline</span>(v = 0, lty = 2, lwd = 2)</code></pre>
            <button class="run-btn" data-lang="r">Run Code</button>
          </div>
        </div>

        <div class="output-simulation" data-output="did-weights" data-lang="python">
          <div class="output-header"><span>Python Output</span><button class="close-output">&times;</button></div>
          <div class="output-body">TWFE Weight Diagnostics (conceptual implementation)
=====================================================

Demeaning outcome and treatment by unit and time fixed effects...

Observations with negative implicit weights: 47

Among 250 treated observations:
  Positive implicit weights: 203 (81.2%)
  Negative implicit weights:  47 (18.8%)

Warning: 18.8% of treated observations receive negative weight.
With heterogeneous treatment effects, TWFE may be biased.
Consider using robust estimators (Callaway-Sant'Anna, Sun-Abraham, etc.)</div>
        </div>

        <div class="output-simulation" data-output="did-weights" data-lang="stata">
          <div class="output-header"><span>Stata Output</span><button class="close-output">&times;</button></div>
          <div class="output-body">. twowayfeweights outcome unit_id year treatment, type(feTR)

Under the common trends assumption, beta estimates a weighted sum of
250 ATTs.

  Positive weights: 203 weights summing to 1.1834
  Negative weights:  47 weights summing to -0.1834

  Total weight:     1.0000

  Minimal value of beta under common trends:     0.2345
  Maximal value of beta under common trends:     0.7891

The TWFE coefficient could be anywhere between [0.23, 0.79] depending
on the pattern of treatment effect heterogeneity.

Warning: Negative weights detected. If treatment effects are heterogeneous,
the TWFE coefficient may not be a consistent estimate of any
meaningful causal parameter.</div>
        </div>

        <div class="output-simulation" data-output="did-weights" data-lang="r">
          <div class="output-header"><span>R Output</span><button class="close-output">&times;</button></div>
          <div class="output-body">Two-Way FE Weights Analysis
============================

Number of group-time cells: 60
  Positive weights: 48 (sum = 1.1834)
  Negative weights: 12 (sum = -0.1834)

Number of negative weights: 12
Sum of negative weights: -0.1834

[Histogram: TWFE Weights Distribution
 - Blue bars: positive weights (majority, right of zero)
 - Red bars: negative weights (12 cells, left of zero)
 - Dashed vertical line at weight = 0
 - Most weights concentrated between 0 and 0.05
 - Negative weights range from -0.04 to -0.01]

Interpretation: 20% of group-time cells receive negative weight.
TWFE may be biased with heterogeneous effects.</div>
        </div>

        <div class="info-box warning">
          <div class="info-box-title">When to Abandon TWFE</div>
          <p style="margin-bottom: 0;">
            If a substantial fraction of weights are negative, do NOT rely on TWFE. Use one of the robust estimators covered in this module instead.
          </p>
        </div>

        <!-- ============================================================ -->
        <!-- SECTION 3: Borusyak et al. Imputation                       -->
        <!-- ============================================================ -->

        <h2 id="borusyak">Borusyak et al. Imputation Estimator</h2>

        <p>
          Borusyak, Jaravel &amp; Spiess (2024) propose an imputation approach: (1) estimate the unit FE + time FE model using ONLY untreated observations, (2) impute counterfactual outcomes for treated observations, (3) the treatment effect is the difference between actual and imputed outcomes. This avoids the negative weighting problem entirely.
        </p>

        <div class="code-tabs" data-runnable="did-borusyak">
          <div class="tab-buttons">
            <button class="tab-button active" data-lang="python">Python</button>
            <button class="tab-button" data-lang="stata">Stata</button>
            <button class="tab-button" data-lang="r">R</button>
          </div>
          <div class="tab-content active" data-lang="python">
<pre><code><span class="code-comment"># Python: No direct package yet</span>
<span class="code-comment"># Conceptual implementation of the imputation approach:</span>
<span class="code-keyword">import</span> statsmodels.api <span class="code-keyword">as</span> sm
<span class="code-keyword">import</span> pandas <span class="code-keyword">as</span> pd

<span class="code-comment"># Step 1: Estimate FE model on untreated observations only</span>
<span class="code-tooltip" data-tip="Only untreated obs are used to estimate the fixed effects model ‚Äî this avoids contamination from treatment">untreated = df[df[<span class="code-string">'treatment'</span>] == 0]</span>
<span class="code-comment"># Add unit and time dummies</span>
untreated_dummies = pd.<span class="code-function">get_dummies</span>(untreated[[<span class="code-string">'unit_id'</span>, <span class="code-string">'year'</span>]],
                                     columns=[<span class="code-string">'unit_id'</span>, <span class="code-string">'year'</span>])
model_untreated = sm.<span class="code-function">OLS</span>(untreated[<span class="code-string">'outcome'</span>], untreated_dummies).<span class="code-function">fit</span>()

<span class="code-comment"># Step 2: Predict counterfactual for treated observations</span>
treated = df[df[<span class="code-string">'treatment'</span>] == 1]
treated_dummies = pd.<span class="code-function">get_dummies</span>(treated[[<span class="code-string">'unit_id'</span>, <span class="code-string">'year'</span>]],
                                   columns=[<span class="code-string">'unit_id'</span>, <span class="code-string">'year'</span>])
<span class="code-comment"># Align columns</span>
treated_dummies = treated_dummies.<span class="code-function">reindex</span>(columns=untreated_dummies.columns, fill_value=0)
<span class="code-tooltip" data-tip="Impute Y(0) for treated units using the model estimated on untreated data">y0_hat = model_untreated.<span class="code-function">predict</span>(treated_dummies)</span>

<span class="code-comment"># Step 3: ATT = mean(Y1 - Y0_hat)</span>
att = (treated[<span class="code-string">'outcome'</span>].values - y0_hat).mean()
print(<span class="code-keyword">f</span><span class="code-string">"Imputation ATT: {att:.4f}"</span>)

<span class="code-comment"># In practice, use R's didimputation or Stata's did_imputation</span></code></pre>
            <button class="run-btn" data-lang="python">Run Code</button>
          </div>
          <div class="tab-content" data-lang="stata">
<pre><code><span class="code-comment">* Install: ssc install did_imputation</span>
<span class="code-comment">* Borusyak et al. imputation estimator</span>

<span class="code-comment">* Static ATT</span>
<span class="code-tooltip" data-tip="Imputes Y(0) for treated obs from a FE model on untreated obs only">did_imputation outcome unit_id year first_treated, allhorizons pretrends(5)</span>

<span class="code-comment">* Event study</span>
did_imputation outcome unit_id year first_treated, ///
    horizons(0/5) pretrends(5)

<span class="code-comment">* The command reports ATT by horizon (event time)</span>
<span class="code-comment">* with standard errors clustered at unit level</span></code></pre>
            <button class="run-btn" data-lang="stata">Run Code</button>
          </div>
          <div class="tab-content" data-lang="r">
<pre><code><span class="code-keyword">library</span>(didimputation)
<span class="code-comment"># Borusyak et al. imputation estimator</span>
<span class="code-comment"># Static ATT</span>
<span class="code-tooltip" data-tip="Estimates Y(0) from untreated data, then computes ATT as actual minus imputed">did_imp <- <span class="code-function">did_imputation</span>(data = df, yname = <span class="code-string">"outcome"</span>,
                           gname = <span class="code-string">"first_treated"</span>,  <span class="code-comment"># cohort indicator</span>
                           tname = <span class="code-string">"year"</span>, idname = <span class="code-string">"unit_id"</span>)</span>
<span class="code-function">summary</span>(did_imp)

<span class="code-comment"># Event study with pre-trends</span>
did_imp_es <- <span class="code-function">did_imputation</span>(data = df, yname = <span class="code-string">"outcome"</span>,
                              gname = <span class="code-string">"first_treated"</span>,
                              tname = <span class="code-string">"year"</span>, idname = <span class="code-string">"unit_id"</span>,
                              horizon = TRUE, pretrends = TRUE)
<span class="code-function">summary</span>(did_imp_es)

<span class="code-comment"># Plot event study</span>
<span class="code-keyword">library</span>(ggplot2)
<span class="code-function">plot</span>(did_imp_es)  <span class="code-comment"># built-in plotting method</span></code></pre>
            <button class="run-btn" data-lang="r">Run Code</button>
          </div>
        </div>

        <div class="output-simulation" data-output="did-borusyak" data-lang="python">
          <div class="output-header"><span>Python Output</span><button class="close-output">&times;</button></div>
          <div class="output-body">Borusyak et al. Imputation Estimator (conceptual)
===================================================

Step 1: FE model estimated on 3,750 untreated observations
  Unit FEs: 50 units
  Time FEs: 10 periods
  R-squared (within): 0.891

Step 2: Counterfactual Y(0) imputed for 1,250 treated observations

Step 3: Treatment effect = Actual - Imputed
  Imputation ATT: 0.5734

In practice, use R's didimputation or Stata's did_imputation
for proper standard errors and event-study decomposition.</div>
        </div>

        <div class="output-simulation" data-output="did-borusyak" data-lang="stata">
          <div class="output-header"><span>Stata Output</span><button class="close-output">&times;</button></div>
          <div class="output-body">. did_imputation outcome unit_id year first_treated, allhorizons pretrends(5)

did_imputation: Borusyak, Jaravel, and Spiess (2024)
=====================================================

ATT by horizon (event time):
----------------------------------------------------------------------
     Horizon |   Estimate    Std. Err.      t     P>|t|     [95% CI]
-------------+--------------------------------------------------------
          -5 |   -0.0123      0.0456    -0.27     0.787    -.102  .077
          -4 |    0.0089      0.0423     0.21     0.834    -.074  .092
          -3 |   -0.0234      0.0478    -0.49     0.625    -.117  .071
          -2 |    0.0156      0.0412     0.38     0.705    -.065  .097
          -1 |    0.0000      (ref)        .         .        .     .
           0 |    0.4567      0.0789     5.79     0.000     .302  .612
           1 |    0.5234      0.0823     6.36     0.000     .362  .685
           2 |    0.5891      0.0891     6.61     0.000     .414  .764
           3 |    0.6123      0.0934     6.56     0.000     .429  .796
           4 |    0.5789      0.1012     5.72     0.000     .380  .778
           5 |    0.6012      0.1089     5.52     0.000     .388  .815
----------------------------------------------------------------------

Overall ATT: 0.5603 (SE: 0.0678)

Pre-trend test: F(4, 49) = 0.34, p = 0.849
  [No evidence against parallel trends]</div>
        </div>

        <div class="output-simulation" data-output="did-borusyak" data-lang="r">
          <div class="output-header"><span>R Output</span><button class="close-output">&times;</button></div>
          <div class="output-body">Borusyak et al. (2024) Imputation Estimator
=============================================

Static ATT:
  Estimate: 0.5603
  Std. Error: 0.0678
  t-value: 8.264
  p-value: < 2e-16 ***
  95% CI: [0.427, 0.694]

Event Study (with pre-trends):
  horizon   estimate   std.error   p.value
      -5    -0.0123      0.0456     0.787
      -4     0.0089      0.0423     0.834
      -3    -0.0234      0.0478     0.625
      -2     0.0156      0.0412     0.705
      -1     0.0000          ref       ref
       0     0.4567      0.0789     0.000
       1     0.5234      0.0823     0.000
       2     0.5891      0.0891     0.000
       3     0.6123      0.0934     0.000
       4     0.5789      0.1012     0.000
       5     0.6012      0.1089     0.000

[Event study plot: pre-treatment coefficients near zero,
 post-treatment coefficients positive and increasing,
 95% CIs shown as vertical bars, dashed line at y = 0]</div>
        </div>

        <div class="citation">
          <div class="citation-title">Reference</div>
          <ul>
            <li>Borusyak, K., Jaravel, X., &amp; Spiess, J. (2024). "Revisiting Event-Study Designs: Robust and Efficient Estimation." <em>Review of Economic Studies</em>, 91(6), 3253-3285.</li>
          </ul>
        </div>

        <!-- ============================================================ -->
        <!-- SECTION 4: Fuzzy DiD                                         -->
        <!-- ============================================================ -->

        <h2 id="fuzzy-did">Fuzzy Difference-in-Differences</h2>

        <p>
          Standard (sharp) DiD assumes perfect compliance&mdash;all units in the treatment group actually receive treatment. Fuzzy DiD handles imperfect compliance, analogous to fuzzy RDD. The idea: use the group&times;post interaction as an instrument for actual treatment. This yields a LATE for compliers, just as in IV estimation.
        </p>

        <div class="code-tabs" data-runnable="did-fuzzy">
          <div class="tab-buttons">
            <button class="tab-button active" data-lang="python">Python</button>
            <button class="tab-button" data-lang="stata">Stata</button>
            <button class="tab-button" data-lang="r">R</button>
          </div>
          <div class="tab-content active" data-lang="python">
<pre><code><span class="code-keyword">from</span> linearmodels.iv <span class="code-keyword">import</span> IV2SLS
<span class="code-keyword">from</span> linearmodels.panel <span class="code-keyword">import</span> PanelOLS
<span class="code-keyword">import</span> pandas <span class="code-keyword">as</span> pd

<span class="code-comment"># Set up panel data</span>
df = df.set_index([<span class="code-string">'unit_id'</span>, <span class="code-string">'year'</span>])

<span class="code-comment"># Sharp DiD</span>
<span class="code-tooltip" data-tip="Standard DiD assumes all assigned units actually take up treatment">sharp = <span class="code-function">PanelOLS</span>(df[<span class="code-string">'outcome'</span>], df[[<span class="code-string">'treatment_actual'</span>]],
                  entity_effects=True, time_effects=True).<span class="code-function">fit</span>(
                  cov_type=<span class="code-string">'clustered'</span>, cluster_entity=True)</span>

<span class="code-comment"># Fuzzy DiD with IV</span>
<span class="code-comment"># Use treatment_assigned as instrument for treatment_actual</span>
<span class="code-tooltip" data-tip="Fuzzy DiD: the group x post assignment instruments for actual treatment uptake">fuzzy = <span class="code-function">IV2SLS</span>(df[<span class="code-string">'outcome'</span>],
               exog=None,
               endog=df[[<span class="code-string">'treatment_actual'</span>]],
               instruments=df[[<span class="code-string">'treatment_assigned'</span>]]).<span class="code-function">fit</span>(
               cov_type=<span class="code-string">'clustered'</span>, clusters=df.index.get_level_values(0))</span>
print(fuzzy.summary)</code></pre>
            <button class="run-btn" data-lang="python">Run Code</button>
          </div>
          <div class="tab-content" data-lang="stata">
<pre><code><span class="code-comment">* Sharp DiD</span>
reghdfe outcome treatment_actual, absorb(unit_id year) cluster(unit_id)

<span class="code-comment">* Fuzzy DiD: IV within DiD framework</span>
<span class="code-comment">* treatment_assigned = group x post interaction (intent to treat)</span>
<span class="code-tooltip" data-tip="Instruments actual treatment with the DiD interaction (intent-to-treat)">ivreghdfe outcome (treatment_actual = treatment_assigned), ///
    absorb(unit_id year) cluster(unit_id)</span>

<span class="code-comment">* Or equivalently with xtivreg</span>
xtivreg outcome (treatment_actual = treatment_assigned) i.year, ///
    fe vce(cluster unit_id)

<span class="code-comment">* Check first stage</span>
estat firststage</code></pre>
            <button class="run-btn" data-lang="stata">Run Code</button>
          </div>
          <div class="tab-content" data-lang="r">
<pre><code><span class="code-keyword">library</span>(fixest)
<span class="code-comment"># Sharp DiD (standard)</span>
sharp <- <span class="code-function">feols</span>(outcome ~ treatment_actual | unit_id + year, data = df)

<span class="code-comment"># Fuzzy DiD: instrument actual treatment with assignment</span>
<span class="code-comment"># The DiD interaction (group x post) instruments for actual treatment</span>
<span class="code-tooltip" data-tip="The | after FEs introduces IV: treatment_actual is instrumented by treatment_assigned">fuzzy <- <span class="code-function">feols</span>(outcome ~ 1 | unit_id + year |
               treatment_actual ~ treatment_assigned, data = df)</span>
<span class="code-function">summary</span>(fuzzy)

<span class="code-comment"># The coefficient on treatment_actual is now the LATE</span>
<span class="code-comment"># (Local Average Treatment Effect for compliers)</span>

<span class="code-comment"># First-stage F-statistic</span>
<span class="code-function">fitstat</span>(fuzzy, <span class="code-string">"ivf"</span>)  <span class="code-comment"># should be > 10</span></code></pre>
            <button class="run-btn" data-lang="r">Run Code</button>
          </div>
        </div>

        <div class="output-simulation" data-output="did-fuzzy" data-lang="python">
          <div class="output-header"><span>Python Output</span><button class="close-output">&times;</button></div>
          <div class="output-body">Sharp DiD (PanelOLS):
  treatment_actual: 0.4523 (SE: 0.0891, p < 0.001)

Fuzzy DiD (IV2SLS):
                          IV-2SLS Estimation Summary
================================================================================
Dep. Variable:                outcome   R-squared:                        0.3891
Estimator:                    IV-2SLS   Adj. R-squared:                   0.3845
No. Observations:               5000   F-statistic:                      45.23

                             Parameter Estimates
================================================================================
                 Parameter  Std. Err.     T-stat    P-value    Lower CI  Upper CI
--------------------------------------------------------------------------------
treatment_actual    0.7234     0.1456      4.968     0.000      0.438     1.009
================================================================================

First-stage F-statistic: 34.56 (> 10, instrument is strong)

Interpretation:
  Sharp DiD (ITT):  0.452 ‚Äî effect of being assigned to treatment
  Fuzzy DiD (LATE): 0.723 ‚Äî effect for compliers (those who actually took up)
  Compliance rate:  ~62.5% (= ITT / LATE)</div>
        </div>

        <div class="output-simulation" data-output="did-fuzzy" data-lang="stata">
          <div class="output-header"><span>Stata Output</span><button class="close-output">&times;</button></div>
          <div class="output-body">. reghdfe outcome treatment_actual, absorb(unit_id year) cluster(unit_id)

Sharp DiD:
------------------------------------------------------------------------------
             |               Robust
     outcome |      Coef.   Std. Err.      t    P>|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
treatment_~l |   .4523456   .0891234     5.08   0.000     .2726789    .6320123
------------------------------------------------------------------------------

. ivreghdfe outcome (treatment_actual = treatment_assigned), ///
>     absorb(unit_id year) cluster(unit_id)

Fuzzy DiD (IV):
                             (Std. Err. adjusted for 50 clusters in unit_id)
------------------------------------------------------------------------------
             |               Robust
     outcome |      Coef.   Std. Err.      t    P>|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
treatment_~l |   .7234567   .1456789     4.97   0.000     .4306234    1.016290
------------------------------------------------------------------------------

Underidentification test (Kleibergen-Paap rk LM statistic): 34.56
                                                   Chi-sq(1) P-val = 0.0000
Weak identification test (Kleibergen-Paap rk Wald F statistic): 34.56
                                        Stock-Yogo weak ID test critical values:
                                        10% maximal IV size             16.38

. estat firststage
  First-stage regression summary statistics
  -------------------------------------------------------
                                     Adjusted   Partial
  Variable     |   R-sq.    R-sq.      R-sq.     F(1,49)
  -------------+-----------------------------------------
  treatment_~l |  0.5234    0.5123     0.4123     34.56</div>
        </div>

        <div class="output-simulation" data-output="did-fuzzy" data-lang="r">
          <div class="output-header"><span>R Output</span><button class="close-output">&times;</button></div>
          <div class="output-body">TSLS estimation - Pair 1
Dep. var.: outcome
Observations: 5,000
Standard-errors: Clustered (unit_id)

                    Estimate Std. Error  t value  Pr(>|t|)
treatment_actual     0.72346    0.14568    4.965   1.2e-05 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

IV diagnostics:
  First-stage F-stat (treatment_actual): 34.56 (p < 0.001)
  Wu-Hausman test: 5.67 (p = 0.017)

Comparison:
  Sharp DiD (OLS):   0.452 ‚Äî Intent-to-Treat (ITT) effect
  Fuzzy DiD (IV):    0.723 ‚Äî Local Average Treatment Effect (LATE)
  Implied compliance: 62.5%</div>
        </div>

        <div class="info-box tip">
          <div class="info-box-title">Interpreting Fuzzy DiD</div>
          <p style="margin-bottom: 0;">
            Fuzzy DiD estimates the LATE for compliers&mdash;units whose actual treatment status changes because of the policy. This is the same interpretation as in IV/2SLS. The identifying assumption combines parallel trends (for DiD) with an exclusion restriction (the instrument only affects outcomes through actual treatment).
          </p>
        </div>

        <div class="citation">
          <div class="citation-title">Reference</div>
          <ul>
            <li>de Chaisemartin, C. &amp; D'Haultfoeuille, X. (2018). "Fuzzy Differences-in-Differences." <em>Review of Economic Studies</em>, 85(2), 999-1028.</li>
          </ul>
        </div>

        <!-- ============================================================ -->
        <!-- SECTION 5: HonestDiD Sensitivity Analysis                    -->
        <!-- ============================================================ -->

        <h2 id="honest-did">HonestDiD Sensitivity Analysis</h2>

        <p>
          Standard parallel trends tests (pre-treatment coefficient = 0) have low power (Roth, 2022). HonestDiD (Rambachan &amp; Roth, 2023) asks: how robust are your results to violations of parallel trends? It computes confidence intervals that remain valid even if pre-trends are violated by up to a magnitude <em>M</em>. The key output is a sensitivity plot showing how CIs change as the allowed violation <em>M</em> increases.
        </p>

        <div class="code-tabs" data-runnable="did-honest">
          <div class="tab-buttons">
            <button class="tab-button active" data-lang="python">Python</button>
            <button class="tab-button" data-lang="stata">Stata</button>
            <button class="tab-button" data-lang="r">R</button>
          </div>
          <div class="tab-content active" data-lang="python">
<pre><code><span class="code-comment"># Python: No direct package ‚Äî use R via rpy2</span>
<span class="code-comment"># Conceptual approach:</span>
<span class="code-keyword">import</span> numpy <span class="code-keyword">as</span> np

<span class="code-comment"># After running event study, extract coefficients and vcov</span>
<span class="code-comment"># betahat = np.array([...])  # event study coefficients</span>
<span class="code-comment"># sigma = np.array([[...]])   # variance-covariance matrix</span>

<span class="code-comment"># The idea: for a given M (maximum violation of parallel trends),</span>
<span class="code-comment"># compute the worst-case bias and adjust confidence intervals</span>
<span class="code-tooltip" data-tip="M=0 assumes exact parallel trends; larger M allows for bigger violations, widening the CI"><span class="code-comment"># M = 0: standard CI (assumes exact parallel trends)</span>
<span class="code-comment"># M > 0: wider CI (allows for some violation)</span></span>

<span class="code-comment"># In practice, use R's HonestDiD package:</span>
<span class="code-comment"># from rpy2.robjects.packages import importr</span>
<span class="code-comment"># honestdid = importr('HonestDiD')</span>
<span class="code-comment"># sensitivity = honestdid.createSensitivityResults_relativeMagnitudes(</span>
<span class="code-comment">#     betahat=betahat, sigma=sigma,</span>
<span class="code-comment">#     numPrePeriods=4, numPostPeriods=5)</span>
print(<span class="code-string">"Use R's HonestDiD package for sensitivity analysis"</span>)
print(<span class="code-string">"See: https://github.com/asheshrambachan/HonestDiD"</span>)</code></pre>
            <button class="run-btn" data-lang="python">Run Code</button>
          </div>
          <div class="tab-content" data-lang="stata">
<pre><code><span class="code-comment">* Install: ssc install honestdid</span>
<span class="code-comment">* Step 1: Run event study</span>
reghdfe outcome ib(-1).rel_time, absorb(unit_id year) cluster(unit_id)

<span class="code-comment">* Step 2: HonestDiD sensitivity analysis</span>
<span class="code-tooltip" data-tip="Computes CIs that remain valid even if parallel trends are violated by up to magnitude M">honestdid, pre(4) post(5) mvec(0 0.5 1 1.5 2)</span>

<span class="code-comment">* The command produces a sensitivity plot showing</span>
<span class="code-comment">* how confidence intervals widen as M increases.</span>
<span class="code-comment">* If CIs still exclude zero at reasonable M values,</span>
<span class="code-comment">* the result is robust to plausible parallel trends violations.</span></code></pre>
            <button class="run-btn" data-lang="stata">Run Code</button>
          </div>
          <div class="tab-content" data-lang="r">
<pre><code><span class="code-keyword">library</span>(HonestDiD)
<span class="code-keyword">library</span>(fixest)

<span class="code-comment"># Step 1: Run event study</span>
es <- <span class="code-function">feols</span>(outcome ~ <span class="code-function">i</span>(rel_time, ref = <span class="code-function">c</span>(-1, -Inf)) | unit_id + year,
            data = df, cluster = ~unit_id)

<span class="code-comment"># Step 2: Extract coefficients and variance-covariance matrix</span>
betahat <- <span class="code-function">coef</span>(es)
sigma <- <span class="code-function">vcov</span>(es)

<span class="code-comment"># Step 3: Sensitivity analysis ‚Äî relative magnitudes approach</span>
<span class="code-tooltip" data-tip="Asks: how large could post-treatment bias be relative to the max pre-trend?">sensitivity <- <span class="code-function">createSensitivityResults_relativeMagnitudes</span>(
  betahat = betahat,
  sigma = sigma,
  numPrePeriods = 4,    <span class="code-comment"># number of pre-treatment periods</span>
  numPostPeriods = 5,   <span class="code-comment"># number of post-treatment periods</span>
  Mbarvec = <span class="code-function">seq</span>(0, 2, by = 0.5)  <span class="code-comment"># grid of M values</span>
)</span>

<span class="code-comment"># Step 4: Plot sensitivity</span>
<span class="code-function">createSensitivityPlot_relativeMagnitudes</span>(sensitivity, rescaleFactor = 1)

<span class="code-comment"># Original CI (M=0) vs robust CIs</span>
print(sensitivity)</code></pre>
            <button class="run-btn" data-lang="r">Run Code</button>
          </div>
        </div>

        <div class="output-simulation" data-output="did-honest" data-lang="python">
          <div class="output-header"><span>Python Output</span><button class="close-output">&times;</button></div>
          <div class="output-body">HonestDiD Sensitivity Analysis
================================

Note: Use R's HonestDiD package for this analysis.
Python implementation not yet available.

See: https://github.com/asheshrambachan/HonestDiD

Conceptual output (from R):
  M = 0.0: CI = [0.427, 0.694]  (standard parallel trends)
  M = 0.5: CI = [0.312, 0.809]
  M = 1.0: CI = [0.198, 0.923]
  M = 1.5: CI = [0.083, 1.038]
  M = 2.0: CI = [-0.031, 1.152]

Result is robust to violations up to M = 1.5
(CI excludes zero for M &le; 1.5)</div>
        </div>

        <div class="output-simulation" data-output="did-honest" data-lang="stata">
          <div class="output-header"><span>Stata Output</span><button class="close-output">&times;</button></div>
          <div class="output-body">. honestdid, pre(4) post(5) mvec(0 0.5 1 1.5 2)

HonestDiD Sensitivity Analysis (Rambachan & Roth, 2023)
=========================================================

Relative Magnitudes Approach:
  (Maximum post-treatment violation relative to max pre-trend)

----------------------------------------------------------------------
     Mbar |    Lower CI    Upper CI    Excludes Zero?
----------+-----------------------------------------------------------
     0.00 |      0.4270      0.6940         Yes
     0.50 |      0.3120      0.8090         Yes
     1.00 |      0.1980      0.9230         Yes
     1.50 |      0.0830      1.0380         Yes
     2.00 |     -0.0310      1.1520         No
----------------------------------------------------------------------

Interpretation:
  The treatment effect remains statistically significant for
  M &le; 1.5 (post-treatment violations up to 1.5x the max pre-trend).
  At M = 2.0, the CI includes zero.

[Sensitivity plot displayed: M (x-axis) vs. confidence interval bounds]</div>
        </div>

        <div class="output-simulation" data-output="did-honest" data-lang="r">
          <div class="output-header"><span>R Output</span><button class="close-output">&times;</button></div>
          <div class="output-body">HonestDiD Sensitivity Analysis
================================

Relative Magnitudes Approach:
  Mbar    lb.robust    ub.robust
   0.0       0.4270       0.6940
   0.5       0.3120       0.8090
   1.0       0.1980       0.9230
   1.5       0.0830       1.0380
   2.0      -0.0310       1.1520

[Sensitivity Plot:
 - X-axis: Mbar (allowed violation magnitude, 0 to 2)
 - Y-axis: Confidence interval bounds
 - Shaded region between lower and upper bounds
 - Dashed line at y = 0
 - CI excludes zero for Mbar in [0, 1.5]
 - CI includes zero at Mbar = 2.0]

Interpretation:
  Original estimate: 0.560 (M = 0, exact parallel trends)
  Breakdown value: M &asymp; 1.85
  (The result is overturned only if post-treatment violations
   exceed 1.85x the maximum pre-treatment trend deviation)</div>
        </div>

        <div class="info-box warning">
          <div class="info-box-title">Why Pre-Trend Tests Are Not Enough</div>
          <p style="margin-bottom: 0;">
            Roth (2022) shows that standard pre-trend tests have low power&mdash;failing to reject parallel trends does NOT mean trends are actually parallel. HonestDiD addresses this by asking how large parallel trends violations need to be before the conclusions change, providing a more informative robustness check.
          </p>
        </div>

        <div class="citation">
          <div class="citation-title">References</div>
          <ul>
            <li>Rambachan, A. &amp; Roth, J. (2023). "A More Credible Approach to Parallel Trends." <em>Review of Economic Studies</em>, 90(5), 2555-2591.</li>
            <li>Roth, J. (2022). "Pretest with Caution: Event-Study Estimates after Testing for Parallel Trends." <em>AER: Insights</em>, 4(3), 305-322.</li>
          </ul>
        </div>

        <div class="citation">
          <div class="citation-title">Key Papers on Modern DiD</div>
          <ul>
            <li><strong>Callaway, B. & Sant'Anna, P.</strong> (2021). "Difference-in-Differences with Multiple Time Periods." <em>Journal of Econometrics</em>.</li>
            <li><strong>de Chaisemartin, C. & D'Haultfoeuille, X.</strong> (2020). "Two-Way Fixed Effects Estimators with Heterogeneous Treatment Effects." <em>AER</em>.</li>
            <li><strong>Sun, L. & Abraham, S.</strong> (2021). "Estimating Dynamic Treatment Effects in Event Studies with Heterogeneous Treatment Effects." <em>Journal of Econometrics</em>.</li>
            <li><strong>Goodman-Bacon, A.</strong> (2021). "Difference-in-Differences with Variation in Treatment Timing." <em>Journal of Econometrics</em>.</li>
            <li><strong>Roth, J.</strong> (2022). "Pretest with Caution: Event-Study Estimates after Testing for Parallel Trends." <em>AER: Insights</em>.</li>
            <li><strong>Borusyak, K., Jaravel, X., &amp; Spiess, J.</strong> (2024). "Revisiting Event-Study Designs: Robust and Efficient Estimation." <em>Review of Economic Studies</em>, 91(6), 3253-3285.</li>
            <li><strong>Rambachan, A. &amp; Roth, J.</strong> (2023). "A More Credible Approach to Parallel Trends." <em>Review of Economic Studies</em>, 90(5), 2555-2591.</li>
            <li><strong>de Chaisemartin, C. &amp; D'Haultfoeuille, X.</strong> (2018). "Fuzzy Differences-in-Differences." <em>Review of Economic Studies</em>, 85(2), 999-1028.</li>
            <li><strong>de Chaisemartin, C. &amp; D'Haultfoeuille, X.</strong> (2022). "Two-Way Fixed Effects and Differences-in-Differences with Heterogeneous Treatment Effects: A Survey." <em>Econometrics Journal</em>, 25(3), 493-510.</li>
          </ul>
        </div>

        <div class="nav-footer">
          <a href="06a-matching.html" class="nav-link prev">6A: Matching</a>
          <a href="06c-rdd.html" class="nav-link next">6C: Regression Discontinuity</a>
        </div>
      </div>
    </main>
  </div>

  <button class="mobile-menu-toggle" aria-label="Toggle navigation menu">Menu</button>
  <script src="../js/main.js"></script>
  <script src="../js/grammar-primer.js"></script>
  <script src="../js/password-protection.js"></script>
</body>
</html>
