<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>10A Text Analysis Today | ProTools ER1</title>
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Crimson+Pro:ital,wght@0,400;0,600;0,700;1,400&family=Fira+Code:wght@400;500&family=Source+Sans+Pro:ital,wght@0,400;0,600;0,700;1,400&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="../css/style.css">
  <style>
    .protected-content { -webkit-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; }
    .protected-content pre, .protected-content code, .protected-content .code-block, .protected-content .code-tabs { -webkit-user-select: text; -moz-user-select: text; -ms-user-select: text; user-select: text; }
    .code-tooltip { position: relative; cursor: help; border-bottom: 1px dotted #888; text-decoration: none; }
    .tooltip-popup { position: fixed; background: #1f2937; color: white; padding: 0.5rem 0.75rem; border-radius: 6px; font-size: 0.75rem; white-space: normal; max-width: 300px; opacity: 0; pointer-events: none; transition: opacity 0.15s ease-in-out; z-index: 10000; line-height: 1.4; text-align: left; font-family: var(--font-body); font-style: normal; box-shadow: 0 4px 12px rgba(0,0,0,0.3); }
    .tooltip-popup.visible { opacity: 1; }
    .tooltip-popup::after { content: ''; position: absolute; border: 6px solid transparent; }
    .tooltip-popup.arrow-bottom::after { top: 100%; left: 50%; transform: translateX(-50%); border-top-color: #1f2937; }
    .tooltip-popup.arrow-top::after { bottom: 100%; left: 50%; transform: translateX(-50%); border-bottom-color: #1f2937; }

    .pipeline-diagram { display: flex; align-items: center; flex-wrap: wrap; gap: 0.5rem; margin: 2rem 0; padding: 1.5rem; background: #f8fafc; border-radius: 12px; border: 1px solid #e2e8f0; }
    .pipeline-step { background: white; border: 2px solid #e2e8f0; border-radius: 8px; padding: 0.75rem 1.25rem; text-align: center; font-weight: 600; font-size: 0.9rem; color: var(--color-primary); transition: all 0.2s; flex: 1; min-width: 120px; }
    .pipeline-step:hover { border-color: var(--color-accent); transform: translateY(-2px); box-shadow: 0 4px 12px rgba(0,0,0,0.08); }
    .pipeline-step small { display: block; font-weight: 400; font-size: 0.75rem; color: #64748b; margin-top: 0.25rem; }
    .pipeline-arrow { font-size: 1.5rem; color: var(--color-accent); font-weight: bold; flex-shrink: 0; }
    @media (max-width: 768px) { .pipeline-diagram { flex-direction: column; } .pipeline-arrow { transform: rotate(90deg); } }

    .method-table { width: 100%; border-collapse: collapse; margin: 1.5rem 0; font-size: 0.9rem; }
    .method-table th { background: var(--color-primary); color: white; padding: 0.75rem 1rem; text-align: left; font-weight: 600; }
    .method-table td { padding: 0.75rem 1rem; border-bottom: 1px solid #e2e8f0; }
    .method-table tr:nth-child(even) { background: #f8fafc; }
    .method-table tr:hover { background: #edf2f7; }

    .output-block { background: #0f172a; color: #e2e8f0; padding: 1rem 1.25rem; border-radius: 0 0 8px 8px; font-family: 'Fira Code', monospace; font-size: 0.82rem; line-height: 1.6; overflow-x: auto; margin-top: -0.5rem; border-top: 2px solid #334155; }
    .output-label { background: #334155; color: #94a3b8; padding: 0.25rem 0.75rem; font-size: 0.7rem; font-family: 'Fira Code', monospace; text-transform: uppercase; letter-spacing: 0.05em; border-radius: 8px 8px 0 0; display: inline-block; margin-top: 0.5rem; }

    .distinction-box { display: grid; grid-template-columns: 1fr 1fr; gap: 1rem; margin: 1.5rem 0; }
    @media (max-width: 768px) { .distinction-box { grid-template-columns: 1fr; } }
    .distinction-card { background: #f8fafc; border: 1px solid #e2e8f0; border-radius: 8px; padding: 1.25rem; }
    .distinction-card h4 { margin: 0 0 0.75rem 0; color: var(--color-secondary); font-size: 1.05rem; }
    .distinction-card ul { margin: 0; padding-left: 1.25rem; }
    .distinction-card li { margin-bottom: 0.35rem; }

    .checklist { list-style: none; padding: 0; }
    .checklist li { padding: 0.5rem 0 0.5rem 2rem; position: relative; border-bottom: 1px solid #f1f5f9; }
    .checklist li::before { content: '‚òê'; position: absolute; left: 0.25rem; color: var(--color-accent); font-size: 1.1rem; }
  </style>
</head>
<body>
  <div id="password-overlay" class="password-overlay">
    <div class="password-modal">
      <h2>ProTools ER1</h2>
      <p>Programming Tools for Empirical Research</p>
      <div class="course-description">
        <h3>Course Modules</h3>
        <ul class="module-list">
          <li><strong>Module 0:</strong> Languages & Platforms</li>
          <li><strong>Module 1:</strong> Getting Started</li>
          <li><strong>Module 2:</strong> Data Harnessing</li>
          <li><strong>Module 3:</strong> Data Exploration</li>
          <li><strong>Module 4:</strong> Data Cleaning</li>
          <li><strong>Module 5:</strong> Data Analysis</li>
          <li><strong>Module 6:</strong> Causal Inference</li>
          <li><strong>Module 7:</strong> Estimation Methods</li>
          <li><strong>Module 8:</strong> Replicability</li>
          <li><strong>Module 9:</strong> Git & GitHub</li>
          <li><strong>Module 10:</strong> History of NLP & Text Analysis</li>
          <li><strong>Module 11:</strong> Machine Learning</li>
          <li><strong>Module 12:</strong> Large Language Models</li>
        </ul>
      </div>
      <div class="access-note">
        This course is currently open to <strong>students at Sciences Po</strong>. If you are not a Sciences Po student but would like access, please <a href="mailto:giulia.caprini@sciencespo.fr">email me</a> to request an invite token.
      </div>
      <div class="password-form">
        <input type="password" id="password-input" placeholder="Enter password" autocomplete="off">
        <button id="password-submit">Access Course</button>
        <p id="password-error" style="color: #e53e3e; font-size: 0.85rem; margin-top: 1rem; display: none;">Incorrect password. Please try again.</p>
      </div>
    </div>
  </div>

  <div class="page-wrapper protected-content">
    <aside class="sidebar">
      <a href="../index.html" class="sidebar-logo">ProTools ER1</a>
      <span class="sidebar-subtitle">Programming Tools for Empirical Research</span>
      <nav>
        <ul>
          <li><a href="../index.html"><span class="welcome-icon">üè†</span> Welcome</a></li>
          <li class="has-subnav">
            <a href="00-languages-platforms.html"><span class="module-number">0</span> Languages & Platforms</a>
            <ul class="sub-nav">
              <li><a href="00a-rstudio-guide.html">RStudio Guide</a></li>
              <li><a href="00b-stata-guide.html">Stata Guide</a></li>
              <li><a href="00c-vscode-guide.html">VS Code Guide</a></li>
              <li><a href="00d-notebooks-guide.html">Notebooks Guide</a></li>
            </ul>
          </li>
          <li><a href="01-getting-started.html"><span class="module-number">1</span> Getting Started</a></li>
          <li class="has-subnav">
            <a href="02-data-harnessing.html"><span class="module-number">2</span> Data Harnessing</a>
            <ul class="sub-nav">
              <li><a href="02a-file-import.html">File Import</a></li>
              <li><a href="02b-apis.html">APIs</a></li>
              <li><a href="02c-web-scraping.html">Web Scraping</a></li>
            </ul>
          </li>
          <li><a href="03-data-exploration.html"><span class="module-number">3</span> Data Exploration</a></li>
          <li><a href="04-data-cleaning.html"><span class="module-number">4</span> Data Cleaning</a></li>
          <li class="has-subnav">
            <a href="05-data-analysis.html"><span class="module-number">5</span> Data Analysis</a>
            <ul class="sub-nav">
              <li><a href="05a-data-simulation.html">Data Simulation</a></li>
            </ul>
          </li>
          <li class="has-subnav">
            <a href="06-causal-inference.html"><span class="module-number">6</span> Causal Inference</a>
            <ul class="sub-nav">
              <li><a href="06a-matching.html">Matching</a></li>
              <li><a href="06b-did.html">Difference-in-Differences</a></li>
              <li><a href="06c-rdd.html">Regression Discontinuity</a></li>
              <li><a href="06d-iv.html">Instrumental Variables</a></li>
              <li><a href="06e-synthetic-control.html">Synthetic Control</a></li>
              <li><a href="05b-experiments.html">Experiments</a></li>
            </ul>
          </li>
          <li><a href="07-estimation.html"><span class="module-number">7</span> Estimation Methods</a></li>
          <li><a href="08-replicability.html"><span class="module-number">8</span> Replicability</a></li>
          <li><a href="09-github.html"><span class="module-number">9</span> Git & GitHub</a></li>
          <li class="has-subnav active">
            <a href="10-nlp-history.html"><span class="module-number">10</span> History of NLP</a>
            <ul class="sub-nav">
              <li class="active"><a href="10a-text-analysis-today.html">Text Analysis Today</a></li>
            </ul>
          </li>
          <li class="has-subnav">
            <a href="11-machine-learning.html"><span class="module-number">11</span> Machine Learning</a>
            <ul class="sub-nav">
              <li><a href="11a-regularization.html">Regularization</a></li>
              <li><a href="11b-trees.html">Tree-Based Methods</a></li>
              <li><a href="11c-neural-networks.html">Neural Networks</a></li>
              <li><a href="11d-causal-ml.html">Causal ML</a></li>
              <li><a href="11e-model-evaluation.html">Model Evaluation</a></li>
            </ul>
          </li>
          <li><a href="12-llms.html"><span class="module-number">12</span> Large Language Models</a></li>
          <li><a href="../resources.html">Resources</a></li>
          <li><a href="contact.html">Contact & Feedback</a></li>
        </ul>
      </nav>
    </aside>

    <main class="main-content">
      <div class="content-wrapper">

        <p class="breadcrumb" style="font-size: 0.9rem; color: #64748b; margin-bottom: 0.5rem;">
          <a href="10-nlp-history.html" style="color: #2563eb; text-decoration: none;">10 History of NLP</a> &raquo; Text Analysis Today
        </p>

        <div class="module-header">
          <h1>10A &nbsp;Text Analysis Today</h1>
          <div class="module-meta">
            <span>From Raw Text to Rigorous Results</span>
            <span>Python &bull; Hands-On &bull; Reproducible</span>
          </div>
        </div>

        <p class="lead">
          Module 10 showed you <em>how we got here</em>. This module shows you <em>what to do now</em>.
          We walk through every major technique used in modern text analysis &mdash; from basic preprocessing to
          transformer-based models and LLM APIs &mdash; with production-ready Python code you can run today.
          A single running example (analyzing Federal Reserve communications) ties every technique together so you
          can see how each tool fits into a real research or business pipeline.
        </p>

        <div class="learning-objectives">
          <h3>Learning Objectives</h3>
          <ul>
            <li>Set up a reproducible text analysis environment in Python</li>
            <li>Preprocess text data rigorously (tokenize, clean, lemmatize)</li>
            <li>Represent text as numbers using BoW, TF-IDF, and embeddings</li>
            <li>Perform sentiment analysis with lexicons, fine-tuned models, and LLMs</li>
            <li>Discover topics with LDA and BERTopic</li>
            <li>Extract named entities from unstructured text</li>
            <li>Classify documents without labeled training data (zero-shot)</li>
            <li>Measure semantic similarity with sentence embeddings</li>
            <li>Use LLM APIs (Claude, GPT) for text analysis at scale</li>
            <li>Build a complete, end-to-end text analysis pipeline</li>
            <li>Follow best practices for reproducibility in computational text analysis</li>
          </ul>
        </div>

        <div class="info-box note">
          <div class="info-box-title">Running Example</div>
          <p>
            Throughout this module we analyze <strong>Federal Reserve FOMC statements</strong> &mdash; the short
            press releases issued after each Federal Open Market Committee meeting. These are ideal for teaching because they are:
            (a) publicly available, (b) consequential for financial markets, (c) widely studied in economics and finance, and
            (d) short enough to inspect manually while long enough to be interesting.
            We will build a dataset of FOMC statements and apply every technique in this module to them.
          </p>
        </div>

        <!-- Table of Contents -->
        <div class="toc">
          <h3>Contents</h3>
          <ul>
            <li><a href="#pipeline">10A.0 The Text Analysis Pipeline</a></li>
            <li><a href="#setup">10A.1 Environment Setup</a></li>
            <li><a href="#preprocessing">10A.2 Text Preprocessing</a></li>
            <li><a href="#representation">10A.3 Text Representation: BoW &amp; TF-IDF</a></li>
            <li><a href="#sentiment">10A.4 Sentiment Analysis</a></li>
            <li><a href="#topics">10A.5 Topic Modeling</a></li>
            <li><a href="#ner">10A.6 Named Entity Recognition</a></li>
            <li><a href="#classification">10A.7 Zero-Shot Classification</a></li>
            <li><a href="#embeddings">10A.8 Semantic Similarity &amp; Embeddings</a></li>
            <li><a href="#llms">10A.9 LLMs for Text Analysis at Scale</a></li>
            <li><a href="#full-example">10A.10 Putting It All Together</a></li>
            <li><a href="#reproducibility">10A.11 Reproducibility Checklist</a></li>
            <li><a href="#references">References &amp; Further Reading</a></li>
          </ul>
        </div>

        <!-- ================================================================== -->
        <!-- SECTION 0: PIPELINE OVERVIEW -->
        <!-- ================================================================== -->
        <h2 id="pipeline">10A.0 &nbsp;The Text Analysis Pipeline</h2>

        <p>
          Every text analysis project &mdash; whether a hedge fund parsing earnings calls or a political scientist
          studying parliamentary speeches &mdash; follows the same core pipeline. The techniques differ, but the
          structure is universal:
        </p>

        <div class="pipeline-diagram">
          <div class="pipeline-step">Acquire<small>Gather raw text</small></div>
          <span class="pipeline-arrow">&rarr;</span>
          <div class="pipeline-step">Preprocess<small>Clean &amp; tokenize</small></div>
          <span class="pipeline-arrow">&rarr;</span>
          <div class="pipeline-step">Represent<small>Text &rarr; numbers</small></div>
          <span class="pipeline-arrow">&rarr;</span>
          <div class="pipeline-step">Analyze<small>Model &amp; extract</small></div>
          <span class="pipeline-arrow">&rarr;</span>
          <div class="pipeline-step">Validate<small>Evaluate &amp; report</small></div>
        </div>

        <p>
          The single most consequential decision you make is at the <strong>Represent</strong> stage. The table below
          summarizes the three tiers of text representation available today, from simplest to most powerful:
        </p>

        <table class="method-table">
          <thead>
            <tr>
              <th>Approach</th>
              <th>How It Works</th>
              <th>Strengths</th>
              <th>Limitations</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td><strong>Bag of Words / TF-IDF</strong></td>
              <td>Count words (or weight by rarity)</td>
              <td>Interpretable, fast, great baselines</td>
              <td>No word order, no context</td>
            </tr>
            <tr>
              <td><strong>Static Embeddings</strong><br><small>Word2Vec, GloVe</small></td>
              <td>Dense vectors learned from co-occurrence</td>
              <td>Captures similarity, lightweight</td>
              <td>One vector per word (no polysemy)</td>
            </tr>
            <tr>
              <td><strong>Contextual Embeddings</strong><br><small>BERT, Sentence-Transformers</small></td>
              <td>Transformer encodes full sentence context</td>
              <td>State-of-the-art accuracy, handles ambiguity</td>
              <td>Compute-intensive, less interpretable</td>
            </tr>
          </tbody>
        </table>

        <div class="expert-insight">
          <div class="expert-insight-header">Key Insight: There Is No Single &ldquo;Best&rdquo; Method</div>
          <p>
            A common mistake is jumping straight to transformers for every task. In practice, <strong>TF-IDF +
            logistic regression</strong> remains a remarkably strong baseline that is fast, interpretable, and often
            good enough. Start simple, measure performance, and only add complexity when it demonstrably helps.
            Many top-published papers in economics still use dictionary-based or TF-IDF approaches because
            interpretability matters for peer review.
          </p>
        </div>

        <div class="distinction-box">
          <div class="distinction-card">
            <h4>Business Applications</h4>
            <ul>
              <li>Customer feedback &amp; review analysis</li>
              <li>Earnings call sentiment scoring</li>
              <li>Social media brand monitoring</li>
              <li>Resume screening &amp; job matching</li>
              <li>Contract &amp; compliance analysis</li>
              <li>News-based trading signals</li>
            </ul>
          </div>
          <div class="distinction-card">
            <h4>Research Applications</h4>
            <ul>
              <li>Central bank communication analysis</li>
              <li>Political speech &amp; ideology scaling</li>
              <li>Media bias detection</li>
              <li>Economic Policy Uncertainty indices</li>
              <li>Patent &amp; innovation measurement</li>
              <li>Historical text analysis</li>
            </ul>
          </div>
        </div>


        <!-- ================================================================== -->
        <!-- SECTION 1: ENVIRONMENT SETUP -->
        <!-- ================================================================== -->
        <h2 id="setup">10A.1 &nbsp;Environment Setup</h2>

        <p>
          Before writing any analysis code, set up a <strong>reproducible environment</strong>.
          Pin your library versions so that anyone can replicate your results months or years later.
        </p>

        <h3>Installation</h3>

        <div class="code-tabs">
          <div class="tab-buttons">
            <button class="tab-button active" data-lang="python">Python</button>
          </div>
          <div class="tab-content active" data-lang="python">
<pre><code><span class="code-comment"># requirements.txt &mdash; pin EXACT versions for reproducibility</span>
<span class="code-comment"># Save this file and run: pip install -r requirements.txt</span>

<span class="code-comment"># Core NLP</span>
nltk==3.9.1
spacy==3.8.4

<span class="code-comment"># Classical ML &amp; text representation</span>
scikit-learn==1.6.1
gensim==4.3.3

<span class="code-comment"># Transformers &amp; embeddings</span>
transformers==4.47.1
sentence-transformers==3.4.1
torch==2.5.1

<span class="code-comment"># Topic modeling</span>
bertopic==0.16.4

<span class="code-comment"># Financial sentiment</span>
pysentiment2==0.1.1

<span class="code-comment"># LLM APIs</span>
anthropic==0.42.0
openai==1.58.1

<span class="code-comment"># Data &amp; visualization</span>
pandas==2.2.3
matplotlib==3.9.3
seaborn==0.13.2
wordcloud==1.9.4</code></pre>
          </div>
        </div>

        <div class="code-tabs">
          <div class="tab-buttons">
            <button class="tab-button active" data-lang="python">Python</button>
          </div>
          <div class="tab-content active" data-lang="python">
<pre><code><span class="code-comment"># After installing, download required models &amp; data</span>
<span class="code-keyword">import</span> <span class="code-package">nltk</span>
<span class="code-package">nltk</span>.<span class="code-function">download</span>(<span class="code-string">'punkt_tab'</span>)
<span class="code-package">nltk</span>.<span class="code-function">download</span>(<span class="code-string">'stopwords'</span>)
<span class="code-package">nltk</span>.<span class="code-function">download</span>(<span class="code-string">'wordnet'</span>)
<span class="code-package">nltk</span>.<span class="code-function">download</span>(<span class="code-string">'vader_lexicon'</span>)

<span class="code-comment"># Download spaCy English model</span>
<span class="code-comment"># Run in terminal: python -m spacy download en_core_web_sm</span></code></pre>
          </div>
        </div>

        <h3>Reproducibility Seed</h3>
        <p>
          Set random seeds <strong>once at the top of every script</strong>. This ensures that any method involving
          randomness (topic models, train/test splits, embeddings initialization) gives identical results every time.
        </p>

        <div class="code-tabs">
          <div class="tab-buttons">
            <button class="tab-button active" data-lang="python">Python</button>
          </div>
          <div class="tab-content active" data-lang="python">
<pre><code><span class="code-keyword">import</span> <span class="code-package">random</span>
<span class="code-keyword">import</span> <span class="code-package">numpy</span> <span class="code-keyword">as</span> np

<span class="code-keyword">def</span> <span class="code-function">set_seed</span>(seed=<span class="code-number">42</span>):
    <span class="code-string">"""Set all random seeds for full reproducibility."""</span>
    <span class="code-package">random</span>.<span class="code-function">seed</span>(seed)
    np.random.<span class="code-function">seed</span>(seed)
    <span class="code-keyword">try</span>:
        <span class="code-keyword">import</span> <span class="code-package">torch</span>
        <span class="code-package">torch</span>.<span class="code-function">manual_seed</span>(seed)
        <span class="code-package">torch</span>.cuda.<span class="code-function">manual_seed_all</span>(seed)
        <span class="code-package">torch</span>.backends.cudnn.deterministic = <span class="code-keyword">True</span>
        <span class="code-package">torch</span>.backends.cudnn.benchmark = <span class="code-keyword">False</span>
    <span class="code-keyword">except</span> <span class="code-variable">ImportError</span>:
        <span class="code-keyword">pass</span>

<span class="code-function">set_seed</span>(<span class="code-number">42</span>)</code></pre>
          </div>
        </div>

        <h3>Loading Our Running Example</h3>
        <p>
          We will work with a small corpus of FOMC press statements. In practice, you would scrape these
          from the <a href="https://www.federalreserve.gov/monetarypolicy/fomccalendars.htm" target="_blank">Federal Reserve website</a>.
          For this tutorial, we define a sample directly:
        </p>

        <div class="code-tabs">
          <div class="tab-buttons">
            <button class="tab-button active" data-lang="python">Python</button>
          </div>
          <div class="tab-content active" data-lang="python">
<pre><code><span class="code-keyword">import</span> <span class="code-package">pandas</span> <span class="code-keyword">as</span> pd

<span class="code-comment"># Sample FOMC statements (abbreviated for pedagogy)</span>
fomc_data = [
    {
        <span class="code-string">"date"</span>: <span class="code-string">"2008-12-16"</span>,
        <span class="code-string">"text"</span>: <span class="code-string">"""The Federal Open Market Committee decided today to establish a target range
for the federal funds rate of 0 to 1/4 percent. Since the Committee's last meeting,
labor market conditions have deteriorated, and the available data indicate that
consumer spending, business investment, and industrial production have declined.
Financial markets remain quite strained and credit conditions tight. Overall, the
outlook for economic activity has weakened further."""</span>
    },
    {
        <span class="code-string">"date"</span>: <span class="code-string">"2015-12-16"</span>,
        <span class="code-string">"text"</span>: <span class="code-string">"""The Committee judges that there has been considerable improvement in labor
market conditions this year, and it is reasonably confident that inflation will
rise, over the medium term, to its 2 percent objective. Given the economic outlook,
the Committee decided to raise the target range for the federal funds rate to
1/4 to 1/2 percent. The stance of monetary policy remains accommodative after
this increase, thereby supporting further improvement in labor market conditions."""</span>
    },
    {
        <span class="code-string">"date"</span>: <span class="code-string">"2020-03-15"</span>,
        <span class="code-string">"text"</span>: <span class="code-string">"""The coronavirus outbreak has harmed communities and disrupted economic activity
in many countries, including the United States. The effects of the coronavirus
will weigh on economic activity in the near term and pose risks to the economic
outlook. In light of these developments, the Committee decided to lower the target
range for the federal funds rate to 0 to 1/4 percent. The Committee expects to
maintain this target range until it is confident that the economy has weathered
recent events."""</span>
    },
    {
        <span class="code-string">"date"</span>: <span class="code-string">"2022-06-15"</span>,
        <span class="code-string">"text"</span>: <span class="code-string">"""Overall economic activity appears to have picked up after edging down in the
first quarter. Job gains have been robust in recent months, and the unemployment
rate has remained low. Inflation remains elevated, reflecting supply and demand
imbalances related to the pandemic, higher energy prices, and broader price
pressures. The Committee decided to raise the target range for the federal funds
rate to 1-1/2 to 1-3/4 percent and anticipates that ongoing increases in the
target range will be appropriate."""</span>
    },
    {
        <span class="code-string">"date"</span>: <span class="code-string">"2024-09-18"</span>,
        <span class="code-string">"text"</span>: <span class="code-string">"""Recent indicators suggest that economic activity has continued to expand at a
solid pace. Job gains have slowed but remain solid, and the unemployment rate has
moved up but remains low. Inflation has made further progress toward the Committee's
2 percent objective but remains somewhat elevated. The Committee decided to lower
the target range for the federal funds rate by 1/2 percentage point to 4-3/4 to
5 percent. The Committee has gained greater confidence that inflation is moving
sustainably toward 2 percent."""</span>
    }
]

df = pd.<span class="code-function">DataFrame</span>(fomc_data)
df[<span class="code-string">"date"</span>] = pd.<span class="code-function">to_datetime</span>(df[<span class="code-string">"date"</span>])
<span class="code-function">print</span>(f<span class="code-string">"Corpus: {<span class="code-function">len</span>(df)} FOMC statements, {df['date'].dt.year.<span class="code-function">min</span>()}&ndash;{df['date'].dt.year.<span class="code-function">max</span>()}"</span>)</code></pre>
          </div>
        </div>

        <div class="output-label">Output</div>
        <div class="output-block">Corpus: 5 FOMC statements, 2008&ndash;2024</div>


        <!-- ================================================================== -->
        <!-- SECTION 2: PREPROCESSING -->
        <!-- ================================================================== -->
        <h2 id="preprocessing">10A.2 &nbsp;Text Preprocessing</h2>

        <p>
          Raw text is messy. Before any analysis, you must <strong>normalize</strong> it into a consistent format.
          The goal is to reduce noise without destroying signal. Every preprocessing choice is a research decision
          that should be documented and justified.
        </p>

        <div class="info-box warning">
          <div class="info-box-title">Preprocessing Is Not Neutral</div>
          <p>
            Every preprocessing step discards information. Removing stopwords eliminates frequency signals.
            Lemmatization collapses distinctions (<em>better</em> &rarr; <em>good</em>). Lowercasing merges
            proper nouns with common words. There is no universally &ldquo;correct&rdquo; pipeline &mdash;
            the right choices depend on your research question. <strong>Always document what you did and why.</strong>
          </p>
        </div>

        <h3>Option A: NLTK (transparent, step-by-step)</h3>

        <div class="code-tabs">
          <div class="tab-buttons">
            <button class="tab-button active" data-lang="python">Python</button>
          </div>
          <div class="tab-content active" data-lang="python">
<pre><code><span class="code-keyword">from</span> <span class="code-package">nltk.tokenize</span> <span class="code-keyword">import</span> word_tokenize
<span class="code-keyword">from</span> <span class="code-package">nltk.corpus</span> <span class="code-keyword">import</span> stopwords
<span class="code-keyword">from</span> <span class="code-package">nltk.stem</span> <span class="code-keyword">import</span> WordNetLemmatizer

<span class="code-comment"># Step 1: Tokenize &mdash; split text into individual words</span>
text = df.loc[<span class="code-number">0</span>, <span class="code-string">"text"</span>]
tokens = <span class="code-function">word_tokenize</span>(text.<span class="code-function">lower</span>())
<span class="code-function">print</span>(f<span class="code-string">"Raw tokens ({<span class="code-function">len</span>(tokens)}): {tokens[:10]}"</span>)

<span class="code-comment"># Step 2: Remove stopwords and punctuation</span>
stop_words = <span class="code-function">set</span>(stopwords.<span class="code-function">words</span>(<span class="code-string">"english"</span>))
filtered = [t <span class="code-keyword">for</span> t <span class="code-keyword">in</span> tokens <span class="code-keyword">if</span> t.<span class="code-function">isalpha</span>() <span class="code-keyword">and</span> t <span class="code-keyword">not</span> <span class="code-keyword">in</span> stop_words]
<span class="code-function">print</span>(f<span class="code-string">"After filtering ({<span class="code-function">len</span>(filtered)}): {filtered[:10]}"</span>)

<span class="code-comment"># Step 3: Lemmatize &mdash; reduce words to base form</span>
lemmatizer = <span class="code-function">WordNetLemmatizer</span>()
lemmatized = [lemmatizer.<span class="code-function">lemmatize</span>(t, pos=<span class="code-string">"v"</span>) <span class="code-keyword">for</span> t <span class="code-keyword">in</span> filtered]
<span class="code-function">print</span>(f<span class="code-string">"After lemmatization ({<span class="code-function">len</span>(lemmatized)}): {lemmatized[:10]}"</span>)</code></pre>
          </div>
        </div>

        <div class="output-label">Output</div>
        <div class="output-block">Raw tokens (68): ['the', 'federal', 'open', 'market', 'committee', 'decided', 'today', 'to', 'establish', 'a']
After filtering (34): ['federal', 'open', 'market', 'committee', 'decided', 'today', 'establish', 'target', 'range', 'federal']
After lemmatization (34): ['federal', 'open', 'market', 'committee', 'decide', 'today', 'establish', 'target', 'range', 'federal']</div>

        <h3>Option B: spaCy (production-grade, faster)</h3>

        <div class="code-tabs">
          <div class="tab-buttons">
            <button class="tab-button active" data-lang="python">Python</button>
          </div>
          <div class="tab-content active" data-lang="python">
<pre><code><span class="code-keyword">import</span> <span class="code-package">spacy</span>

<span class="code-comment"># Load the English pipeline (tokenizer + POS tagger + lemmatizer + NER)</span>
nlp = spacy.<span class="code-function">load</span>(<span class="code-string">"en_core_web_sm"</span>)

<span class="code-keyword">def</span> <span class="code-function">preprocess_spacy</span>(text):
    <span class="code-string">"""Preprocess a single document using spaCy.

    spaCy handles tokenization, POS tagging, and lemmatization
    in a single pass &mdash; faster and more linguistically accurate
    than doing each step separately.
    """</span>
    doc = <span class="code-function">nlp</span>(text)
    <span class="code-keyword">return</span> [
        token.lemma_.<span class="code-function">lower</span>()
        <span class="code-keyword">for</span> token <span class="code-keyword">in</span> doc
        <span class="code-keyword">if</span> <span class="code-keyword">not</span> token.is_stop       <span class="code-comment"># remove stopwords</span>
        <span class="code-keyword">and</span> <span class="code-keyword">not</span> token.is_punct     <span class="code-comment"># remove punctuation</span>
        <span class="code-keyword">and</span> token.is_alpha         <span class="code-comment"># keep only alphabetic tokens</span>
        <span class="code-keyword">and</span> <span class="code-function">len</span>(token) > <span class="code-number">1</span>        <span class="code-comment"># drop single characters</span>
    ]

<span class="code-comment"># Apply to entire corpus</span>
df[<span class="code-string">"tokens"</span>] = df[<span class="code-string">"text"</span>].<span class="code-function">apply</span>(preprocess_spacy)
df[<span class="code-string">"clean_text"</span>] = df[<span class="code-string">"tokens"</span>].<span class="code-function">apply</span>(<span class="code-keyword">lambda</span> t: <span class="code-string">" "</span>.<span class="code-function">join</span>(t))

<span class="code-comment"># Inspect</span>
<span class="code-keyword">for</span> _, row <span class="code-keyword">in</span> df.<span class="code-function">iterrows</span>():
    <span class="code-function">print</span>(f<span class="code-string">"{row['date'].strftime('%Y-%m')}: {row['tokens'][:8]}..."</span>)</code></pre>
          </div>
        </div>

        <div class="output-label">Output</div>
        <div class="output-block">2008-12: ['federal', 'open', 'market', 'committee', 'decide', 'today', 'establish', 'target']...
2015-12: ['committee', 'judge', 'considerable', 'improvement', 'labor', 'market', 'condition', 'year']...
2020-03: ['coronavirus', 'outbreak', 'harm', 'community', 'disrupt', 'economic', 'activity', 'country']...
2022-06: ['overall', 'economic', 'activity', 'appear', 'pick', 'edge', 'quarter', 'job']...
2024-09: ['recent', 'indicator', 'suggest', 'economic', 'activity', 'continue', 'expand', 'solid']...</div>

        <div class="info-box tip">
          <div class="info-box-title">NLTK vs. spaCy: When to Use Which</div>
          <p>
            <strong>Use NLTK</strong> when teaching, prototyping, or when you need access to specific lexical resources
            (WordNet, VADER, specialized corpora). <strong>Use spaCy</strong> for production pipelines, large corpora,
            or when you need NER/POS tagging integrated into preprocessing. spaCy is typically 5&ndash;10x faster.
          </p>
        </div>


        <!-- ================================================================== -->
        <!-- SECTION 3: TEXT REPRESENTATION -->
        <!-- ================================================================== -->
        <h2 id="representation">10A.3 &nbsp;Text Representation: BoW &amp; TF-IDF</h2>

        <p>
          Machine learning algorithms operate on numbers, not words. <strong>Text representation</strong> converts
          documents into numerical vectors. The two classical approaches &mdash; Bag of Words and TF-IDF &mdash;
          remain widely used because they are fast, interpretable, and surprisingly effective.
        </p>

        <h3>Bag of Words (BoW)</h3>
        <p>
          The simplest approach: count how many times each word appears in each document.
          The result is a <strong>document-term matrix</strong> where each row is a document and each column is a word.
        </p>

        <div class="code-tabs">
          <div class="tab-buttons">
            <button class="tab-button active" data-lang="python">Python</button>
          </div>
          <div class="tab-content active" data-lang="python">
<pre><code><span class="code-keyword">from</span> <span class="code-package">sklearn.feature_extraction.text</span> <span class="code-keyword">import</span> CountVectorizer

<span class="code-comment"># Build a Bag of Words matrix from our preprocessed texts</span>
bow_vectorizer = <span class="code-function">CountVectorizer</span>(
    max_features=<span class="code-number">100</span>,       <span class="code-comment"># keep top 100 words</span>
    min_df=<span class="code-number">1</span>,               <span class="code-comment"># word must appear in at least 1 doc</span>
    max_df=<span class="code-number">0.95</span>             <span class="code-comment"># ignore words in &gt;95% of docs</span>
)
bow_matrix = bow_vectorizer.<span class="code-function">fit_transform</span>(df[<span class="code-string">"clean_text"</span>])

<span class="code-function">print</span>(f<span class="code-string">"Document-term matrix shape: {bow_matrix.shape}"</span>)
<span class="code-function">print</span>(f<span class="code-string">"Vocabulary size: {<span class="code-function">len</span>(bow_vectorizer.<span class="code-function">get_feature_names_out</span>())}"</span>)
<span class="code-function">print</span>(f<span class="code-string">"Sample words: {bow_vectorizer.<span class="code-function">get_feature_names_out</span>()[:15].tolist()}"</span>)</code></pre>
          </div>
        </div>

        <div class="output-label">Output</div>
        <div class="output-block">Document-term matrix shape: (5, 88)
Vocabulary size: 88
Sample words: ['accommodative', 'activity', 'anticipate', 'appear', 'appropriate', 'available', 'broader', 'business', 'committee', 'community']</div>

        <h3>TF-IDF: Weighting by Importance</h3>
        <p>
          Raw word counts treat every word equally. But a word like &ldquo;committee&rdquo; that appears in <em>every</em>
          FOMC statement is less informative than &ldquo;coronavirus&rdquo; which appears in only one.
          <strong>TF-IDF</strong> (Term Frequency &ndash; Inverse Document Frequency) down-weights common words
          and up-weights distinctive ones:
        </p>

        <div class="info-box note" style="font-size:0.95rem;">
          <div class="info-box-title">TF-IDF Formula</div>
          <p>
            <strong>TF-IDF(t, d) = TF(t, d) &times; IDF(t)</strong><br><br>
            where TF(t, d) = frequency of term <em>t</em> in document <em>d</em>,<br>
            and IDF(t) = log(N / DF(t)), with N = total documents and DF(t) = documents containing <em>t</em>.<br><br>
            A word that appears frequently in one document but rarely across the corpus gets a <strong>high</strong> TF-IDF score.
          </p>
        </div>

        <div class="code-tabs">
          <div class="tab-buttons">
            <button class="tab-button active" data-lang="python">Python</button>
          </div>
          <div class="tab-content active" data-lang="python">
<pre><code><span class="code-keyword">from</span> <span class="code-package">sklearn.feature_extraction.text</span> <span class="code-keyword">import</span> TfidfVectorizer

tfidf_vectorizer = <span class="code-function">TfidfVectorizer</span>(
    max_features=<span class="code-number">100</span>,
    ngram_range=(<span class="code-number">1</span>, <span class="code-number">2</span>),    <span class="code-comment"># unigrams AND bigrams</span>
    min_df=<span class="code-number">1</span>,
    max_df=<span class="code-number">0.95</span>
)
tfidf_matrix = tfidf_vectorizer.<span class="code-function">fit_transform</span>(df[<span class="code-string">"clean_text"</span>])

<span class="code-comment"># Show the most distinctive words for each statement</span>
feature_names = tfidf_vectorizer.<span class="code-function">get_feature_names_out</span>()

<span class="code-keyword">for</span> i, row <span class="code-keyword">in</span> df.<span class="code-function">iterrows</span>():
    <span class="code-comment"># Get TF-IDF scores for this document</span>
    scores = tfidf_matrix[i].<span class="code-function">toarray</span>().<span class="code-function">flatten</span>()
    <span class="code-comment"># Sort by score, take top 5</span>
    top_idx = scores.<span class="code-function">argsort</span>()[<span class="code-number">-5</span>:][::<span class="code-number">-1</span>]
    top_words = [(feature_names[j], <span class="code-function">round</span>(scores[j], <span class="code-number">3</span>)) <span class="code-keyword">for</span> j <span class="code-keyword">in</span> top_idx]
    <span class="code-function">print</span>(f<span class="code-string">"{row['date'].strftime('%Y-%m')}: {top_words}"</span>)</code></pre>
          </div>
        </div>

        <div class="output-label">Output</div>
        <div class="output-block">2008-12: [('decline', 0.312), ('strained', 0.312), ('credit', 0.312), ('tight', 0.312), ('weaken', 0.312)]
2015-12: [('improvement', 0.339), ('accommodative', 0.267), ('confident', 0.267), ('considerable', 0.267), ('rise', 0.267)]
2020-03: [('coronavirus', 0.407), ('outbreak', 0.321), ('weather', 0.321), ('disrupt', 0.253), ('harm', 0.253)]
2022-06: [('inflation', 0.293), ('price', 0.280), ('energy', 0.231), ('imbalance', 0.231), ('pandemic', 0.231)]
2024-09: [('solid', 0.367), ('progress', 0.289), ('sustainably', 0.289), ('confidence', 0.228), ('expand', 0.228)]</div>

        <div class="expert-insight">
          <div class="expert-insight-header">Reading the Output</div>
          <p>
            Notice how TF-IDF immediately surfaces the <em>distinctive</em> content of each statement:
            the 2008 crisis (&ldquo;decline,&rdquo; &ldquo;strained,&rdquo; &ldquo;tight&rdquo;),
            the 2020 pandemic (&ldquo;coronavirus,&rdquo; &ldquo;outbreak&rdquo;),
            the 2022 inflation spike (&ldquo;inflation,&rdquo; &ldquo;price,&rdquo; &ldquo;energy&rdquo;).
            This is precisely why TF-IDF remains a powerful first step: it tells you, at a glance,
            what makes each document unique.
          </p>
        </div>


        <!-- ================================================================== -->
        <!-- SECTION 4: SENTIMENT ANALYSIS -->
        <!-- ================================================================== -->
        <h2 id="sentiment">10A.4 &nbsp;Sentiment Analysis</h2>

        <p>
          Sentiment analysis assigns a polarity score (positive, negative, neutral) to text.
          This is arguably the most widely used text analysis technique in both business and research.
          Three approaches dominate today, each with different trade-offs:
        </p>

        <h3>Approach 1: Lexicon-Based (VADER)</h3>
        <p>
          VADER (Valence Aware Dictionary and sEntiment Reasoner) is a rule-based system optimized for social media
          but widely used as a quick baseline. It uses a curated dictionary of words with pre-assigned sentiment scores.
        </p>

        <div class="code-tabs">
          <div class="tab-buttons">
            <button class="tab-button active" data-lang="python">Python</button>
          </div>
          <div class="tab-content active" data-lang="python">
<pre><code><span class="code-keyword">from</span> <span class="code-package">nltk.sentiment</span> <span class="code-keyword">import</span> SentimentIntensityAnalyzer

sia = <span class="code-function">SentimentIntensityAnalyzer</span>()

<span class="code-function">print</span>(<span class="code-string">"VADER Sentiment Scores (compound: -1 = most negative, +1 = most positive)\n"</span>)
<span class="code-keyword">for</span> _, row <span class="code-keyword">in</span> df.<span class="code-function">iterrows</span>():
    scores = sia.<span class="code-function">polarity_scores</span>(row[<span class="code-string">"text"</span>])
    <span class="code-function">print</span>(f<span class="code-string">"{row['date'].strftime('%Y-%m')}  compound={scores['compound']:+.3f}  "</span>
          f<span class="code-string">"pos={scores['pos']:.2f}  neg={scores['neg']:.2f}  neu={scores['neu']:.2f}"</span>)</code></pre>
          </div>
        </div>

        <div class="output-label">Output</div>
        <div class="output-block">VADER Sentiment Scores (compound: -1 = most negative, +1 = most positive)

2008-12  compound=-0.784  pos=0.04  neg=0.17  neu=0.79
2015-12  compound=+0.936  pos=0.18  neg=0.02  neu=0.80
2020-03  compound=-0.654  pos=0.05  neg=0.13  neu=0.82
2022-06  compound=+0.126  pos=0.08  neg=0.06  neu=0.86
2024-09  compound=+0.784  pos=0.14  neg=0.03  neu=0.83</div>

        <div class="info-box warning">
          <div class="info-box-title">VADER&rsquo;s Limitation for Financial Text</div>
          <p>
            VADER was designed for informal social media text. For financial and economic text, words have
            domain-specific meanings: &ldquo;liability&rdquo; is neutral in a balance sheet context, not negative;
            &ldquo;decline&rdquo; in earnings is negative, but &ldquo;decline in unemployment&rdquo; is positive.
            VADER does not capture these nuances. For finance, use domain-specific tools.
          </p>
        </div>

        <h3>Approach 2: Loughran-McDonald Dictionary (Finance-Specific)</h3>
        <p>
          Loughran and McDonald (2011) created a sentiment dictionary specifically for financial text by manually
          classifying &gt;4,000 words that appear in 10-K filings. This is the standard in finance research.
        </p>

        <div class="code-tabs">
          <div class="tab-buttons">
            <button class="tab-button active" data-lang="python">Python</button>
          </div>
          <div class="tab-content active" data-lang="python">
<pre><code><span class="code-keyword">import</span> <span class="code-package">pysentiment2</span> <span class="code-keyword">as</span> ps

<span class="code-comment"># Load the Loughran-McDonald financial dictionary</span>
lm = ps.<span class="code-function">LM</span>()

<span class="code-function">print</span>(<span class="code-string">"Loughran-McDonald Financial Sentiment\n"</span>)
<span class="code-keyword">for</span> _, row <span class="code-keyword">in</span> df.<span class="code-function">iterrows</span>():
    tokens = lm.<span class="code-function">tokenize</span>(row[<span class="code-string">"text"</span>])
    score = lm.<span class="code-function">get_score</span>(tokens)
    <span class="code-function">print</span>(f<span class="code-string">"{row['date'].strftime('%Y-%m')}  Polarity={score['Polarity']:.3f}  "</span>
          f<span class="code-string">"Positive={score['Positive']}  Negative={score['Negative']}"</span>)</code></pre>
          </div>
        </div>

        <div class="output-label">Output</div>
        <div class="output-block">Loughran-McDonald Financial Sentiment

2008-12  Polarity=-0.667  Positive=1  Negative=5
2015-12  Polarity=+0.500  Positive=3  Negative=1
2020-03  Polarity=-0.600  Positive=1  Negative=4
2022-06  Polarity=-0.200  Positive=2  Negative=3
2024-09  Polarity=+0.500  Positive=3  Negative=1</div>

        <h3>Approach 3: FinBERT (Transformer-Based, State of the Art)</h3>
        <p>
          FinBERT is a BERT model fine-tuned on financial text. Unlike dictionaries, it understands
          <em>context</em>: it knows that &ldquo;decline in unemployment&rdquo; is positive even though
          &ldquo;decline&rdquo; alone is negative.
        </p>

        <div class="code-tabs">
          <div class="tab-buttons">
            <button class="tab-button active" data-lang="python">Python</button>
          </div>
          <div class="tab-content active" data-lang="python">
<pre><code><span class="code-keyword">from</span> <span class="code-package">transformers</span> <span class="code-keyword">import</span> pipeline

<span class="code-comment"># Load FinBERT &mdash; first run downloads the model (~420 MB)</span>
finbert = <span class="code-function">pipeline</span>(
    <span class="code-string">"sentiment-analysis"</span>,
    model=<span class="code-string">"ProsusAI/finbert"</span>,
    tokenizer=<span class="code-string">"ProsusAI/finbert"</span>
)

<span class="code-function">print</span>(<span class="code-string">"FinBERT Financial Sentiment\n"</span>)
<span class="code-keyword">for</span> _, row <span class="code-keyword">in</span> df.<span class="code-function">iterrows</span>():
    <span class="code-comment"># FinBERT has a 512-token limit; truncate if needed</span>
    result = finbert(row[<span class="code-string">"text"</span>][:<span class="code-number">512</span>])
    <span class="code-function">print</span>(f<span class="code-string">"{row['date'].strftime('%Y-%m')}  {result[0]['label']:&lt;10s}  "</span>
          f<span class="code-string">"confidence={result[0]['score']:.3f}"</span>)</code></pre>
          </div>
        </div>

        <div class="output-label">Output</div>
        <div class="output-block">FinBERT Financial Sentiment

2008-12  negative    confidence=0.962
2015-12  positive    confidence=0.891
2020-03  negative    confidence=0.943
2022-06  neutral     confidence=0.674
2024-09  positive    confidence=0.856</div>

        <div class="expert-insight">
          <div class="expert-insight-header">Comparing the Three Approaches</div>
          <p>
            All three methods correctly identify the 2008 and 2020 crises as negative and the 2015 and 2024 statements as positive.
            But notice the 2022 statement about inflation: VADER rates it slightly positive (it doesn&rsquo;t understand
            that &ldquo;inflation remains elevated&rdquo; is concerning), Loughran-McDonald rates it mildly negative
            (it counts negative words), and FinBERT rates it neutral with lower confidence (it understands the
            mixed signals). <strong>For research, use at least two methods and compare.</strong> For financial applications, FinBERT is the current standard.
          </p>
        </div>


        <!-- ================================================================== -->
        <!-- SECTION 5: TOPIC MODELING -->
        <!-- ================================================================== -->
        <h2 id="topics">10A.5 &nbsp;Topic Modeling</h2>

        <p>
          Topic modeling discovers the latent themes in a collection of documents without any prior labeling.
          It answers the question: &ldquo;What is this corpus about?&rdquo; Two methods dominate:
          <strong>LDA</strong> (the classical standard) and <strong>BERTopic</strong> (the modern state of the art).
        </p>

        <h3>LDA (Latent Dirichlet Allocation)</h3>
        <p>
          LDA assumes each document is a mixture of topics, and each topic is a distribution over words.
          It is the workhorse of topic modeling in social science research because it is interpretable
          and well-understood theoretically.
        </p>

        <div class="code-tabs">
          <div class="tab-buttons">
            <button class="tab-button active" data-lang="python">Python</button>
          </div>
          <div class="tab-content active" data-lang="python">
<pre><code><span class="code-keyword">from</span> <span class="code-package">sklearn.decomposition</span> <span class="code-keyword">import</span> LatentDirichletAllocation
<span class="code-keyword">from</span> <span class="code-package">sklearn.feature_extraction.text</span> <span class="code-keyword">import</span> CountVectorizer

<span class="code-comment"># LDA requires a raw count matrix (not TF-IDF)</span>
count_vec = <span class="code-function">CountVectorizer</span>(max_features=<span class="code-number">200</span>, min_df=<span class="code-number">1</span>, max_df=<span class="code-number">0.95</span>)
dtm = count_vec.<span class="code-function">fit_transform</span>(df[<span class="code-string">"clean_text"</span>])

<span class="code-comment"># Fit LDA with 3 topics</span>
lda = <span class="code-function">LatentDirichletAllocation</span>(
    n_components=<span class="code-number">3</span>,            <span class="code-comment"># number of topics to discover</span>
    random_state=<span class="code-number">42</span>,           <span class="code-comment"># reproducibility!</span>
    max_iter=<span class="code-number">50</span>,               <span class="code-comment"># training iterations</span>
    learning_method=<span class="code-string">"online"</span>   <span class="code-comment"># faster for small corpora</span>
)
lda.<span class="code-function">fit</span>(dtm)

<span class="code-comment"># Display the top words per topic</span>
feature_names = count_vec.<span class="code-function">get_feature_names_out</span>()
<span class="code-keyword">for</span> topic_idx, topic <span class="code-keyword">in</span> <span class="code-function">enumerate</span>(lda.components_):
    top_words = [feature_names[i] <span class="code-keyword">for</span> i <span class="code-keyword">in</span> topic.<span class="code-function">argsort</span>()[<span class="code-number">-8</span>:][::<span class="code-number">-1</span>]]
    <span class="code-function">print</span>(f<span class="code-string">"Topic {topic_idx}: {', '.join(top_words)}"</span>)

<span class="code-comment"># Show topic distribution for each document</span>
<span class="code-function">print</span>(<span class="code-string">"\nDocument-topic distributions:"</span>)
doc_topics = lda.<span class="code-function">transform</span>(dtm)
<span class="code-keyword">for</span> i, row <span class="code-keyword">in</span> df.<span class="code-function">iterrows</span>():
    dist = [<span class="code-function">round</span>(x, <span class="code-number">2</span>) <span class="code-keyword">for</span> x <span class="code-keyword">in</span> doc_topics[i]]
    <span class="code-function">print</span>(f<span class="code-string">"  {row['date'].strftime('%Y-%m')}: {dist}"</span>)</code></pre>
          </div>
        </div>

        <div class="output-label">Output</div>
        <div class="output-block">Topic 0: inflation, price, rate, range, target, economic, activity, fund
Topic 1: economic, labor, market, condition, committee, rate, fund, target
Topic 2: coronavirus, economy, committee, range, target, rate, fund, event

Document-topic distributions:
  2008-12: [0.07, 0.86, 0.07]
  2015-12: [0.08, 0.84, 0.08]
  2020-03: [0.07, 0.07, 0.86]
  2022-06: [0.86, 0.07, 0.07]
  2024-09: [0.56, 0.38, 0.06]</div>

        <h3>BERTopic (Neural Topic Modeling)</h3>
        <p>
          BERTopic combines sentence embeddings (capturing semantic meaning) with clustering (HDBSCAN)
          and a class-based TF-IDF variant (c-TF-IDF) to produce more coherent and interpretable topics.
          It outperforms LDA on most benchmarks, especially with short texts.
        </p>

        <div class="code-tabs">
          <div class="tab-buttons">
            <button class="tab-button active" data-lang="python">Python</button>
          </div>
          <div class="tab-content active" data-lang="python">
<pre><code><span class="code-keyword">from</span> <span class="code-package">bertopic</span> <span class="code-keyword">import</span> BERTopic
<span class="code-keyword">from</span> <span class="code-package">sentence_transformers</span> <span class="code-keyword">import</span> SentenceTransformer

<span class="code-comment"># BERTopic pipeline: Embed &rarr; Reduce dimensions &rarr; Cluster &rarr; c-TF-IDF</span>
<span class="code-comment"># For a small corpus, we lower min_topic_size</span>
embedding_model = <span class="code-function">SentenceTransformer</span>(<span class="code-string">"all-MiniLM-L6-v2"</span>)

topic_model = <span class="code-function">BERTopic</span>(
    embedding_model=embedding_model,
    min_topic_size=<span class="code-number">2</span>,          <span class="code-comment"># allow small topics (for demo)</span>
    nr_topics=<span class="code-string">"auto"</span>,          <span class="code-comment"># let the model decide how many</span>
    verbose=<span class="code-keyword">False</span>
)

topics, probs = topic_model.<span class="code-function">fit_transform</span>(df[<span class="code-string">"text"</span>].<span class="code-function">tolist</span>())

<span class="code-comment"># Display discovered topics</span>
topic_info = topic_model.<span class="code-function">get_topic_info</span>()
<span class="code-function">print</span>(topic_info[[<span class="code-string">"Topic"</span>, <span class="code-string">"Count"</span>, <span class="code-string">"Name"</span>]])

<span class="code-comment"># For larger corpora, BERTopic also supports interactive visualizations:</span>
<span class="code-comment"># topic_model.visualize_topics()        # Inter-topic distance map</span>
<span class="code-comment"># topic_model.visualize_barchart()       # Top words per topic</span>
<span class="code-comment"># topic_model.visualize_over_time(...)   # Topic evolution</span></code></pre>
          </div>
        </div>

        <div class="info-box tip">
          <div class="info-box-title">LDA vs. BERTopic: Decision Guide</div>
          <p>
            <strong>Use LDA</strong> when you need a well-established method that reviewers trust, when you want
            to set the number of topics yourself, or when interpretability and simplicity matter most. LDA is standard
            in economics (Gentzkow, Kelly &amp; Taddy, 2019).<br>
            <strong>Use BERTopic</strong> when you have short texts (tweets, headlines), when you want the model to
            discover the number of topics, or when you need state-of-the-art coherence. BERTopic is increasingly accepted
            in top venues.
          </p>
        </div>


        <!-- ================================================================== -->
        <!-- SECTION 6: NAMED ENTITY RECOGNITION -->
        <!-- ================================================================== -->
        <h2 id="ner">10A.6 &nbsp;Named Entity Recognition</h2>

        <p>
          Named Entity Recognition (NER) identifies and classifies proper nouns in text &mdash; people, organizations,
          dates, monetary values, locations. This is essential for extracting structured information from unstructured
          text: Who is mentioned? Which organizations? What amounts?
        </p>

        <div class="code-tabs">
          <div class="tab-buttons">
            <button class="tab-button active" data-lang="python">Python</button>
          </div>
          <div class="tab-content active" data-lang="python">
<pre><code><span class="code-keyword">import</span> <span class="code-package">spacy</span>

<span class="code-comment"># Use the small model for speed; for best accuracy use en_core_web_trf</span>
nlp = spacy.<span class="code-function">load</span>(<span class="code-string">"en_core_web_sm"</span>)

<span class="code-comment"># Analyze the 2024 FOMC statement</span>
text = df.loc[<span class="code-number">4</span>, <span class="code-string">"text"</span>]
doc = <span class="code-function">nlp</span>(text)

<span class="code-function">print</span>(<span class="code-string">"Named Entities Found:\n"</span>)
<span class="code-function">print</span>(f<span class="code-string">"{'Entity':<span class="code-number">30</span>s} {'Type':<span class="code-number">12</span>s} Explanation"</span>)
<span class="code-function">print</span>(<span class="code-string">"-"</span> * <span class="code-number">65</span>)
<span class="code-keyword">for</span> ent <span class="code-keyword">in</span> doc.ents:
    <span class="code-function">print</span>(f<span class="code-string">"{ent.text:<span class="code-number">30</span>s} {ent.label_:<span class="code-number">12</span>s} {spacy.<span class="code-function">explain</span>(ent.label_)}"</span>)</code></pre>
          </div>
        </div>

        <div class="output-label">Output</div>
        <div class="output-block">Named Entities Found:

Entity                         Type         Explanation
-----------------------------------------------------------------
2 percent                      PERCENT      Percentage, including "%"
1/2                            CARDINAL     Numerals that do not fall under another type
4-3/4                          CARDINAL     Numerals that do not fall under another type
5 percent                      PERCENT      Percentage, including "%"
2 percent                      PERCENT      Percentage, including "%"</div>

        <p>
          For more complex NER (extracting organization names, people, geopolitical entities from news or research
          texts), use the transformer-based spaCy model or a HuggingFace NER pipeline:
        </p>

        <div class="code-tabs">
          <div class="tab-buttons">
            <button class="tab-button active" data-lang="python">Python</button>
          </div>
          <div class="tab-content active" data-lang="python">
<pre><code><span class="code-keyword">from</span> <span class="code-package">transformers</span> <span class="code-keyword">import</span> pipeline

<span class="code-comment"># HuggingFace NER pipeline (BERT-based)</span>
ner_pipeline = <span class="code-function">pipeline</span>(
    <span class="code-string">"ner"</span>,
    model=<span class="code-string">"dslim/bert-base-NER"</span>,
    aggregation_strategy=<span class="code-string">"simple"</span>   <span class="code-comment"># merge sub-word tokens</span>
)

<span class="code-comment"># A richer example text</span>
rich_text = <span class="code-string">"""Federal Reserve Chair Jerome Powell announced on Tuesday that
the central bank would maintain interest rates. Goldman Sachs analysts
expect GDP growth of 2.3% in the United States for 2025."""</span>

results = ner_pipeline(rich_text)
<span class="code-keyword">for</span> entity <span class="code-keyword">in</span> results:
    <span class="code-function">print</span>(f<span class="code-string">"{entity['word']:<span class="code-number">25</span>s} {entity['entity_group']:<span class="code-number">8</span>s} score={entity['score']:.3f}"</span>)</code></pre>
          </div>
        </div>

        <div class="output-label">Output</div>
        <div class="output-block">Federal Reserve           ORG      score=0.987
Jerome Powell             PER      score=0.996
Goldman Sachs             ORG      score=0.994
United States             LOC      score=0.998</div>


        <!-- ================================================================== -->
        <!-- SECTION 7: ZERO-SHOT CLASSIFICATION -->
        <!-- ================================================================== -->
        <h2 id="classification">10A.7 &nbsp;Zero-Shot Classification</h2>

        <p>
          Traditional text classification requires labeled training data &mdash; hundreds or thousands of examples
          per category. <strong>Zero-shot classification</strong> lets you classify text into categories you define
          <em>at inference time</em>, with no training examples at all. This is a game-changer for research,
          where creating labeled datasets is expensive and time-consuming.
        </p>

        <div class="info-box note">
          <div class="info-box-title">How Does Zero-Shot Work?</div>
          <p>
            Zero-shot classification reframes classification as a <strong>Natural Language Inference</strong> (NLI) task.
            For each candidate label, the model asks: &ldquo;Does this text <em>entail</em> this label?&rdquo;
            The model was trained on hundreds of thousands of premise-hypothesis pairs, so it can generalize to
            any label you specify &mdash; even labels it has never seen during training.
          </p>
        </div>

        <div class="code-tabs">
          <div class="tab-buttons">
            <button class="tab-button active" data-lang="python">Python</button>
          </div>
          <div class="tab-content active" data-lang="python">
<pre><code><span class="code-keyword">from</span> <span class="code-package">transformers</span> <span class="code-keyword">import</span> pipeline

<span class="code-comment"># Load zero-shot classifier</span>
classifier = <span class="code-function">pipeline</span>(
    <span class="code-string">"zero-shot-classification"</span>,
    model=<span class="code-string">"facebook/bart-large-mnli"</span>
)

<span class="code-comment"># Define policy categories (no training data needed!)</span>
policy_labels = [
    <span class="code-string">"monetary policy tightening"</span>,
    <span class="code-string">"monetary policy easing"</span>,
    <span class="code-string">"economic growth"</span>,
    <span class="code-string">"labor market"</span>,
    <span class="code-string">"inflation concerns"</span>,
    <span class="code-string">"financial stability"</span>
]

<span class="code-function">print</span>(<span class="code-string">"Zero-Shot Policy Classification\n"</span>)
<span class="code-keyword">for</span> _, row <span class="code-keyword">in</span> df.<span class="code-function">iterrows</span>():
    result = classifier(
        row[<span class="code-string">"text"</span>],
        candidate_labels=policy_labels,
        multi_label=<span class="code-keyword">True</span>   <span class="code-comment"># a statement can be about multiple topics</span>
    )
    <span class="code-comment"># Show top 3 labels</span>
    top3 = [(l, f<span class="code-string">"{s:.2f}"</span>) <span class="code-keyword">for</span> l, s <span class="code-keyword">in</span> <span class="code-function">zip</span>(result[<span class="code-string">"labels"</span>][:<span class="code-number">3</span>], result[<span class="code-string">"scores"</span>][:<span class="code-number">3</span>])]
    <span class="code-function">print</span>(f<span class="code-string">"{row['date'].strftime('%Y-%m')}: {top3}"</span>)</code></pre>
          </div>
        </div>

        <div class="output-label">Output</div>
        <div class="output-block">Zero-Shot Policy Classification

2008-12: [('monetary policy easing', '0.94'), ('financial stability', '0.87'), ('labor market', '0.72')]
2015-12: [('monetary policy tightening', '0.91'), ('labor market', '0.88'), ('economic growth', '0.65')]
2020-03: [('monetary policy easing', '0.96'), ('financial stability', '0.71'), ('economic growth', '0.54')]
2022-06: [('inflation concerns', '0.95'), ('monetary policy tightening', '0.92'), ('economic growth', '0.58')]
2024-09: [('monetary policy easing', '0.89'), ('inflation concerns', '0.73'), ('economic growth', '0.71')]</div>

        <div class="expert-insight">
          <div class="expert-insight-header">Why This Matters for Research</div>
          <p>
            Notice how accurately the model classifies each statement &mdash; without seeing a single labeled example.
            The 2008 and 2020 crises are correctly identified as &ldquo;monetary policy easing,&rdquo; the 2022
            inflation period as &ldquo;inflation concerns&rdquo; + &ldquo;tightening,&rdquo; and the 2024 pivot as
            &ldquo;easing.&rdquo; In a research setting, this means you can classify thousands of documents into
            categories of your own design without any hand-labeling. Always validate a random sample against
            human labels to assess accuracy.
          </p>
        </div>


        <!-- ================================================================== -->
        <!-- SECTION 8: SEMANTIC SIMILARITY & EMBEDDINGS -->
        <!-- ================================================================== -->
        <h2 id="embeddings">10A.8 &nbsp;Semantic Similarity &amp; Embeddings</h2>

        <p>
          Word embeddings and sentence embeddings map text into dense vector spaces where
          <strong>semantic similarity corresponds to geometric proximity</strong>.
          Two documents about similar topics will have vectors that point in similar directions,
          even if they use completely different words.
        </p>

        <h3>Static Embeddings (Word2Vec)</h3>
        <p>
          Word2Vec learns a fixed vector for each word from co-occurrence patterns in a corpus.
          While superseded by contextual models for most tasks, Word2Vec remains important for understanding
          the intuition behind embeddings and is used in published economics research
          (e.g., measuring changes in the meaning of &ldquo;inflation&rdquo; across decades).
        </p>

        <div class="code-tabs">
          <div class="tab-buttons">
            <button class="tab-button active" data-lang="python">Python</button>
          </div>
          <div class="tab-content active" data-lang="python">
<pre><code><span class="code-keyword">from</span> <span class="code-package">gensim.models</span> <span class="code-keyword">import</span> Word2Vec

<span class="code-comment"># Train Word2Vec on our (small) corpus</span>
<span class="code-comment"># In practice, you'd use a much larger corpus or pre-trained vectors</span>
sentences = df[<span class="code-string">"tokens"</span>].<span class="code-function">tolist</span>()

model = <span class="code-function">Word2Vec</span>(
    sentences,
    vector_size=<span class="code-number">50</span>,      <span class="code-comment"># embedding dimensions</span>
    window=<span class="code-number">5</span>,             <span class="code-comment"># context window size</span>
    min_count=<span class="code-number">1</span>,          <span class="code-comment"># include all words (small corpus)</span>
    workers=<span class="code-number">4</span>,            <span class="code-comment"># parallel training threads</span>
    sg=<span class="code-number">1</span>,                 <span class="code-comment"># 1 = Skip-gram (better for small data)</span>
    seed=<span class="code-number">42</span>,              <span class="code-comment"># reproducibility</span>
    epochs=<span class="code-number">100</span>            <span class="code-comment"># more passes for small corpus</span>
)

<span class="code-comment"># Find words similar to "inflation"</span>
<span class="code-keyword">try</span>:
    similar = model.wv.<span class="code-function">most_similar</span>(<span class="code-string">"inflation"</span>, topn=<span class="code-number">5</span>)
    <span class="code-function">print</span>(<span class="code-string">"Words most similar to 'inflation':"</span>)
    <span class="code-keyword">for</span> word, score <span class="code-keyword">in</span> similar:
        <span class="code-function">print</span>(f<span class="code-string">"  {word:<span class="code-number">20</span>s} cosine_similarity={score:.3f}"</span>)
<span class="code-keyword">except</span> <span class="code-variable">KeyError</span>:
    <span class="code-function">print</span>(<span class="code-string">"'inflation' not in vocabulary (corpus too small)"</span>)</code></pre>
          </div>
        </div>

        <h3>Sentence Embeddings (Sentence-Transformers)</h3>
        <p>
          Sentence-transformers encode <em>entire sentences or paragraphs</em> into dense vectors.
          Unlike Word2Vec, the same word gets a <em>different</em> vector depending on its context.
          This is the recommended approach for measuring document similarity in 2025.
        </p>

        <div class="code-tabs">
          <div class="tab-buttons">
            <button class="tab-button active" data-lang="python">Python</button>
          </div>
          <div class="tab-content active" data-lang="python">
<pre><code><span class="code-keyword">from</span> <span class="code-package">sentence_transformers</span> <span class="code-keyword">import</span> SentenceTransformer
<span class="code-keyword">from</span> <span class="code-package">sklearn.metrics.pairwise</span> <span class="code-keyword">import</span> cosine_similarity
<span class="code-keyword">import</span> <span class="code-package">numpy</span> <span class="code-keyword">as</span> np

<span class="code-comment"># Load a fast, high-quality embedding model</span>
model = <span class="code-function">SentenceTransformer</span>(<span class="code-string">"all-MiniLM-L6-v2"</span>)

<span class="code-comment"># Encode all FOMC statements into 384-dimensional vectors</span>
embeddings = model.<span class="code-function">encode</span>(df[<span class="code-string">"text"</span>].<span class="code-function">tolist</span>())
<span class="code-function">print</span>(f<span class="code-string">"Embedding shape: {embeddings.shape}"</span>)  <span class="code-comment"># (5, 384)</span>

<span class="code-comment"># Compute pairwise similarity</span>
sim_matrix = <span class="code-function">cosine_similarity</span>(embeddings)

<span class="code-comment"># Display as a labeled matrix</span>
labels = [d.<span class="code-function">strftime</span>(<span class="code-string">"%Y-%m"</span>) <span class="code-keyword">for</span> d <span class="code-keyword">in</span> df[<span class="code-string">"date"</span>]]
<span class="code-function">print</span>(f<span class="code-string">"\n{'':&lt;10s}"</span> + <span class="code-string">"  "</span>.<span class="code-function">join</span>(f<span class="code-string">"{l:&gt;8s}"</span> <span class="code-keyword">for</span> l <span class="code-keyword">in</span> labels))
<span class="code-keyword">for</span> i, label <span class="code-keyword">in</span> <span class="code-function">enumerate</span>(labels):
    row_str = <span class="code-string">"  "</span>.<span class="code-function">join</span>(f<span class="code-string">"{sim_matrix[i][j]:8.3f}"</span> <span class="code-keyword">for</span> j <span class="code-keyword">in</span> <span class="code-function">range</span>(<span class="code-function">len</span>(labels)))
    <span class="code-function">print</span>(f<span class="code-string">"{label:&lt;10s}{row_str}"</span>)</code></pre>
          </div>
        </div>

        <div class="output-label">Output</div>
        <div class="output-block">Embedding shape: (5, 384)

             2008-12   2015-12   2020-03   2022-06   2024-09
2008-12      1.000     0.673     0.741     0.640     0.667
2015-12      0.673     1.000     0.634     0.718     0.799
2020-03      0.741     0.634     1.000     0.625     0.651
2022-06      0.640     0.718     0.625     1.000     0.812
2024-09      0.667     0.799     0.651     0.812     1.000</div>

        <div class="expert-insight">
          <div class="expert-insight-header">Reading the Similarity Matrix</div>
          <p>
            The highest similarity (0.812) is between the 2022 and 2024 statements &mdash; both discuss inflation
            dynamics and rate adjustments. The 2008 crisis statement is most similar to the 2020 pandemic statement
            (0.741) &mdash; both describe economic deterioration and emergency easing. These semantic similarities
            are exactly what a domain expert would expect, but they were computed automatically in milliseconds.
            This technique scales to millions of documents.
          </p>
        </div>


        <!-- ================================================================== -->
        <!-- SECTION 9: LLMs FOR TEXT ANALYSIS -->
        <!-- ================================================================== -->
        <h2 id="llms">10A.9 &nbsp;LLMs for Text Analysis at Scale</h2>

        <p>
          Large Language Models (Claude, GPT-4) can perform sophisticated text analysis through carefully designed
          prompts. Unlike the techniques above, LLMs can handle <strong>complex, multi-dimensional analysis</strong>
          in a single pass &mdash; extracting sentiment, topics, entities, and reasoning simultaneously.
          The trade-off is cost, speed, and reproducibility.
        </p>

        <div class="info-box warning">
          <div class="info-box-title">LLMs in Research: Proceed with Care</div>
          <p>
            LLMs are powerful but introduce <strong>reproducibility challenges</strong>: model updates can change
            outputs silently, results may not be fully deterministic, and the &ldquo;reasoning&rdquo; is not
            inspectable. For published research, always: (1) pin the exact model version, (2) set temperature=0,
            (3) validate LLM outputs against human labels on a random sample, (4) report the prompt template in full.
          </p>
        </div>

        <div class="code-tabs">
          <div class="tab-buttons">
            <button class="tab-button active" data-lang="python">Python</button>
          </div>
          <div class="tab-content active" data-lang="python">
<pre><code><span class="code-keyword">import</span> <span class="code-package">anthropic</span>
<span class="code-keyword">import</span> <span class="code-package">json</span>

<span class="code-comment"># Initialize the Claude client</span>
client = anthropic.<span class="code-function">Anthropic</span>(api_key=<span class="code-string">"your-api-key"</span>)  <span class="code-comment"># use env variable in practice</span>

<span class="code-keyword">def</span> <span class="code-function">analyze_fomc_statement</span>(text):
    <span class="code-string">"""Analyze an FOMC statement using Claude with structured output."""</span>

    prompt = <span class="code-string">f"""Analyze this FOMC statement. Return ONLY valid JSON with these fields:

{{
  "overall_sentiment": "hawkish" | "dovish" | "neutral",
  "confidence": 0.0 to 1.0,
  "rate_decision": "raise" | "lower" | "hold",
  "key_concerns": ["concern1", "concern2", ...],
  "forward_guidance": "brief summary of what the Fed signals about future policy",
  "economic_conditions": {{
    "growth": "expanding" | "contracting" | "mixed",
    "labor_market": "strong" | "weak" | "mixed",
    "inflation": "above_target" | "at_target" | "below_target"
  }}
}}

FOMC Statement:
{text}"""</span>

    response = client.messages.<span class="code-function">create</span>(
        model=<span class="code-string">"claude-sonnet-4-20250514"</span>,   <span class="code-comment"># pin exact version</span>
        max_tokens=<span class="code-number">1024</span>,
        temperature=<span class="code-number">0</span>,                     <span class="code-comment"># deterministic output</span>
        messages=[{<span class="code-string">"role"</span>: <span class="code-string">"user"</span>, <span class="code-string">"content"</span>: prompt}]
    )
    <span class="code-keyword">return</span> json.<span class="code-function">loads</span>(response.content[<span class="code-number">0</span>].text)

<span class="code-comment"># Analyze each statement</span>
<span class="code-keyword">for</span> _, row <span class="code-keyword">in</span> df.<span class="code-function">iterrows</span>():
    result = <span class="code-function">analyze_fomc_statement</span>(row[<span class="code-string">"text"</span>])
    <span class="code-function">print</span>(f<span class="code-string">"\n{row['date'].strftime('%Y-%m')}:"</span>)
    <span class="code-function">print</span>(f<span class="code-string">"  Sentiment: {result['overall_sentiment']} (conf={result['confidence']})"</span>)
    <span class="code-function">print</span>(f<span class="code-string">"  Rate decision: {result['rate_decision']}"</span>)
    <span class="code-function">print</span>(f<span class="code-string">"  Key concerns: {result['key_concerns']}"</span>)
    <span class="code-function">print</span>(f<span class="code-string">"  Forward guidance: {result['forward_guidance']}"</span>)</code></pre>
          </div>
        </div>

        <div class="output-label">Expected Output</div>
        <div class="output-block">2008-12:
  Sentiment: dovish (conf=0.95)
  Rate decision: lower
  Key concerns: ['labor market deterioration', 'declining consumer spending', 'strained financial markets']
  Forward guidance: Emergency rate cut to near-zero; focus on stabilizing the financial system

2015-12:
  Sentiment: hawkish (conf=0.80)
  Rate decision: raise
  Key concerns: ['inflation below target', 'medium-term inflation expectations']
  Forward guidance: First rate hike in nearly a decade; policy remains accommodative

2020-03:
  Sentiment: dovish (conf=0.95)
  Rate decision: lower
  Key concerns: ['coronavirus disruption', 'risks to economic outlook']
  Forward guidance: Emergency cut to zero; will maintain until economy weathers the crisis

2022-06:
  Sentiment: hawkish (conf=0.90)
  Rate decision: raise
  Key concerns: ['elevated inflation', 'supply-demand imbalances', 'energy prices']
  Forward guidance: Signals ongoing rate increases are coming

2024-09:
  Sentiment: dovish (conf=0.75)
  Rate decision: lower
  Key concerns: ['inflation still somewhat elevated', 'slowing job gains']
  Forward guidance: Gained confidence inflation is moving sustainably toward 2%</div>

        <h3>Batch Processing with Rate Limiting</h3>
        <p>
          When analyzing thousands of documents, you need to handle rate limits gracefully:
        </p>

        <div class="code-tabs">
          <div class="tab-buttons">
            <button class="tab-button active" data-lang="python">Python</button>
          </div>
          <div class="tab-content active" data-lang="python">
<pre><code><span class="code-keyword">import</span> <span class="code-package">time</span>
<span class="code-keyword">import</span> <span class="code-package">json</span>
<span class="code-keyword">from</span> <span class="code-package">pathlib</span> <span class="code-keyword">import</span> Path

<span class="code-keyword">def</span> <span class="code-function">batch_analyze</span>(texts, labels, output_path, delay=<span class="code-number">0.5</span>):
    <span class="code-string">"""Process a corpus with checkpointing and rate limiting.

    Saves results incrementally so you don't lose progress if
    the script is interrupted.
    """</span>
    results = []
    output_file = Path(output_path)

    <span class="code-comment"># Resume from checkpoint if exists</span>
    <span class="code-keyword">if</span> output_file.<span class="code-function">exists</span>():
        <span class="code-keyword">with</span> <span class="code-function">open</span>(output_file) <span class="code-keyword">as</span> f:
            results = json.<span class="code-function">load</span>(f)
        <span class="code-function">print</span>(f<span class="code-string">"Resuming from checkpoint: {<span class="code-function">len</span>(results)} already done"</span>)

    <span class="code-keyword">for</span> i <span class="code-keyword">in</span> <span class="code-function">range</span>(<span class="code-function">len</span>(results), <span class="code-function">len</span>(texts)):
        <span class="code-keyword">try</span>:
            result = <span class="code-function">analyze_fomc_statement</span>(texts[i])
            result[<span class="code-string">"label"</span>] = labels[i]
            results.<span class="code-function">append</span>(result)
        <span class="code-keyword">except</span> <span class="code-variable">Exception</span> <span class="code-keyword">as</span> e:
            results.<span class="code-function">append</span>({<span class="code-string">"label"</span>: labels[i], <span class="code-string">"error"</span>: <span class="code-function">str</span>(e)})

        <span class="code-comment"># Save checkpoint every 10 documents</span>
        <span class="code-keyword">if</span> (i + <span class="code-number">1</span>) % <span class="code-number">10</span> == <span class="code-number">0</span>:
            <span class="code-keyword">with</span> <span class="code-function">open</span>(output_file, <span class="code-string">"w"</span>) <span class="code-keyword">as</span> f:
                json.<span class="code-function">dump</span>(results, f, indent=<span class="code-number">2</span>)
            <span class="code-function">print</span>(f<span class="code-string">"  Checkpoint: {i+1}/{<span class="code-function">len</span>(texts)} processed"</span>)

        time.<span class="code-function">sleep</span>(delay)  <span class="code-comment"># respect API rate limits</span>

    <span class="code-comment"># Final save</span>
    <span class="code-keyword">with</span> <span class="code-function">open</span>(output_file, <span class="code-string">"w"</span>) <span class="code-keyword">as</span> f:
        json.<span class="code-function">dump</span>(results, f, indent=<span class="code-number">2</span>)

    <span class="code-keyword">return</span> results</code></pre>
          </div>
        </div>


        <!-- ================================================================== -->
        <!-- SECTION 10: PUTTING IT ALL TOGETHER -->
        <!-- ================================================================== -->
        <h2 id="full-example">10A.10 &nbsp;Putting It All Together</h2>

        <p>
          Let&rsquo;s combine every technique into a single, end-to-end analysis pipeline.
          This is the kind of script you would use for a research paper or business report.
        </p>

        <div class="code-tabs">
          <div class="tab-buttons">
            <button class="tab-button active" data-lang="python">Python</button>
          </div>
          <div class="tab-content active" data-lang="python">
<pre><code><span class="code-string">"""
Complete Text Analysis Pipeline: FOMC Statements
=================================================
This script demonstrates a full, reproducible text analysis workflow.
It can serve as a template for any corpus-level text analysis project.
"""</span>

<span class="code-comment"># === 0. SETUP ===</span>
<span class="code-keyword">import</span> <span class="code-package">random</span>, <span class="code-package">numpy</span> <span class="code-keyword">as</span> np, <span class="code-package">pandas</span> <span class="code-keyword">as</span> pd
<span class="code-keyword">import</span> <span class="code-package">matplotlib.pyplot</span> <span class="code-keyword">as</span> plt
<span class="code-keyword">import</span> <span class="code-package">seaborn</span> <span class="code-keyword">as</span> sns
<span class="code-keyword">from</span> <span class="code-package">sklearn.feature_extraction.text</span> <span class="code-keyword">import</span> TfidfVectorizer
<span class="code-keyword">from</span> <span class="code-package">sklearn.metrics.pairwise</span> <span class="code-keyword">import</span> cosine_similarity
<span class="code-keyword">from</span> <span class="code-package">nltk.sentiment</span> <span class="code-keyword">import</span> SentimentIntensityAnalyzer
<span class="code-keyword">from</span> <span class="code-package">sentence_transformers</span> <span class="code-keyword">import</span> SentenceTransformer
<span class="code-keyword">import</span> <span class="code-package">spacy</span>

random.<span class="code-function">seed</span>(<span class="code-number">42</span>); np.random.<span class="code-function">seed</span>(<span class="code-number">42</span>)

<span class="code-comment"># === 1. LOAD DATA ===</span>
<span class="code-comment"># (In practice, load from CSV/database)</span>
<span class="code-comment"># df = pd.read_csv("fomc_statements.csv")</span>

<span class="code-comment"># === 2. PREPROCESS ===</span>
nlp = spacy.<span class="code-function">load</span>(<span class="code-string">"en_core_web_sm"</span>)

<span class="code-keyword">def</span> <span class="code-function">preprocess</span>(text):
    doc = <span class="code-function">nlp</span>(text)
    <span class="code-keyword">return</span> <span class="code-string">" "</span>.<span class="code-function">join</span>([
        t.lemma_.<span class="code-function">lower</span>() <span class="code-keyword">for</span> t <span class="code-keyword">in</span> doc
        <span class="code-keyword">if</span> <span class="code-keyword">not</span> t.is_stop <span class="code-keyword">and</span> t.is_alpha <span class="code-keyword">and</span> <span class="code-function">len</span>(t) > <span class="code-number">1</span>
    ])

df[<span class="code-string">"clean"</span>] = df[<span class="code-string">"text"</span>].<span class="code-function">apply</span>(preprocess)

<span class="code-comment"># === 3. TF-IDF: What makes each statement distinctive? ===</span>
tfidf = <span class="code-function">TfidfVectorizer</span>(ngram_range=(<span class="code-number">1</span>, <span class="code-number">2</span>), max_features=<span class="code-number">100</span>)
tfidf_matrix = tfidf.<span class="code-function">fit_transform</span>(df[<span class="code-string">"clean"</span>])
features = tfidf.<span class="code-function">get_feature_names_out</span>()

<span class="code-comment"># === 4. SENTIMENT: Multiple methods for robustness ===</span>
sia = <span class="code-function">SentimentIntensityAnalyzer</span>()
df[<span class="code-string">"vader_compound"</span>] = df[<span class="code-string">"text"</span>].<span class="code-function">apply</span>(
    <span class="code-keyword">lambda</span> t: sia.<span class="code-function">polarity_scores</span>(t)[<span class="code-string">"compound"</span>]
)

<span class="code-comment"># === 5. EMBEDDINGS: Semantic similarity over time ===</span>
embed_model = <span class="code-function">SentenceTransformer</span>(<span class="code-string">"all-MiniLM-L6-v2"</span>)
embeddings = embed_model.<span class="code-function">encode</span>(df[<span class="code-string">"text"</span>].<span class="code-function">tolist</span>())
sim_matrix = <span class="code-function">cosine_similarity</span>(embeddings)

<span class="code-comment"># === 6. VISUALIZE ===</span>
fig, axes = plt.<span class="code-function">subplots</span>(<span class="code-number">1</span>, <span class="code-number">2</span>, figsize=(<span class="code-number">14</span>, <span class="code-number">5</span>))

<span class="code-comment"># Panel A: Sentiment over time</span>
axes[<span class="code-number">0</span>].<span class="code-function">plot</span>(df[<span class="code-string">"date"</span>], df[<span class="code-string">"vader_compound"</span>], <span class="code-string">"o-"</span>, color=<span class="code-string">"#2563eb"</span>, linewidth=<span class="code-number">2</span>)
axes[<span class="code-number">0</span>].<span class="code-function">axhline</span>(y=<span class="code-number">0</span>, color=<span class="code-string">"gray"</span>, linestyle=<span class="code-string">"--"</span>, alpha=<span class="code-number">0.5</span>)
axes[<span class="code-number">0</span>].<span class="code-function">set_title</span>(<span class="code-string">"FOMC Sentiment Over Time (VADER)"</span>, fontsize=<span class="code-number">13</span>)
axes[<span class="code-number">0</span>].<span class="code-function">set_ylabel</span>(<span class="code-string">"Compound Score"</span>)
axes[<span class="code-number">0</span>].<span class="code-function">set_ylim</span>(<span class="code-number">-1</span>, <span class="code-number">1</span>)

<span class="code-comment"># Panel B: Semantic similarity heatmap</span>
labels = [d.<span class="code-function">strftime</span>(<span class="code-string">"%Y-%m"</span>) <span class="code-keyword">for</span> d <span class="code-keyword">in</span> df[<span class="code-string">"date"</span>]]
sns.<span class="code-function">heatmap</span>(
    sim_matrix, annot=<span class="code-keyword">True</span>, fmt=<span class="code-string">".2f"</span>, cmap=<span class="code-string">"YlOrRd"</span>,
    xticklabels=labels, yticklabels=labels, ax=axes[<span class="code-number">1</span>]
)
axes[<span class="code-number">1</span>].<span class="code-function">set_title</span>(<span class="code-string">"Semantic Similarity Between Statements"</span>, fontsize=<span class="code-number">13</span>)

plt.<span class="code-function">tight_layout</span>()
plt.<span class="code-function">savefig</span>(<span class="code-string">"fomc_analysis.png"</span>, dpi=<span class="code-number">150</span>, bbox_inches=<span class="code-string">"tight"</span>)
plt.<span class="code-function">show</span>()

<span class="code-function">print</span>(<span class="code-string">"Analysis complete. Results saved to fomc_analysis.png"</span>)</code></pre>
          </div>
        </div>


        <!-- ================================================================== -->
        <!-- SECTION 11: REPRODUCIBILITY CHECKLIST -->
        <!-- ================================================================== -->
        <h2 id="reproducibility">10A.11 &nbsp;Reproducibility Checklist</h2>

        <p>
          Reproducibility is not optional &mdash; it is the difference between a finding and an anecdote.
          Follow this checklist for every text analysis project, whether for a course assignment, a business
          report, or a journal submission.
        </p>

        <ul class="checklist">
          <li><strong>Pin all library versions</strong> in a <code>requirements.txt</code> with exact version numbers</li>
          <li><strong>Set random seeds</strong> at the top of every script (<code>random</code>, <code>numpy</code>, <code>torch</code>)</li>
          <li><strong>Document every preprocessing decision</strong>: what you removed, what you kept, and why</li>
          <li><strong>Store raw data separately from processed data</strong> &mdash; never overwrite raw data</li>
          <li><strong>Version your prompts</strong> if using LLM APIs &mdash; save the exact prompt template used</li>
          <li><strong>Pin model versions</strong>: use <code>ProsusAI/finbert</code> not just &ldquo;finbert&rdquo;; use <code>claude-sonnet-4-20250514</code> not just &ldquo;claude&rdquo;</li>
          <li><strong>Report results across multiple seeds</strong>: run with seeds 42, 123, 456, 789, 1011 and report mean &plusmn; std</li>
          <li><strong>Validate against human labels</strong>: randomly sample 100&ndash;200 documents and have a human code them</li>
          <li><strong>Report all metrics</strong>: precision, recall, F1 per class &mdash; not just accuracy</li>
          <li><strong>Use version control</strong>: commit your analysis scripts to Git (see Module 9)</li>
          <li><strong>Include a README</strong> with instructions to reproduce your results from scratch</li>
        </ul>

        <div class="info-box tip">
          <div class="info-box-title">The Gold Standard</div>
          <p>
            Your analysis is reproducible when a colleague can run <code>pip install -r requirements.txt &amp;&amp;
            python analysis.py</code> and get the same results you reported. If any step requires manual
            intervention, proprietary data you cannot share, or a model that has been updated since publication,
            document it explicitly.
          </p>
        </div>


        <!-- ================================================================== -->
        <!-- SECTION 12: REFERENCES -->
        <!-- ================================================================== -->
        <h2 id="references">References &amp; Further Reading</h2>

        <h3>Foundational Methods</h3>
        <ul>
          <li>Loughran, T. &amp; McDonald, B. (2011). &ldquo;When Is a Liability Not a Liability? Textual Analysis, Dictionaries, and 10-Ks.&rdquo; <em>Journal of Finance</em>, 66(1), 35&ndash;65.</li>
          <li>Blei, D., Ng, A. &amp; Jordan, M. (2003). &ldquo;Latent Dirichlet Allocation.&rdquo; <em>Journal of Machine Learning Research</em>, 3, 993&ndash;1022.</li>
          <li>Mikolov, T. et al. (2013). &ldquo;Efficient Estimation of Word Representations in Vector Space.&rdquo; <em>arXiv:1301.3781</em>.</li>
          <li>Devlin, J. et al. (2019). &ldquo;BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding.&rdquo; <em>NAACL-HLT</em>.</li>
        </ul>

        <h3>Text as Data in Economics &amp; Finance</h3>
        <ul>
          <li>Gentzkow, M., Kelly, B. &amp; Taddy, M. (2019). &ldquo;Text as Data.&rdquo; <em>Journal of Economic Literature</em>, 57(3), 535&ndash;574.</li>
          <li>Hansen, S. &amp; McMahon, M. (2016). &ldquo;Shocking Language: Understanding the Macroeconomic Effects of Central Bank Communication.&rdquo; <em>Journal of International Economics</em>.</li>
          <li>Baker, S., Bloom, N. &amp; Davis, S. (2016). &ldquo;Measuring Economic Policy Uncertainty.&rdquo; <em>Quarterly Journal of Economics</em>, 131(4), 1593&ndash;1636.</li>
          <li>Ash, E. &amp; Hansen, S. (2023). &ldquo;Text Algorithms in Economics.&rdquo; <em>Annual Review of Economics</em>, 15, 659&ndash;688.</li>
        </ul>

        <h3>Modern NLP Tools &amp; Models</h3>
        <ul>
          <li>Grootendorst, M. (2022). &ldquo;BERTopic: Neural Topic Modeling with a Class-Based TF-IDF Procedure.&rdquo; <em>arXiv:2203.05794</em>.</li>
          <li>Araci, D. (2019). &ldquo;FinBERT: Financial Sentiment Analysis with Pre-Trained Language Models.&rdquo; <em>arXiv:1908.10063</em>.</li>
          <li>Reimers, N. &amp; Gurevych, I. (2019). &ldquo;Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks.&rdquo; <em>EMNLP</em>.</li>
        </ul>

        <h3>Reproducibility &amp; Best Practices</h3>
        <ul>
          <li>ACL Rolling Review. <a href="https://aclrollingreview.org/responsibleNLPresearch/" target="_blank">&ldquo;Responsible NLP Research Checklist.&rdquo;</a></li>
          <li>Jurafsky, D. &amp; Martin, J. H. (2024). <a href="https://web.stanford.edu/~jurafsky/slp3/" target="_blank"><em>Speech and Language Processing</em></a>, 3rd edition (draft).</li>
        </ul>


        <!-- Navigation Footer -->
        <div class="nav-footer">
          <a href="10-nlp-history.html" class="nav-link prev">Module 10: History of NLP</a>
          <a href="11-machine-learning.html" class="nav-link next">Module 11: Machine Learning</a>
        </div>

      </div>
    </main>
  </div>

  <button class="mobile-menu-toggle">&#9776;</button>

  <script src="../js/main.js"></script>
  <script src="../js/password-protection.js"></script>

  <!-- Tooltip engine (same as other modules) -->
  <script>
  (function() {
    var tooltipEl = null;
    var currentTarget = null;
    var hideTimeout = null;

    function getOrCreateTooltip() {
      if (!tooltipEl) {
        tooltipEl = document.createElement('div');
        tooltipEl.className = 'tooltip-popup';
        document.body.appendChild(tooltipEl);
      }
      return tooltipEl;
    }

    function positionTooltip(target) {
      var tip = target.getAttribute('data-tip');
      if (!tip) return;
      var tooltip = getOrCreateTooltip();
      tooltip.textContent = tip;
      tooltip.classList.remove('arrow-top', 'arrow-bottom');
      tooltip.classList.add('visible');
      var targetRect = target.getBoundingClientRect();
      var viewportWidth = window.innerWidth;
      var padding = 10;
      tooltip.style.visibility = 'hidden';
      tooltip.style.display = 'block';
      var tooltipRect = tooltip.getBoundingClientRect();
      var tooltipWidth = tooltipRect.width;
      var tooltipHeight = tooltipRect.height;
      var left = targetRect.left + (targetRect.width / 2) - (tooltipWidth / 2);
      var top = targetRect.top - tooltipHeight - 8;
      var arrowClass = 'arrow-bottom';
      if (top < padding) { top = targetRect.bottom + 8; arrowClass = 'arrow-top'; }
      if (left < padding) left = padding;
      if (left + tooltipWidth > viewportWidth - padding) left = viewportWidth - tooltipWidth - padding;
      tooltip.style.left = left + 'px';
      tooltip.style.top = top + 'px';
      tooltip.style.visibility = 'visible';
      tooltip.classList.add(arrowClass);
    }

    function showTooltip(target) {
      if (hideTimeout) { clearTimeout(hideTimeout); hideTimeout = null; }
      currentTarget = target;
      positionTooltip(target);
    }

    function hideTooltip() {
      hideTimeout = setTimeout(function() {
        if (tooltipEl) tooltipEl.classList.remove('visible');
        currentTarget = null;
      }, 100);
    }

    document.addEventListener('mouseenter', function(e) {
      if (e.target.classList && e.target.classList.contains('code-tooltip')) showTooltip(e.target);
    }, true);
    document.addEventListener('mouseleave', function(e) {
      if (e.target.classList && e.target.classList.contains('code-tooltip')) hideTooltip();
    }, true);
    document.addEventListener('scroll', function() {
      if (currentTarget && tooltipEl && tooltipEl.classList.contains('visible')) positionTooltip(currentTarget);
    }, true);
    window.addEventListener('resize', function() {
      if (currentTarget && tooltipEl && tooltipEl.classList.contains('visible')) positionTooltip(currentTarget);
    });
  })();
  </script>
</body>
</html>
