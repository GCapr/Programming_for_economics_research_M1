<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Module 7: Estimation Methods | ProTools ER1</title>
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Crimson+Pro:ital,wght@0,400;0,600;0,700;1,400&family=Fira+Code:wght@400;500&family=Source+Sans+Pro:ital,wght@0,400;0,600;0,700;1,400&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="../css/style.css">
  <style>
    .protected-content { -webkit-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; }
    .code-tooltip { position: relative; cursor: help; border-bottom: 1px dotted #888; text-decoration: none; }
    .tooltip-popup { position: fixed; background: #1f2937; color: white; padding: 0.5rem 0.75rem; border-radius: 6px; font-size: 0.75rem; white-space: normal; max-width: 300px; opacity: 0; pointer-events: none; transition: opacity 0.15s ease-in-out; z-index: 10000; }
    .tooltip-popup.visible { opacity: 1; }
    .distinction-box { display: grid; grid-template-columns: 1fr 1fr; gap: 1rem; margin: 1.5rem 0; }
    @media (max-width: 768px) { .distinction-box { grid-template-columns: 1fr; } }
    .distinction-card { background: #f8fafc; border: 1px solid #e2e8f0; border-radius: 8px; padding: 1rem; }
    .distinction-card h4 { margin: 0 0 0.5rem 0; color: #2563eb; }
    .distinction-card ul { margin: 0; padding-left: 1.25rem; }
  </style>
</head>
<body>
  <div id="password-overlay" class="password-overlay">
    <div class="password-modal">
      <h2>ProTools ER1</h2>
      <p>Programming Tools for Empirical Research</p>
      <p style="font-size: 0.9rem; color: #666; margin-bottom: 1.5rem;">Please enter the course password to access the materials.</p>
      <input type="password" id="password-input" placeholder="Enter password" autocomplete="off">
      <button id="password-submit">Access Course</button>
      <p id="password-error" style="color: #e53e3e; font-size: 0.85rem; margin-top: 1rem; display: none;">Incorrect password. Please try again.</p>
    </div>
  </div>

  <div class="page-wrapper protected-content">
    <aside class="sidebar">
      <a href="../index.html" class="sidebar-logo">ProTools ER1</a>
      <span class="sidebar-subtitle">Programming Tools for Empirical Research</span>
      <nav>
        <ul>
          <li><a href="../index.html"><span class="welcome-icon">üè†</span> Welcome</a></li>
          <li class="has-subnav">
            <a href="00-languages-platforms.html"><span class="module-number">0</span> Languages & Platforms</a>
            <ul class="sub-nav">
              <li><a href="00a-rstudio-guide.html">RStudio Guide</a></li>
              <li><a href="00b-stata-guide.html">Stata Guide</a></li>
              <li><a href="00c-vscode-guide.html">VS Code Guide</a></li>
              <li><a href="00d-notebooks-guide.html">Notebooks Guide</a></li>
            </ul>
          </li>
          <li><a href="01-getting-started.html"><span class="module-number">1</span> Getting Started</a></li>
          <li class="has-subnav">
            <a href="02-data-harnessing.html"><span class="module-number">2</span> Data Harnessing</a>
            <ul class="sub-nav">
              <li><a href="02a-file-import.html">File Import</a></li>
              <li><a href="02b-apis.html">APIs</a></li>
              <li><a href="02c-web-scraping.html">Web Scraping</a></li>
            </ul>
          </li>
          <li><a href="03-data-exploration.html"><span class="module-number">3</span> Data Exploration</a></li>
          <li><a href="04-data-cleaning.html"><span class="module-number">4</span> Data Cleaning</a></li>
          <li><a href="05-data-analysis.html"><span class="module-number">5</span> Data Analysis</a></li>
          <li><a href="05a-data-simulation.html"><span class="module-number">5A</span> Data Simulation</a></li>
          <li class="has-subnav">
            <a href="05b-experiments.html"><span class="module-number">5B</span> Experiments</a>
            <ul class="sub-nav">
              <li><a href="05b1-power-analysis.html">Power Analysis</a></li>
              <li><a href="05b2-survey-programming.html">Survey Programming</a></li>
              <li><a href="05b3-randomization.html">Randomization</a></li>
              <li><a href="05b4-balance-checks.html">Balance Checks</a></li>
            </ul>
          </li>
          <li class="has-subnav">
            <a href="06-causal-inference.html"><span class="module-number">6</span> Causal Inference</a>
            <ul class="sub-nav">
              <li><a href="06a-matching.html">Matching</a></li>
              <li><a href="06b-did.html">Difference-in-Differences</a></li>
              <li><a href="06c-rdd.html">Regression Discontinuity</a></li>
              <li><a href="06d-iv.html">Instrumental Variables</a></li>
              <li><a href="06e-synthetic-control.html">Synthetic Control</a></li>
            </ul>
          </li>
          <li class="active"><a href="07-estimation.html"><span class="module-number">7</span> Estimation Methods</a></li>
          <li><a href="08-replicability.html"><span class="module-number">8</span> Replicability</a></li>
          <li><a href="09-github.html"><span class="module-number">9</span> Git & GitHub</a></li>
          <li><a href="10-nlp-history.html"><span class="module-number">10</span> History of NLP</a></li>
          <li><a href="11-machine-learning.html"><span class="module-number">11</span> Machine Learning</a></li>
          <li><a href="12-llms.html"><span class="module-number">12</span> Large Language Models</a></li>
          <li><a href="../resources.html">Resources</a></li>
          <li><a href="contact.html">Contact & Feedback</a></li>
        </ul>
      </nav>
    </aside>

    <main class="main-content">
      <div class="content">
        <div class="module-header">
          <h1>7 &nbsp;Estimation Methods</h1>
          <div class="module-meta">
            <span>~6 hours</span>
            <span>Standard Errors, Panel Data, Nonlinear Models</span>
            <span>Intermediate-Advanced</span>
          </div>
        </div>

        <div class="learning-objectives">
          <h3>Learning Objectives</h3>
          <ul>
            <li>Distinguish between identification and estimation</li>
            <li>Choose appropriate standard errors for your data structure</li>
            <li>Handle panel data with fixed effects efficiently</li>
            <li>Implement nonlinear models (logit, probit, Poisson)</li>
            <li>Understand maximum likelihood and GMM estimation</li>
          </ul>
        </div>

        <div class="toc">
          <h3>Table of Contents</h3>
          <ul>
            <li><a href="#identification-vs-estimation">7.1 Identification vs. Estimation</a></li>
            <li><a href="#standard-errors">7.2 Standard Errors and Inference</a></li>
            <li><a href="#panel">7.3 Panel Data Methods</a></li>
            <li><a href="#nonlinear">7.4 Nonlinear Models</a></li>
            <li><a href="#mle-gmm">7.5 MLE and GMM</a></li>
            <li><a href="#bootstrap">7.6 Bootstrap Methods</a></li>
          </ul>
        </div>

        <h2 id="identification-vs-estimation">7.1 Identification vs. Estimation</h2>

        <p>
          A common source of confusion: <strong>identification</strong> and <strong>estimation</strong> are different problems.
        </p>

        <div class="distinction-box">
          <div class="distinction-card">
            <h4>Identification (Module 6)</h4>
            <p><em>Can</em> we learn the causal effect from data?</p>
            <ul>
              <li>Research design and assumptions</li>
              <li>What variation identifies the effect?</li>
              <li>Parallel trends, exclusion restriction, etc.</li>
              <li>Whether your estimate is causal or just correlational</li>
            </ul>
          </div>
          <div class="distinction-card">
            <h4>Estimation (This Module)</h4>
            <p><em>How</em> do we compute the estimate from data?</p>
            <ul>
              <li>OLS, MLE, GMM, nonparametric methods</li>
              <li>Standard errors and inference</li>
              <li>Handling large datasets efficiently</li>
              <li>Correcting for clustering, heteroskedasticity</li>
            </ul>
          </div>
        </div>

        <p>
          You can have correct identification but bad estimation (wrong standard errors), or good estimation but no identification (precise estimate of a biased number). Both matter.
        </p>

        <h2 id="standard-errors">7.2 Standard Errors and Inference</h2>

        <p>
          Choosing the right standard errors is essential for valid inference. The main considerations are heteroskedasticity and clustering.
        </p>

        <h3>Robust (Heteroskedasticity-Consistent) Standard Errors</h3>

        <div class="code-tabs">
          <div class="tab-buttons">
            <button class="tab-button active" data-lang="python">Python</button>
            <button class="tab-button" data-lang="stata">Stata</button>
            <button class="tab-button" data-lang="r">R</button>
          </div>
          <div class="tab-content active" data-lang="python">
<pre><code><span class="code-comment"># Python: Robust Standard Errors</span>
<span class="code-keyword">import</span> statsmodels.formula.api <span class="code-keyword">as</span> smf

<span class="code-comment"># Default (homoskedastic) standard errors</span>
model = smf.ols(<span class="code-string">'outcome ~ treatment + controls'</span>, data=df).fit()

<span class="code-comment"># Robust (heteroskedasticity-consistent) HC1</span>
<span class="code-tooltip" data-tip="HC1 is the most common. HC0, HC2, HC3 are alternatives with small-sample adjustments.">model_robust = smf.ols(<span class="code-string">'outcome ~ treatment + controls'</span>, data=df).fit(
    cov_type=<span class="code-string">'HC1'</span>
)</span>
print(model_robust.summary())</code></pre>
          </div>
          <div class="tab-content" data-lang="stata">
<pre><code><span class="code-comment">* Stata: Robust Standard Errors</span>

<span class="code-comment">* Default standard errors</span>
reg outcome treatment controls

<span class="code-comment">* Robust (heteroskedasticity-consistent) - ALWAYS use this</span>
<span class="code-tooltip" data-tip="In Stata, 'robust' is the standard option for heteroskedasticity-consistent SEs">reg outcome treatment controls, robust</span>

<span class="code-comment">* Equivalent: vce(robust)</span>
reg outcome treatment controls, vce(robust)</code></pre>
          </div>
          <div class="tab-content" data-lang="r">
<pre><code><span class="code-comment"># R: Robust Standard Errors</span>
<span class="code-keyword">library</span>(sandwich)
<span class="code-keyword">library</span>(lmtest)

<span class="code-comment"># Fit model</span>
model <- lm(outcome ~ treatment + controls, data = df)

<span class="code-comment"># Robust standard errors (HC1)</span>
<span class="code-tooltip" data-tip="vcovHC computes heteroskedasticity-consistent covariance matrix">coeftest(model, vcov = vcovHC(model, type = "HC1"))</span>

<span class="code-comment"># Using fixest (cleaner syntax)</span>
<span class="code-keyword">library</span>(fixest)
model <- feols(outcome ~ treatment + controls, data = df, vcov = "hetero")
summary(model)</code></pre>
          </div>
        </div>

        <h3>Clustered Standard Errors</h3>

        <p>
          When observations are correlated within groups (e.g., students within schools, repeated observations of the same person), you need clustered standard errors.
        </p>

        <div class="code-tabs">
          <div class="tab-buttons">
            <button class="tab-button active" data-lang="python">Python</button>
            <button class="tab-button" data-lang="stata">Stata</button>
            <button class="tab-button" data-lang="r">R</button>
          </div>
          <div class="tab-content active" data-lang="python">
<pre><code><span class="code-comment"># Python: Clustered Standard Errors</span>
<span class="code-keyword">import</span> statsmodels.formula.api <span class="code-keyword">as</span> smf

<span class="code-comment"># Cluster at the school level</span>
<span class="code-tooltip" data-tip="Clustering accounts for within-group correlation. Cluster at the level where treatment varies or errors are correlated.">model = smf.ols(<span class="code-string">'outcome ~ treatment'</span>, data=df).fit(
    cov_type=<span class="code-string">'cluster'</span>,
    cov_kwds={<span class="code-string">'groups'</span>: df[<span class="code-string">'school_id'</span>]}
)</span>

<span class="code-comment"># Two-way clustering (e.g., state and year)</span>
<span class="code-keyword">from</span> linearmodels.panel <span class="code-keyword">import</span> PanelOLS
df_panel = df.set_index([<span class="code-string">'state'</span>, <span class="code-string">'year'</span>])
model = PanelOLS.from_formula(<span class="code-string">'outcome ~ treatment'</span>, data=df_panel)
<span class="code-tooltip" data-tip="Two-way clustering accounts for correlation within both dimensions">results = model.fit(cov_type=<span class="code-string">'clustered'</span>, cluster_entity=True, cluster_time=True)</span></code></pre>
          </div>
          <div class="tab-content" data-lang="stata">
<pre><code><span class="code-comment">* Stata: Clustered Standard Errors</span>

<span class="code-comment">* One-way clustering</span>
<span class="code-tooltip" data-tip="cluster(school_id) clusters SEs at the school level">reg outcome treatment controls, cluster(school_id)</span>

<span class="code-comment">* Two-way clustering</span>
<span class="code-comment">* ssc install reghdfe</span>
<span class="code-tooltip" data-tip="Two-way clustering with reghdfe: cluster on both state and year">reghdfe outcome treatment, absorb(state year) cluster(state year)</span>

<span class="code-comment">* Check number of clusters</span>
<span class="code-tooltip" data-tip="Rule of thumb: need at least 30-50 clusters for reliable inference">tab school_id, matrow(clusters)
display r(r)</span></code></pre>
          </div>
          <div class="tab-content" data-lang="r">
<pre><code><span class="code-comment"># R: Clustered Standard Errors</span>
<span class="code-keyword">library</span>(fixest)

<span class="code-comment"># One-way clustering</span>
<span class="code-tooltip" data-tip="cluster = ~school_id clusters at the school level">model <- feols(outcome ~ treatment + controls,
               data = df,
               cluster = ~ school_id)</span>
summary(model)

<span class="code-comment"># Two-way clustering</span>
<span class="code-tooltip" data-tip="Two-way clustering with fixest: cluster on both dimensions">model <- feols(outcome ~ treatment | state + year,
               data = df,
               cluster = ~ state + year)</span>

<span class="code-comment"># With sandwich package</span>
<span class="code-keyword">library</span>(sandwich)
model <- lm(outcome ~ treatment, data = df)
vcovCL(model, cluster = ~ school_id)</code></pre>
          </div>
        </div>

        <div class="info-box warning">
          <div class="info-box-title">When to Cluster</div>
          <p>
            General rule: cluster at the level where:
          </p>
          <ul>
            <li>Treatment is assigned (for experiments)</li>
            <li>There's correlation in unobservables (for observational studies)</li>
          </ul>
          <p style="margin-bottom: 0;">
            When in doubt, cluster at a more aggregate level. See <a href="https://cameron.econ.ucdavis.edu/research/Cameron_Miller_JHR_2015.pdf" target="_blank">Cameron & Miller (2015)</a> for guidance.
          </p>
        </div>

        <h2 id="panel">7.3 Panel Data Methods</h2>

        <p>
          Panel data (repeated observations of units over time) enables powerful designs but requires appropriate methods.
        </p>

        <h3>Fixed Effects</h3>

        <div class="code-tabs">
          <div class="tab-buttons">
            <button class="tab-button active" data-lang="python">Python</button>
            <button class="tab-button" data-lang="stata">Stata</button>
            <button class="tab-button" data-lang="r">R</button>
          </div>
          <div class="tab-content active" data-lang="python">
<pre><code><span class="code-comment"># Python: Fixed Effects with linearmodels</span>
<span class="code-keyword">from</span> linearmodels.panel <span class="code-keyword">import</span> PanelOLS

<span class="code-comment"># Set panel index</span>
df = df.set_index([<span class="code-string">'unit_id'</span>, <span class="code-string">'year'</span>])

<span class="code-comment"># Unit fixed effects only</span>
<span class="code-tooltip" data-tip="entity_effects=True absorbs unit-level fixed effects (within estimator)">model = PanelOLS.from_formula(
    <span class="code-string">'outcome ~ treatment + time_varying_controls'</span>,
    data=df,
    entity_effects=True
)</span>
results = model.fit(cov_type=<span class="code-string">'clustered'</span>, cluster_entity=True)

<span class="code-comment"># Two-way fixed effects (unit + time)</span>
model = PanelOLS.from_formula(
    <span class="code-string">'outcome ~ treatment'</span>,
    data=df,
    entity_effects=True,
    time_effects=True
)
results = model.fit(cov_type=<span class="code-string">'clustered'</span>, cluster_entity=True)</code></pre>
          </div>
          <div class="tab-content" data-lang="stata">
<pre><code><span class="code-comment">* Stata: Fixed Effects</span>

<span class="code-comment">* Declare panel structure</span>
xtset unit_id year

<span class="code-comment">* Unit fixed effects</span>
<span class="code-tooltip" data-tip="xtreg with fe option does within-transformation (demeans by unit)">xtreg outcome treatment time_varying_controls, fe cluster(unit_id)</span>

<span class="code-comment">* Two-way fixed effects with reghdfe (RECOMMENDED for speed)</span>
<span class="code-tooltip" data-tip="reghdfe absorbs high-dimensional fixed effects efficiently">reghdfe outcome treatment, absorb(unit_id year) cluster(unit_id)</span>

<span class="code-comment">* With multiple sets of fixed effects</span>
reghdfe outcome treatment, absorb(unit_id year industry_id) cluster(unit_id)</code></pre>
          </div>
          <div class="tab-content" data-lang="r">
<pre><code><span class="code-comment"># R: Fixed Effects with fixest</span>
<span class="code-keyword">library</span>(fixest)

<span class="code-comment"># Unit fixed effects</span>
<span class="code-tooltip" data-tip="| unit_id specifies unit fixed effects after the pipe">model <- feols(outcome ~ treatment + controls | unit_id,
               data = df,
               cluster = ~ unit_id)</span>
summary(model)

<span class="code-comment"># Two-way fixed effects</span>
model <- feols(outcome ~ treatment | unit_id + year,
               data = df,
               cluster = ~ unit_id)

<span class="code-comment"># Multiple sets of fixed effects</span>
model <- feols(outcome ~ treatment | unit_id + year + industry_id,
               data = df,
               cluster = ~ unit_id)

<span class="code-comment"># With plm package (older, slower)</span>
<span class="code-keyword">library</span>(plm)
pdata <- pdata.frame(df, index = c("unit_id", "year"))
model <- plm(outcome ~ treatment, data = pdata, model = "within")</code></pre>
          </div>
        </div>

        <h3>Random Effects</h3>

        <div class="code-tabs">
          <div class="tab-buttons">
            <button class="tab-button active" data-lang="python">Python</button>
            <button class="tab-button" data-lang="stata">Stata</button>
            <button class="tab-button" data-lang="r">R</button>
          </div>
          <div class="tab-content active" data-lang="python">
<pre><code><span class="code-comment"># Python: Random Effects</span>
<span class="code-keyword">from</span> linearmodels.panel <span class="code-keyword">import</span> RandomEffects

df = df.set_index([<span class="code-string">'unit_id'</span>, <span class="code-string">'year'</span>])

<span class="code-tooltip" data-tip="Random effects assumes unit effects are uncorrelated with regressors (stronger assumption)">model = RandomEffects.from_formula(
    <span class="code-string">'outcome ~ treatment + controls'</span>,
    data=df
)</span>
results = model.fit()

<span class="code-comment"># Hausman test: FE vs RE</span>
<span class="code-keyword">from</span> linearmodels.panel <span class="code-keyword">import</span> compare
<span class="code-tooltip" data-tip="Hausman test: reject means RE is inconsistent, use FE">fe_model = PanelOLS.from_formula(<span class="code-string">'outcome ~ treatment'</span>, data=df, entity_effects=True).fit()
re_model = RandomEffects.from_formula(<span class="code-string">'outcome ~ treatment'</span>, data=df).fit()
print(compare({<span class="code-string">'FE'</span>: fe_model, <span class="code-string">'RE'</span>: re_model}))</span></code></pre>
          </div>
          <div class="tab-content" data-lang="stata">
<pre><code><span class="code-comment">* Stata: Random Effects</span>

<span class="code-comment">* Random effects model</span>
<span class="code-tooltip" data-tip="RE assumes unit effects are uncorrelated with regressors">xtreg outcome treatment controls, re</span>

<span class="code-comment">* Hausman test</span>
<span class="code-tooltip" data-tip="Hausman test: significant p-value suggests FE is more appropriate">xtreg outcome treatment controls, fe
estimates store fe
xtreg outcome treatment controls, re
hausman fe .</span></code></pre>
          </div>
          <div class="tab-content" data-lang="r">
<pre><code><span class="code-comment"># R: Random Effects</span>
<span class="code-keyword">library</span>(plm)

pdata <- pdata.frame(df, index = c("unit_id", "year"))

<span class="code-comment"># Random effects model</span>
<span class="code-tooltip" data-tip="model='random' specifies random effects">re_model <- plm(outcome ~ treatment + controls,
                data = pdata,
                model = "random")</span>
summary(re_model)

<span class="code-comment"># Hausman test</span>
fe_model <- plm(outcome ~ treatment + controls, data = pdata, model = "within")
<span class="code-tooltip" data-tip="Hausman test: significant p-value means FE is preferred">phtest(fe_model, re_model)</span></code></pre>
          </div>
        </div>

        <h2 id="nonlinear">7.4 Nonlinear Models</h2>

        <p>
          When outcomes are binary, counts, or bounded, linear models may be inappropriate.
        </p>

        <h3>Logit and Probit</h3>

        <div class="code-tabs">
          <div class="tab-buttons">
            <button class="tab-button active" data-lang="python">Python</button>
            <button class="tab-button" data-lang="stata">Stata</button>
            <button class="tab-button" data-lang="r">R</button>
          </div>
          <div class="tab-content active" data-lang="python">
<pre><code><span class="code-comment"># Python: Logit and Probit</span>
<span class="code-keyword">import</span> statsmodels.formula.api <span class="code-keyword">as</span> smf

<span class="code-comment"># Logit model (binary outcome)</span>
<span class="code-tooltip" data-tip="Logit uses logistic CDF; probit uses normal CDF. Results are similar in practice.">logit = smf.logit(<span class="code-string">'hired ~ education + experience + age'</span>, data=df).fit()</span>
print(logit.summary())

<span class="code-comment"># Probit model</span>
probit = smf.probit(<span class="code-string">'hired ~ education + experience + age'</span>, data=df).fit()

<span class="code-comment"># Marginal effects (more interpretable)</span>
<span class="code-tooltip" data-tip="Marginal effects give the change in probability for a unit change in X">margeff = logit.get_margeff()
print(margeff.summary())</span>

<span class="code-comment"># Average marginal effects at specific values</span>
margeff_at_means = logit.get_margeff(at=<span class="code-string">'mean'</span>)</code></pre>
          </div>
          <div class="tab-content" data-lang="stata">
<pre><code><span class="code-comment">* Stata: Logit and Probit</span>

<span class="code-comment">* Logit</span>
logit hired education experience age

<span class="code-comment">* Probit</span>
probit hired education experience age

<span class="code-comment">* Marginal effects (average marginal effects)</span>
<span class="code-tooltip" data-tip="margins, dydx(*) computes average marginal effects for all variables">margins, dydx(*)</span>

<span class="code-comment">* Marginal effects at specific values</span>
margins, dydx(*) at(education=16 experience=5)

<span class="code-comment">* Odds ratios (for logit)</span>
<span class="code-tooltip" data-tip="or option reports odds ratios instead of log-odds coefficients">logit hired education experience age, or</span></code></pre>
          </div>
          <div class="tab-content" data-lang="r">
<pre><code><span class="code-comment"># R: Logit and Probit</span>

<span class="code-comment"># Logit</span>
<span class="code-tooltip" data-tip="family=binomial() specifies logistic regression">logit <- glm(hired ~ education + experience + age,
             data = df,
             family = binomial(link = "logit"))</span>
summary(logit)

<span class="code-comment"># Probit</span>
probit <- glm(hired ~ education + experience + age,
              data = df,
              family = binomial(link = "probit"))

<span class="code-comment"># Marginal effects with margins package</span>
<span class="code-keyword">library</span>(margins)
<span class="code-tooltip" data-tip="margins() computes average marginal effects">margeff <- margins(logit)
summary(margeff)</span>

<span class="code-comment"># Odds ratios</span>
exp(coef(logit))</code></pre>
          </div>
        </div>

        <h3>Poisson and Negative Binomial (Count Data)</h3>

        <div class="code-tabs">
          <div class="tab-buttons">
            <button class="tab-button active" data-lang="python">Python</button>
            <button class="tab-button" data-lang="stata">Stata</button>
            <button class="tab-button" data-lang="r">R</button>
          </div>
          <div class="tab-content active" data-lang="python">
<pre><code><span class="code-comment"># Python: Poisson Regression</span>
<span class="code-keyword">import</span> statsmodels.formula.api <span class="code-keyword">as</span> smf

<span class="code-comment"># Poisson (count data)</span>
<span class="code-tooltip" data-tip="Poisson assumes mean equals variance. Use negative binomial if overdispersed.">poisson = smf.poisson(<span class="code-string">'num_patents ~ rd_spending + firm_size'</span>, data=df).fit()</span>
print(poisson.summary())

<span class="code-comment"># Negative binomial (allows overdispersion)</span>
<span class="code-keyword">from</span> statsmodels.discrete.discrete_model <span class="code-keyword">import</span> NegativeBinomial
<span class="code-tooltip" data-tip="Negative binomial allows variance to exceed mean (overdispersion)">nb = smf.negativebinomial(<span class="code-string">'num_patents ~ rd_spending + firm_size'</span>, data=df).fit()</span>

<span class="code-comment"># Robust Poisson (PPML for trade gravity equations)</span>
<span class="code-tooltip" data-tip="Poisson with robust SEs is consistent even if not Poisson distributed">poisson_robust = smf.poisson(<span class="code-string">'trade ~ distance + gdp_origin + gdp_dest'</span>, data=df).fit(
    cov_type=<span class="code-string">'HC1'</span>
)</span></code></pre>
          </div>
          <div class="tab-content" data-lang="stata">
<pre><code><span class="code-comment">* Stata: Count Data Models</span>

<span class="code-comment">* Poisson</span>
poisson num_patents rd_spending firm_size

<span class="code-comment">* Negative binomial</span>
nbreg num_patents rd_spending firm_size

<span class="code-comment">* Poisson with robust SEs (PPML)</span>
<span class="code-tooltip" data-tip="ppmlhdfe is commonly used for gravity equations in trade">ppmlhdfe trade distance gdp_origin gdp_dest, absorb(origin dest) cluster(pair)</span>

<span class="code-comment">* Check for overdispersion</span>
<span class="code-tooltip" data-tip="If alpha significantly > 0, use negative binomial">estat gof</span></code></pre>
          </div>
          <div class="tab-content" data-lang="r">
<pre><code><span class="code-comment"># R: Count Data Models</span>

<span class="code-comment"># Poisson</span>
<span class="code-tooltip" data-tip="family=poisson() specifies Poisson regression">poisson <- glm(num_patents ~ rd_spending + firm_size,
               data = df,
               family = poisson())</span>
summary(poisson)

<span class="code-comment"># Negative binomial</span>
<span class="code-keyword">library</span>(MASS)
<span class="code-tooltip" data-tip="glm.nb handles overdispersion">nb <- glm.nb(num_patents ~ rd_spending + firm_size, data = df)</span>
summary(nb)

<span class="code-comment"># With fixest (fast, with fixed effects)</span>
<span class="code-keyword">library</span>(fixest)
poisson_fe <- fepois(num_patents ~ rd_spending | firm_id + year,
                     data = df)</code></pre>
          </div>
        </div>

        <h2 id="mle-gmm">7.5 MLE and GMM</h2>

        <p>
          Maximum Likelihood Estimation (MLE) and Generalized Method of Moments (GMM) are general frameworks underlying most estimation methods.
        </p>

        <h3>Custom MLE</h3>

        <div class="code-tabs">
          <div class="tab-buttons">
            <button class="tab-button active" data-lang="python">Python</button>
            <button class="tab-button" data-lang="stata">Stata</button>
            <button class="tab-button" data-lang="r">R</button>
          </div>
          <div class="tab-content active" data-lang="python">
<pre><code><span class="code-comment"># Python: Custom MLE</span>
<span class="code-keyword">from</span> scipy.optimize <span class="code-keyword">import</span> minimize
<span class="code-keyword">import</span> numpy <span class="code-keyword">as</span> np

<span class="code-keyword">def</span> <span class="code-function">neg_log_likelihood</span>(params, X, y):
    <span class="code-string">"""Negative log-likelihood for linear regression."""</span>
    beta = params[:-1]
    sigma = params[-1]
    <span class="code-keyword">if</span> sigma <= 0:
        <span class="code-keyword">return</span> np.inf

    y_hat = X @ beta
    residuals = y - y_hat

    <span class="code-comment"># Normal log-likelihood</span>
    ll = -0.5 * len(y) * np.log(2 * np.pi * sigma**2)
    ll -= np.sum(residuals**2) / (2 * sigma**2)
    <span class="code-keyword">return</span> -ll  <span class="code-comment"># negative because we minimize</span>

<span class="code-comment"># Estimate</span>
X = np.column_stack([np.ones(len(df)), df[<span class="code-string">'x1'</span>], df[<span class="code-string">'x2'</span>]])
y = df[<span class="code-string">'y'</span>].values
initial = np.zeros(X.shape[1] + 1)
initial[-1] = 1  <span class="code-comment"># initial sigma</span>

<span class="code-tooltip" data-tip="MLE finds parameters that maximize the probability of observed data">result = minimize(neg_log_likelihood, initial, args=(X, y), method=<span class="code-string">'BFGS'</span>)
print(<span class="code-string">"MLE estimates:"</span>, result.x)</span></code></pre>
          </div>
          <div class="tab-content" data-lang="stata">
<pre><code><span class="code-comment">* Stata: Custom MLE with ml</span>

<span class="code-comment">* Define the log-likelihood function</span>
program mylogit_ll
    args lnf xb
    quietly replace `lnf' = $ML_y1 * `xb' - ln(1 + exp(`xb'))
end

<span class="code-comment">* Estimate</span>
<span class="code-tooltip" data-tip="ml model lf defines the likelihood; ml maximize estimates">ml model lf mylogit_ll (outcome = x1 x2)
ml maximize</span></code></pre>
          </div>
          <div class="tab-content" data-lang="r">
<pre><code><span class="code-comment"># R: Custom MLE</span>

<span class="code-comment"># Define negative log-likelihood</span>
neg_ll <- function(params, X, y) {
  beta <- params[-length(params)]
  sigma <- params[length(params)]
  <span class="code-keyword">if</span> (sigma <= 0) return(Inf)

  y_hat <- X %*% beta
  resid <- y - y_hat

  ll <- -0.5 * length(y) * log(2 * pi * sigma^2)
  ll <- ll - sum(resid^2) / (2 * sigma^2)
  return(-ll)
}

<span class="code-comment"># Estimate</span>
X <- cbind(1, df$x1, df$x2)
y <- df$y
initial <- c(rep(0, ncol(X)), 1)

<span class="code-tooltip" data-tip="optim minimizes the negative log-likelihood">result <- optim(initial, neg_ll, X = X, y = y, method = "BFGS", hessian = TRUE)
print(result$par)</span>

<span class="code-comment"># Standard errors from Hessian</span>
se <- sqrt(diag(solve(result$hessian)))</code></pre>
          </div>
        </div>

        <h2 id="bootstrap">7.6 Bootstrap Methods</h2>

        <p>
          Bootstrap provides standard errors and confidence intervals when analytical formulas are complex or unavailable.
        </p>

        <div class="code-tabs">
          <div class="tab-buttons">
            <button class="tab-button active" data-lang="python">Python</button>
            <button class="tab-button" data-lang="stata">Stata</button>
            <button class="tab-button" data-lang="r">R</button>
          </div>
          <div class="tab-content active" data-lang="python">
<pre><code><span class="code-comment"># Python: Bootstrap</span>
<span class="code-keyword">import</span> numpy <span class="code-keyword">as</span> np
<span class="code-keyword">import</span> statsmodels.formula.api <span class="code-keyword">as</span> smf

<span class="code-keyword">def</span> <span class="code-function">bootstrap_coef</span>(df, formula, n_bootstrap=1000):
    <span class="code-string">"""Bootstrap standard errors for regression coefficients."""</span>
    n = len(df)
    coefs = []

    <span class="code-keyword">for</span> _ <span class="code-keyword">in</span> range(n_bootstrap):
        <span class="code-comment"># Resample with replacement</span>
        sample = df.sample(n, replace=True)
        model = smf.ols(formula, data=sample).fit()
        coefs.append(model.params.values)

    coefs = np.array(coefs)
    <span class="code-keyword">return</span> {
        <span class="code-string">'mean'</span>: coefs.mean(axis=0),
        <span class="code-string">'se'</span>: coefs.std(axis=0),
        <span class="code-string">'ci_lower'</span>: np.percentile(coefs, 2.5, axis=0),
        <span class="code-string">'ci_upper'</span>: np.percentile(coefs, 97.5, axis=0)
    }

<span class="code-tooltip" data-tip="Bootstrap: resample data, re-estimate, repeat many times">results = bootstrap_coef(df, <span class="code-string">'y ~ x1 + x2'</span>)
print(<span class="code-string">"Bootstrap SEs:"</span>, results[<span class="code-string">'se'</span>])</span></code></pre>
          </div>
          <div class="tab-content" data-lang="stata">
<pre><code><span class="code-comment">* Stata: Bootstrap</span>

<span class="code-comment">* Simple bootstrap</span>
<span class="code-tooltip" data-tip="bootstrap resamples data and re-estimates reps times">bootstrap _b, reps(1000) seed(12345): reg outcome treatment controls</span>

<span class="code-comment">* Cluster bootstrap (for clustered data)</span>
<span class="code-tooltip" data-tip="cluster() option resamples whole clusters">bootstrap _b, reps(1000) seed(12345) cluster(school_id): ///
    reg outcome treatment controls</span>

<span class="code-comment">* Pairs cluster bootstrap (Stata 18+)</span>
vce(bootstrap, cluster(school_id) reps(1000))</code></pre>
          </div>
          <div class="tab-content" data-lang="r">
<pre><code><span class="code-comment"># R: Bootstrap</span>
<span class="code-keyword">library</span>(boot)

<span class="code-comment"># Function to extract coefficients</span>
boot_fn <- function(data, indices) {
  d <- data[indices, ]
  model <- lm(y ~ x1 + x2, data = d)
  return(coef(model))
}

<span class="code-comment"># Run bootstrap</span>
<span class="code-tooltip" data-tip="boot() resamples and re-estimates R times">results <- boot(df, boot_fn, R = 1000)</span>
print(results)

<span class="code-comment"># Confidence intervals</span>
<span class="code-tooltip" data-tip="boot.ci computes various bootstrap CI types">boot.ci(results, type = c("perc", "bca"), index = 2)</span>

<span class="code-comment"># Cluster bootstrap</span>
<span class="code-keyword">library</span>(fwildclusterboot)
model <- lm(outcome ~ treatment, data = df)
<span class="code-tooltip" data-tip="Wild cluster bootstrap for few clusters">boottest(model, param = "treatment", clustid = ~ school_id, B = 999)</span></code></pre>
          </div>
        </div>

        <div class="citation">
          <div class="citation-title">Key References</div>
          <ul>
            <li><strong>Cameron, A.C. & Trivedi, P.</strong> (2005). <em>Microeconometrics: Methods and Applications</em>. Cambridge.</li>
            <li><strong>Wooldridge, J.</strong> (2010). <em>Econometric Analysis of Cross Section and Panel Data</em>. MIT Press.</li>
            <li><strong>Cameron, A.C. & Miller, D.</strong> (2015). "A Practitioner's Guide to Cluster-Robust Inference." <em>JHR</em>.</li>
            <li><strong>Abadie, A., Athey, S., Imbens, G., & Wooldridge, J.</strong> (2023). "When Should You Adjust Standard Errors for Clustering?" <em>QJE</em>.</li>
          </ul>
        </div>

        <div class="nav-footer">
          <a href="06e-synthetic-control.html" class="nav-link prev">6E: Synthetic Control</a>
          <a href="08-replicability.html" class="nav-link next">Module 8: Replicability</a>
        </div>
      </div>
    </main>
  </div>

  <button class="mobile-menu-toggle" aria-label="Toggle navigation menu">Menu</button>
  <script src="../js/main.js"></script>
  <script src="../js/password-protection.js"></script>
</body>
</html>
