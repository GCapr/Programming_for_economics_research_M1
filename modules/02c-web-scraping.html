<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Module 2c: Web Scraping | ProTools ER1</title>
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Crimson+Pro:ital,wght@0,400;0,600;0,700;1,400&family=Fira+Code:wght@400;500&family=Source+Sans+Pro:ital,wght@0,400;0,600;0,700;1,400&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="../css/style.css">
  <style>
    .protected-content { -webkit-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; }
    .output-simulation { background: #1e1e1e; border-radius: 8px; margin: 1rem 0; overflow: hidden; font-family: 'Fira Code', monospace; font-size: 0.8rem; display: none; }
    .output-simulation.visible { display: block; }
    .output-header { background: #333; padding: 0.5rem 1rem; display: flex; justify-content: space-between; align-items: center; color: #ccc; font-size: 0.75rem; }
    .output-body { padding: 1rem; color: #d4d4d4; white-space: pre-wrap; overflow-x: auto; max-height: 400px; overflow-y: auto; }
    .output-body .out-green { color: #4ec9b0; }
    .output-body .out-yellow { color: #dcdcaa; }
    .output-body .out-blue { color: #569cd6; }
    .output-body .out-num { color: #b5cea8; }
    .output-body .out-str { color: #ce9178; }
    .output-body .out-red { color: #f14c4c; }
    .research-banner { background: #4a5568; color: white; padding: 1.5rem; border-radius: 12px; margin: 2rem 0; border-left: 5px solid #ed8936; }
    .research-banner h3 { color: white; margin-top: 0; }
    .concept-box { background: #f0f9ff; border-left: 4px solid #2563eb; padding: 1.5rem; margin: 1.5rem 0; border-radius: 0 8px 8px 0; }
    .concept-box h4 { color: #1e40af; margin-top: 0; }
    .legal-box { background: #fef3c7; border-left: 4px solid #d97706; padding: 1.5rem; margin: 1.5rem 0; border-radius: 0 8px 8px 0; }
    .legal-box h4 { color: #92400e; margin-top: 0; }
    .danger-box { background: #fee2e2; border-left: 4px solid #dc2626; padding: 1.5rem; margin: 1.5rem 0; border-radius: 0 8px 8px 0; }
    .danger-box h4 { color: #991b1b; margin-top: 0; }
    .run-btn { background: #22c55e; color: white; border: none; padding: 0.5rem 1rem; border-radius: 6px; cursor: pointer; font-size: 0.85rem; font-weight: 600; margin-top: 0.5rem; display: inline-flex; align-items: center; gap: 0.5rem; }
    .run-btn:hover { background: #16a34a; }
    .run-btn::before { content: '‚ñ∂'; font-size: 0.7rem; }
    .close-output { background: transparent; border: none; color: #9ca3af; cursor: pointer; font-size: 1.2rem; }
    .close-output:hover { color: white; }
    .code-tooltip { position: relative; cursor: help; border-bottom: 1px dotted #888; }
    .code-tooltip::after { content: attr(data-tip); position: absolute; bottom: 100%; left: 50%; transform: translateX(-50%); background: #1f2937; color: white; padding: 0.5rem 0.75rem; border-radius: 6px; font-size: 0.75rem; white-space: nowrap; opacity: 0; pointer-events: none; transition: opacity 0.2s; z-index: 100; max-width: 300px; white-space: normal; }
    .code-tooltip:hover::after { opacity: 1; }
    .html-diagram { background: #1e1e1e; border-radius: 8px; padding: 1.5rem; margin: 1.5rem 0; font-family: 'Fira Code', monospace; font-size: 0.85rem; color: #d4d4d4; overflow-x: auto; }
    .html-diagram .tag { color: #569cd6; }
    .html-diagram .attr { color: #9cdcfe; }
    .html-diagram .value { color: #ce9178; }
    .html-diagram .content { color: #d4d4d4; }
    .html-diagram .comment { color: #6a9955; }
    .checklist { background: #f0fdf4; border: 1px solid #86efac; border-radius: 8px; padding: 1.5rem; margin: 1.5rem 0; }
    .checklist h4 { color: #166534; margin-top: 0; }
    .checklist ul { margin-bottom: 0; }
    .checklist li { margin-bottom: 0.5rem; }
  </style>
</head>
<body>
  <div id="password-overlay" class="password-overlay">
    <div class="password-modal">
      <h2>ProTools ER1</h2>
      <p>Programming Tools for Empirical Research</p>
      <p style="font-size: 0.9rem; color: #666; margin-bottom: 1.5rem;">Please enter the course password to access the materials.</p>
      <input type="password" id="password-input" placeholder="Enter password" autocomplete="off">
      <button id="password-submit">Access Course</button>
      <p id="password-error" style="color: #e53e3e; font-size: 0.85rem; margin-top: 1rem; display: none;">Incorrect password. Please try again.</p>
    </div>
  </div>

  <div class="page-wrapper protected-content">
    <aside class="sidebar">
      <a href="../index.html" class="sidebar-logo">ProTools ER1</a>
      <span class="sidebar-subtitle">Programming Tools for Empirical Research</span>
      <nav>
          <ul>
          <li><a href="../index.html"><span class="welcome-icon">üè†</span> Welcome</a></li>
          <li>
            <a href="00-languages-platforms.html"><span class="module-number">0</span> Languages & Platforms</a>
            <ul class="sub-nav">
              <li><a href="00a-rstudio-guide.html">RStudio Guide</a></li>
              <li><a href="00b-stata-guide.html">Stata Guide</a></li>
              <li><a href="00c-vscode-guide.html">VS Code Guide</a></li>
              <li><a href="00d-notebooks-guide.html">Notebooks Guide</a></li>
            </ul>
          </li>
          <li><a href="01-getting-started.html"><span class="module-number">1</span> Getting Started</a></li>
          <li class="active">
            <a href="02-data-harnessing.html"><span class="module-number">2</span> Data Harnessing</a>
            <ul class="sub-nav">
              <li><a href="02a-file-import.html">Importing from Files</a></li>
              <li><a href="02b-apis.html">Working with APIs</a></li>
              <li class="active"><a href="02c-web-scraping.html">Web Scraping</a></li>
            </ul>
          </li>
          <li><a href="03-data-exploration.html"><span class="module-number">3</span> Data Exploration</a></li>
          <li><a href="04-data-cleaning.html"><span class="module-number">4</span> Data Cleaning</a></li>
          <li><a href="05-data-analysis.html"><span class="module-number">5</span> Data Analysis</a></li>
          <li><a href="06-causal-inference.html"><span class="module-number">6</span> Causal Inference</a></li>
          <li><a href="07-estimation.html"><span class="module-number">7</span> Estimation Methods</a></li>
          <li><a href="08-replicability.html"><span class="module-number">8</span> Replicability</a></li>
          <li><a href="09-github.html"><span class="module-number">9</span> Git & GitHub</a></li>
          <li><a href="10-nlp-history.html"><span class="module-number">10</span> History of NLP</a></li>
          <li><a href="11-machine-learning.html"><span class="module-number">11</span> Machine Learning</a></li>
          <li><a href="12-llms.html"><span class="module-number">12</span> Large Language Models</a></li>
          <li><a href="../resources.html">Resources</a></li>
          <li><a href="contact.html">Contact &amp; Feedback</a></li>
          </ul>
        </nav>
    </aside>

    <main class="main-content">
      <div class="content">
        <div class="module-header">
          <h1>2c &nbsp;Web Scraping</h1>
          <div class="module-meta">
            <span>~5 hours</span>
            <span>HTML, BeautifulSoup, Legal Considerations</span>
            <span>Intermediate</span>
          </div>
        </div>

        <div class="learning-objectives">
          <h3>Learning Objectives</h3>
          <ul>
            <li>Understand when web scraping is appropriate vs. using APIs</li>
            <li>Navigate the legal and ethical landscape of web scraping</li>
            <li>Parse HTML structure and extract data using BeautifulSoup/rvest</li>
            <li>Handle pagination, rate limiting, and dynamic content</li>
            <li>Build robust, respectful scrapers for research data collection</li>
          </ul>
        </div>

        <!-- Critical Legal Warning -->
        <div class="danger-box">
          <h4>Before You Scrape: Legal and Ethical Obligations</h4>
          <p><strong>Web scraping exists in a legal gray area.</strong> What's technically possible isn't always legal or ethical. Before scraping any website, you must understand the legal framework and respect website owners' rights.</p>
          <p style="margin-bottom: 0;"><strong>This module teaches responsible scraping for legitimate research purposes only.</strong></p>
        </div>

        <div class="toc">
          <h3>Table of Contents</h3>
          <ul>
            <li><a href="#when-to-scrape">2c.1 When to Scrape (and When Not To)</a></li>
            <li><a href="#legal-framework">2c.2 Legal Framework</a></li>
            <li><a href="#html-basics">2c.3 Understanding HTML Structure</a></li>
            <li><a href="#basic-scraping">2c.4 Basic Scraping Techniques</a></li>
            <li><a href="#advanced-techniques">2c.5 Advanced Techniques</a></li>
            <li><a href="#best-practices">2c.6 Best Practices for Research</a></li>
          </ul>
        </div>

        <!-- Section 1: When to Scrape -->
        <h2 id="when-to-scrape">2c.1 When to Scrape (and When Not To)</h2>

        <div class="concept-box">
          <h4>The Hierarchy of Data Acquisition</h4>
          <p style="margin-bottom: 0.5rem;">Always prefer these options <strong>in order</strong>:</p>
          <ol style="margin-bottom: 0;">
            <li><strong>Official datasets</strong> &mdash; Published data files from the source</li>
            <li><strong>APIs</strong> &mdash; Structured, sanctioned data access (see <a href="02b-apis.html">Module 2b</a>)</li>
            <li><strong>Data request</strong> &mdash; Contact the organization directly</li>
            <li><strong>Web scraping</strong> &mdash; Last resort when above options fail</li>
          </ol>
        </div>

        <!-- Section 2: Legal Framework -->
        <h2 id="legal-framework">2c.2 Legal Framework</h2>

        <div class="legal-box">
          <h4>I Am Not a Lawyer</h4>
          <p style="margin-bottom: 0;">This section provides educational information about legal concepts related to web scraping. <strong>It is not legal advice.</strong> Consult with your institution's legal counsel or a qualified attorney for guidance on specific situations.</p>
        </div>

        <h3>Key Legal Considerations</h3>

        <h4>1. Terms of Service (ToS)</h4>
        <p>Most websites have Terms of Service that may prohibit automated data collection. Violating ToS can result in:</p>
        <ul>
          <li>Being blocked from the website</li>
          <li>Civil lawsuits for breach of contract</li>
          <li>In some jurisdictions, criminal charges under computer fraud laws</li>
        </ul>

        <div class="info-box warning">
          <div class="info-box-title">Always Check the Terms of Service</div>
          <p style="margin-bottom: 0;">Before scraping, find and read the website's ToS. Look for keywords like "automated", "scraping", "crawling", "bot", "data collection". If the ToS prohibits scraping, <strong>do not scrape</strong>.</p>
        </div>

        <h4>2. robots.txt</h4>
        <p>The <code>robots.txt</code> file tells automated systems which parts of a site they can access. It's located at the root of every website (e.g., <code>example.com/robots.txt</code>).</p>

        <div class="html-diagram">
<span class="comment"># Example robots.txt file</span>

User-agent: *          <span class="comment"># Rules for all bots</span>
Disallow: /private/    <span class="comment"># Don't access /private/</span>
Disallow: /admin/      <span class="comment"># Don't access /admin/</span>
Allow: /public/        <span class="comment"># Explicitly allowed</span>

User-agent: Googlebot  <span class="comment"># Special rules for Google</span>
Allow: /              <span class="comment"># Google can access everything</span>

Crawl-delay: 10        <span class="comment"># Wait 10 seconds between requests</span>
        </div>

        <div class="info-box note">
          <div class="info-box-title">robots.txt is Not Legally Binding</div>
          <p style="margin-bottom: 0;">Technically, robots.txt is a voluntary standard&mdash;websites can't enforce it. However, ignoring it demonstrates bad faith and may be used against you in legal proceedings. <strong>Always respect robots.txt.</strong></p>
        </div>

        <h4>3. Copyright and Database Rights</h4>
        <p>Even if you can legally <em>access</em> data, you may not have the right to <em>use</em> or <em>republish</em> it:</p>
        <ul>
          <li><strong>Copyright</strong> protects creative works (articles, images, unique descriptions)</li>
          <li><strong>Database rights</strong> (EU) protect substantial investments in compiling data</li>
          <li><strong>Facts themselves</strong> are generally not copyrightable, but their presentation may be</li>
        </ul>

        <h4>4. The Computer Fraud and Abuse Act (CFAA) - US</h4>
        <p>The CFAA prohibits "unauthorized access" to computer systems. Recent court decisions have significantly <strong>clarified researchers' rights</strong>:</p>

        <div class="concept-box" style="background: #ecfdf5; border-left-color: #059669;">
          <h4 style="color: #047857;">Key Legal Precedents Favoring Researchers</h4>
          <ul style="margin-bottom: 0;">
            <li><strong>hiQ Labs v. LinkedIn (9th Cir. 2022)</strong>: The court ruled that scraping <em>publicly accessible</em> data does not constitute "unauthorized access" under the CFAA. LinkedIn could not use the CFAA to block hiQ from scraping public profiles. This is a landmark decision for researchers working with public web data.</li>
            <li><strong>Van Buren v. United States (Supreme Court, 2021)</strong>: The Supreme Court narrowed the CFAA's scope, ruling that "exceeds authorized access" only applies to accessing areas of a system one wasn't entitled to access&mdash;not to misusing information from areas one <em>was</em> authorized to access. Violating Terms of Service alone does not trigger criminal CFAA liability.</li>
            <li><strong>Sandvig v. Barr (D.D.C. 2020)</strong>: Researchers challenged CFAA restrictions on audit testing. The court ruled that the CFAA does not criminalize mere ToS violations, protecting researchers conducting discrimination audits via scraping.</li>
            <li><strong>Clearview AI Litigation (ongoing)</strong>: While Clearview faced lawsuits, courts have distinguished between commercial and research uses. Academic research has stronger protections than commercial exploitation.</li>
          </ul>
        </div>

        <h4>5. European Union Regulation</h4>
        <p>The EU has established explicit legal frameworks that <strong>protect research scraping</strong>:</p>

        <div class="concept-box" style="background: #eff6ff; border-left-color: #2563eb;">
          <h4 style="color: #1e40af;">EU Text and Data Mining (TDM) Exceptions</h4>
          <p>The <strong>Digital Single Market (DSM) Directive 2019/790</strong> created specific exceptions for text and data mining:</p>
          <ul>
            <li><strong>Article 3 &mdash; Research Exception</strong>: Research organizations and cultural heritage institutions may perform text and data mining on works they have lawful access to, <em>regardless of contractual terms</em>. This explicitly overrides ToS restrictions for legitimate research.</li>
            <li><strong>Article 4 &mdash; General TDM Exception</strong>: Any lawful access holder may perform TDM unless the rightsholder has expressly reserved this right in a machine-readable format. Mere ToS language is insufficient; reservations must be explicit.</li>
          </ul>
          <p style="margin-bottom: 0;"><strong>Practical implication:</strong> In the EU, academic researchers at recognized institutions have a statutory right to scrape publicly accessible content for research purposes, even if ToS prohibit it.</p>
        </div>

        <div class="concept-box" style="background: #fefce8; border-left-color: #ca8a04;">
          <h4 style="color: #854d0e;">GDPR and Research</h4>
          <p>The GDPR provides specific accommodations for research:</p>
          <ul style="margin-bottom: 0;">
            <li><strong>Article 89</strong>: Allows processing of personal data for scientific research with appropriate safeguards</li>
            <li><strong>Recital 159</strong>: Broadly defines "scientific research" to include technological development, fundamental research, and applied research</li>
            <li><strong>Research requires</strong>: Data minimization, pseudonymization where possible, and documented public interest justification</li>
          </ul>
        </div>

        <h4>6. Recent Legal Developments (2023-2025)</h4>
        <ul>
          <li><strong>AI Training Data Debates</strong>: While commercial AI companies face copyright challenges, academic research maintains stronger fair use/fair dealing protections</li>
          <li><strong>US Copyright Office Guidance (2023)</strong>: Affirmed that factual data extraction generally does not constitute copyright infringement</li>
          <li><strong>EU AI Act (2024)</strong>: Distinguishes research uses from commercial deployment; research scraping for AI development has explicit carve-outs</li>
          <li><strong>Meta v. Bright Data (2024)</strong>: Court found that scraping publicly available data does not violate the CFAA, reinforcing hiQ precedent</li>
        </ul>

        <div class="info-box warning">
          <div class="info-box-title">Jurisdiction Matters</div>
          <p style="margin-bottom: 0;">Legal protections vary by country. EU researchers generally have stronger statutory protections than US researchers. If your institution spans multiple jurisdictions, consult with legal counsel about which framework applies to your specific project.</p>
        </div>

        <h3>Research-Specific Considerations</h3>

        <div class="danger-box">
          <h4>Document Your Decision-Making Process</h4>
          <p>If your scraping is ever questioned, you need a clear record showing you acted in good faith. Courts and ethics committees look favorably on researchers who demonstrate thoughtful consideration of legal and ethical issues.</p>
          <p style="margin-bottom: 0;"><strong>Your documentation should be created BEFORE you scrape</strong>&mdash;not reconstructed afterward.</p>
        </div>

        <div class="checklist">
          <h4>Pre-Scraping Checklist for Researchers</h4>
          <ul>
            <li><strong>Check for existing datasets</strong> &mdash; ICPSR, Harvard Dataverse, Kaggle, data.gov</li>
            <li><strong>Check for an API</strong> &mdash; Even if undocumented, try adding /api/ to the URL</li>
            <li><strong>Read the Terms of Service</strong> &mdash; Document that you checked and your interpretation</li>
            <li><strong>Check robots.txt</strong> &mdash; Respect all directives and document compliance</li>
            <li><strong>Consider fair use/TDM exceptions</strong> &mdash; Is your use transformative? Non-commercial? Does EU Article 3 apply?</li>
            <li><strong>Contact your IRB</strong> &mdash; Human subjects data may require approval</li>
            <li><strong>Consult your institution</strong> &mdash; Many universities have policies on scraping</li>
          </ul>
        </div>

        <div class="concept-box" style="background: #f0fdf4; border-left-color: #22c55e;">
          <h4 style="color: #166534;">Documentation Template for Research Scraping</h4>
          <p>Create a dated memo that includes:</p>
          <ol>
            <li><strong>Research purpose</strong>: What question are you investigating? Why is web data necessary?</li>
            <li><strong>Data source assessment</strong>: Did you check for official datasets, APIs, or data request options?</li>
            <li><strong>Legal analysis</strong>:
              <ul>
                <li>ToS review: What do the terms say? How does your use comply or qualify for exceptions?</li>
                <li>robots.txt review: What does it permit/prohibit? How will you comply?</li>
                <li>Applicable law: Which jurisdiction applies? What protections exist (CFAA/hiQ, EU TDM)?</li>
              </ul>
            </li>
            <li><strong>Ethical considerations</strong>: Is the data sensitive? Could individuals be harmed? What safeguards will you implement?</li>
            <li><strong>Technical safeguards</strong>: Rate limiting, caching, minimal data collection, secure storage</li>
            <li><strong>Institutional approvals</strong>: IRB status, departmental sign-off, legal consultation</li>
          </ol>
          <p style="margin-bottom: 0;"><strong>Keep this document with your project files.</strong> If questions arise years later during peer review or legal inquiry, this contemporaneous record demonstrates good faith.</p>
        </div>

        <!-- Section 3: HTML Basics -->
        <h2 id="html-basics">2c.3 Understanding HTML Structure</h2>

        <div class="concept-box">
          <h4>What is HTML?</h4>
          <p style="margin-bottom: 0;"><strong>HTML (HyperText Markup Language)</strong> is the structure of web pages. It uses nested <strong>tags</strong> to organize content. To scrape data, you need to understand this structure so you can tell your code where to find the information you want.</p>
        </div>

        <h3>HTML Elements</h3>
        <p>HTML is made of <strong>elements</strong> with opening and closing tags:</p>

        <div class="html-diagram">
<span class="tag">&lt;tagname</span> <span class="attr">attribute</span>=<span class="value">"value"</span><span class="tag">&gt;</span><span class="content">Content goes here</span><span class="tag">&lt;/tagname&gt;</span>

<span class="comment">&lt;!-- Common examples: --&gt;</span>
<span class="tag">&lt;p&gt;</span>This is a paragraph<span class="tag">&lt;/p&gt;</span>
<span class="tag">&lt;a</span> <span class="attr">href</span>=<span class="value">"https://example.com"</span><span class="tag">&gt;</span>This is a link<span class="tag">&lt;/a&gt;</span>
<span class="tag">&lt;div</span> <span class="attr">class</span>=<span class="value">"container"</span><span class="tag">&gt;</span>This is a division/section<span class="tag">&lt;/div&gt;</span>
<span class="tag">&lt;span</span> <span class="attr">id</span>=<span class="value">"price"</span><span class="tag">&gt;</span>$99.99<span class="tag">&lt;/span&gt;</span>
<span class="tag">&lt;table&gt;</span>...<span class="tag">&lt;/table&gt;</span>              <span class="comment">&lt;!-- Tables --&gt;</span>
<span class="tag">&lt;ul&gt;&lt;li&gt;</span>...<span class="tag">&lt;/li&gt;&lt;/ul&gt;</span>         <span class="comment">&lt;!-- Lists --&gt;</span>
        </div>

        <h3>Attributes: class and id</h3>
        <p>Attributes help identify specific elements. The most important for scraping are:</p>
        <ul>
          <li><strong>class</strong> &mdash; Shared by multiple elements (e.g., all prices might have <code>class="price"</code>)</li>
          <li><strong>id</strong> &mdash; Unique identifier for a single element (e.g., <code>id="main-content"</code>)</li>
        </ul>

        <h3>Viewing Page Source</h3>
        <p>To see a page's HTML structure:</p>
        <ol>
          <li>Right-click anywhere on the page</li>
          <li>Select "View Page Source" (sees original HTML) or "Inspect" (interactive developer tools)</li>
          <li>In developer tools, you can hover over elements to see their HTML</li>
        </ol>

        <!-- GIF Demonstration -->
        <div style="margin: 1.5rem 0; border-radius: 12px; overflow: hidden; box-shadow: 0 4px 15px rgba(0,0,0,0.1);">
          <div style="background: #1f2937; padding: 0.5rem 1rem; display: flex; align-items: center; gap: 0.5rem;">
            <div style="width: 12px; height: 12px; border-radius: 50%; background: #ef4444;"></div>
            <div style="width: 12px; height: 12px; border-radius: 50%; background: #fbbf24;"></div>
            <div style="width: 12px; height: 12px; border-radius: 50%; background: #22c55e;"></div>
            <span style="color: #9ca3af; font-size: 0.8rem; margin-left: 0.5rem;">Chrome Developer Tools Demo</span>
          </div>
          <div id="inspect-demo-container">
            <img src="../images/inspect-element-demo.gif" alt="Animation showing how to use Chrome DevTools to inspect elements" style="width: 100%; display: block;" onerror="this.parentElement.innerHTML = `
              <div style='background: linear-gradient(135deg, #1a365d 0%, #2c5282 100%); padding: 3rem 2rem; text-align: center; color: white;'>
                <div style='font-size: 3rem; margin-bottom: 1rem;'>üîç</div>
                <div style='font-weight: 600; font-size: 1.1rem; margin-bottom: 0.5rem;'>Try it yourself!</div>
                <div style='opacity: 0.9; font-size: 0.9rem; line-height: 1.6;'>
                  <strong>1.</strong> Right-click anywhere on this page<br>
                  <strong>2.</strong> Select &quot;Inspect&quot; or &quot;Inspect Element&quot;<br>
                  <strong>3.</strong> Hover over HTML elements in the panel<br>
                  <strong>4.</strong> Watch them highlight on the page!
                </div>
              </div>
            `">
          </div>
        </div>
        <p style="font-size: 0.85rem; color: #666; text-align: center; margin-top: 0.5rem;"><em>Right-click ‚Üí Inspect ‚Üí Hover over HTML to highlight elements on the page</em></p>

        <div class="info-box tip">
          <div class="info-box-title">Pro Tip: Use the Element Picker</div>
          <p style="margin-bottom: 0;">In Chrome/Firefox developer tools, click the element picker icon (cursor in box) then click any element on the page. The HTML for that element will be highlighted in the developer panel.</p>
        </div>

        <h3>Example: A Simple Web Page</h3>
        <div class="html-diagram">
<span class="tag">&lt;html&gt;</span>
  <span class="tag">&lt;head&gt;</span>
    <span class="tag">&lt;title&gt;</span>Country GDP Data<span class="tag">&lt;/title&gt;</span>
  <span class="tag">&lt;/head&gt;</span>
  <span class="tag">&lt;body&gt;</span>
    <span class="tag">&lt;h1&gt;</span>GDP by Country<span class="tag">&lt;/h1&gt;</span>

    <span class="tag">&lt;table</span> <span class="attr">class</span>=<span class="value">"data-table"</span><span class="tag">&gt;</span>
      <span class="tag">&lt;tr&gt;</span>
        <span class="tag">&lt;th&gt;</span>Country<span class="tag">&lt;/th&gt;</span>
        <span class="tag">&lt;th&gt;</span>GDP (Billion USD)<span class="tag">&lt;/th&gt;</span>
      <span class="tag">&lt;/tr&gt;</span>
      <span class="tag">&lt;tr&gt;</span>
        <span class="tag">&lt;td&gt;</span>United States<span class="tag">&lt;/td&gt;</span>
        <span class="tag">&lt;td</span> <span class="attr">class</span>=<span class="value">"gdp-value"</span><span class="tag">&gt;</span>21,000<span class="tag">&lt;/td&gt;</span>
      <span class="tag">&lt;/tr&gt;</span>
      <span class="tag">&lt;tr&gt;</span>
        <span class="tag">&lt;td&gt;</span>China<span class="tag">&lt;/td&gt;</span>
        <span class="tag">&lt;td</span> <span class="attr">class</span>=<span class="value">"gdp-value"</span><span class="tag">&gt;</span>14,700<span class="tag">&lt;/td&gt;</span>
      <span class="tag">&lt;/tr&gt;</span>
    <span class="tag">&lt;/table&gt;</span>
  <span class="tag">&lt;/body&gt;</span>
<span class="tag">&lt;/html&gt;</span>
        </div>

        <!-- Section 4: Basic Scraping -->
        <h2 id="basic-scraping">2c.4 Basic Scraping Techniques</h2>

        <p>We'll use <strong>Python with BeautifulSoup</strong> (most common) and <strong>R with rvest</strong>. Stata doesn't have native scraping capabilities, but you can call Python from Stata (not covered here, but you can ask the chatbot if you're interested!).</p>

        <h3>Step 1: Fetch the Page</h3>

        <div class="code-tabs" data-runnable="fetch-1">
          <div class="tab-buttons">
            <button class="tab-button active" data-lang="python">Python</button>
            <button class="tab-button" data-lang="r">R</button>
          </div>
          <div class="tab-content active" data-lang="python">
<pre><code><span class="code-comment"># Python: Fetch a web page</span>
<span class="code-keyword">import</span> <span class="code-tooltip" data-tip="requests is Python's HTTP library for fetching web pages">requests</span>
<span class="code-keyword">from</span> <span class="code-tooltip" data-tip="BeautifulSoup parses HTML and lets you search for elements">bs4</span> <span class="code-keyword">import</span> BeautifulSoup

<span class="code-comment"># Define a User-Agent (identifies your scraper)</span>
<span class="code-comment"># Be honest - some sites block generic Python requests</span>
<span class="code-tooltip" data-tip="Headers tell the server about your request. User-Agent identifies your browser/scraper.">headers</span> = {
    <span class="code-string">'User-Agent'</span>: <span class="code-string">'Mozilla/5.0 (Research scraper for academic project; contact@university.edu)'</span>
}

<span class="code-comment"># Fetch the page</span>
url = <span class="code-string">"https://example.com/data"</span>
<span class="code-tooltip" data-tip="requests.get() fetches the page. timeout prevents hanging forever.">response</span> = requests.get(url, headers=headers, timeout=<span class="code-number">30</span>)

<span class="code-comment"># Check if request was successful</span>
<span class="code-keyword">if</span> response.status_code == <span class="code-number">200</span>:
    <span class="code-keyword">print</span>(<span class="code-string">"Success! Page fetched."</span>)
    <span class="code-comment"># Parse the HTML</span>
    <span class="code-tooltip" data-tip="BeautifulSoup creates a parse tree from HTML. 'html.parser' is the built-in parser.">soup</span> = BeautifulSoup(response.text, <span class="code-string">'html.parser'</span>)
<span class="code-keyword">else</span>:
    <span class="code-keyword">print</span>(<span class="code-string">f"Error: {response.status_code}"</span>)</code></pre>
            <button class="run-btn" data-lang="python">Run Code</button>
          </div>
          <div class="tab-content" data-lang="r">
<pre><code><span class="code-comment"># R: Fetch a web page</span>
<span class="code-function">library</span>(<span class="code-tooltip" data-tip="rvest is R's main web scraping package, part of tidyverse">rvest</span>)
<span class="code-function">library</span>(httr)

<span class="code-comment"># Define User-Agent</span>
<span class="code-tooltip" data-tip="set_config() sets global options for all httr requests">set_config</span>(<span class="code-function">user_agent</span>(<span class="code-string">"Research scraper for academic project; contact@university.edu"</span>))

<span class="code-comment"># Fetch and parse the page in one step</span>
url <- <span class="code-string">"https://example.com/data"</span>
<span class="code-tooltip" data-tip="read_html() fetches and parses the page, returning an XML document">page</span> <- <span class="code-function">read_html</span>(url)

<span class="code-comment"># Page is now ready for extraction</span>
<span class="code-function">print</span>(<span class="code-string">"Page fetched successfully"</span>)</code></pre>
            <button class="run-btn" data-lang="r">Run Code</button>
          </div>
        </div>

        <div class="output-simulation" data-output="fetch-1" data-lang="python">
          <div class="output-header">
            <span>Python Output</span>
            <button class="close-output">&times;</button>
          </div>
          <div class="output-body"><span class="out-green">Success! Page fetched.</span>

<span class="out-blue">Response details:</span>
Status: <span class="out-num">200</span> OK
Content-Type: text/html; charset=utf-8
Content-Length: <span class="out-num">45,231</span> bytes</div>
        </div>

        <div class="output-simulation" data-output="fetch-1" data-lang="r">
          <div class="output-header">
            <span>R Output</span>
            <button class="close-output">&times;</button>
          </div>
          <div class="output-body"><span class="out-green">Page fetched successfully</span>

{html_document}
&lt;html&gt;
[1] &lt;head&gt;...
[2] &lt;body&gt;...</div>
        </div>

        <h3>Step 2: Extract Data</h3>

        <div class="code-tabs" data-runnable="extract-1">
          <div class="tab-buttons">
            <button class="tab-button active" data-lang="python">Python</button>
            <button class="tab-button" data-lang="r">R</button>
          </div>
          <div class="tab-content active" data-lang="python">
<pre><code><span class="code-comment"># Python: Extract data from HTML</span>

<span class="code-comment"># Find a single element</span>
<span class="code-tooltip" data-tip="find() returns the FIRST matching element. Returns None if not found.">title</span> = soup.find(<span class="code-string">'h1'</span>)
<span class="code-keyword">print</span>(<span class="code-string">f"Title: {title.text}"</span>)

<span class="code-comment"># Find by class name</span>
<span class="code-tooltip" data-tip="Use class_ (with underscore) because 'class' is a Python keyword">price</span> = soup.find(<span class="code-string">'span'</span>, class_=<span class="code-string">'price'</span>)

<span class="code-comment"># Find by id</span>
main_content = soup.find(id=<span class="code-string">'main-content'</span>)

<span class="code-comment"># Find ALL matching elements</span>
<span class="code-tooltip" data-tip="find_all() returns a LIST of all matching elements">all_prices</span> = soup.find_all(<span class="code-string">'span'</span>, class_=<span class="code-string">'price'</span>)
<span class="code-keyword">for</span> p <span class="code-keyword">in</span> all_prices:
    <span class="code-keyword">print</span>(p.text)

<span class="code-comment"># Extract from a table</span>
table = soup.find(<span class="code-string">'table'</span>, class_=<span class="code-string">'data-table'</span>)
rows = table.find_all(<span class="code-string">'tr'</span>)
<span class="code-keyword">for</span> row <span class="code-keyword">in</span> rows[<span class="code-number">1</span>:]:  <span class="code-comment"># Skip header row</span>
    cells = row.find_all(<span class="code-string">'td'</span>)
    country = cells[<span class="code-number">0</span>].text.strip()
    gdp = cells[<span class="code-number">1</span>].text.strip()
    <span class="code-keyword">print</span>(<span class="code-string">f"{country}: {gdp}"</span>)

<span class="code-comment"># Extract attribute values (like href from links)</span>
links = soup.find_all(<span class="code-string">'a'</span>)
<span class="code-keyword">for</span> link <span class="code-keyword">in</span> links:
    <span class="code-tooltip" data-tip="Use .get() to safely extract attributes. Returns None if attribute doesn't exist.">href</span> = link.get(<span class="code-string">'href'</span>)
    <span class="code-keyword">print</span>(href)</code></pre>
            <button class="run-btn" data-lang="python">Run Code</button>
          </div>
          <div class="tab-content" data-lang="r">
<pre><code><span class="code-comment"># R: Extract data from HTML using rvest</span>

<span class="code-comment"># Find elements using CSS selectors</span>
<span class="code-tooltip" data-tip="html_element() returns the FIRST match, html_elements() returns ALL matches">title</span> <- page %>%
  <span class="code-function">html_element</span>(<span class="code-string">"h1"</span>) %>%
  <span class="code-function">html_text</span>()
<span class="code-function">print</span>(<span class="code-function">paste</span>(<span class="code-string">"Title:"</span>, title))

<span class="code-comment"># Find by class (use . prefix for class)</span>
prices <- page %>%
  <span class="code-function"><span class="code-tooltip" data-tip="CSS selector: .classname for class, #idname for id">html_elements</span></span>(<span class="code-string">".price"</span>) %>%
  <span class="code-function">html_text</span>()

<span class="code-comment"># Find by id (use # prefix)</span>
main_content <- page %>%
  <span class="code-function">html_element</span>(<span class="code-string">"#main-content"</span>) %>%
  <span class="code-function">html_text</span>()

<span class="code-comment"># Extract a table (rvest makes this easy!)</span>
<span class="code-tooltip" data-tip="html_table() automatically extracts tables into data frames">table_data</span> <- page %>%
  <span class="code-function">html_element</span>(<span class="code-string">"table.data-table"</span>) %>%
  <span class="code-function">html_table</span>()
<span class="code-function">print</span>(table_data)

<span class="code-comment"># Extract attribute values (like href)</span>
links <- page %>%
  <span class="code-function">html_elements</span>(<span class="code-string">"a"</span>) %>%
  <span class="code-function"><span class="code-tooltip" data-tip="html_attr() extracts a specific attribute from elements">html_attr</span></span>(<span class="code-string">"href"</span>)
<span class="code-function">print</span>(links)</code></pre>
            <button class="run-btn" data-lang="r">Run Code</button>
          </div>
        </div>

        <div class="output-simulation" data-output="extract-1" data-lang="python">
          <div class="output-header">
            <span>Python Output</span>
            <button class="close-output">&times;</button>
          </div>
          <div class="output-body">Title: <span class="out-str">GDP by Country</span>

<span class="out-blue">Table data extracted:</span>
<span class="out-str">United States</span>: <span class="out-num">21,000</span>
<span class="out-str">China</span>: <span class="out-num">14,700</span>
<span class="out-str">Japan</span>: <span class="out-num">5,100</span>
<span class="out-str">Germany</span>: <span class="out-num">3,800</span>

<span class="out-blue">Links found:</span>
/about
/data/countries
https://example.com/methodology</div>
        </div>

        <div class="output-simulation" data-output="extract-1" data-lang="r">
          <div class="output-header">
            <span>R Output</span>
            <button class="close-output">&times;</button>
          </div>
          <div class="output-body">[1] "Title: GDP by Country"

<span class="out-green"># A tibble: 4 x 2</span>
  Country       `GDP (Billion USD)`
  <span class="out-blue">&lt;chr&gt;</span>                       <span class="out-blue">&lt;dbl&gt;</span>
<span class="out-num">1</span> United States               21000
<span class="out-num">2</span> China                       14700
<span class="out-num">3</span> Japan                        5100
<span class="out-num">4</span> Germany                      3800

[1] <span class="out-str">"/about"</span> <span class="out-str">"/data/countries"</span> <span class="out-str">"https://example.com/methodology"</span></div>
        </div>

        <h3>CSS Selectors Quick Reference</h3>
        <table style="width: 100%; margin: 1rem 0;">
          <thead>
            <tr>
              <th>Selector</th>
              <th>Meaning</th>
              <th>Example</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td><code>tag</code></td>
              <td>Element by tag name</td>
              <td><code>div</code>, <code>table</code>, <code>a</code></td>
            </tr>
            <tr>
              <td><code>.class</code></td>
              <td>Element by class</td>
              <td><code>.price</code>, <code>.data-table</code></td>
            </tr>
            <tr>
              <td><code>#id</code></td>
              <td>Element by id</td>
              <td><code>#main-content</code></td>
            </tr>
            <tr>
              <td><code>tag.class</code></td>
              <td>Tag with specific class</td>
              <td><code>span.price</code></td>
            </tr>
            <tr>
              <td><code>parent child</code></td>
              <td>Nested elements</td>
              <td><code>table tr td</code></td>
            </tr>
            <tr>
              <td><code>[attr=value]</code></td>
              <td>By attribute</td>
              <td><code>[data-country="USA"]</code></td>
            </tr>
          </tbody>
        </table>

        <!-- Section 5: Advanced Techniques -->
        <h2 id="advanced-techniques">2c.5 Advanced Techniques</h2>

        <h3>Handling Pagination</h3>
        <p>Many websites spread data across multiple pages. You need to iterate through them:</p>

        <div class="code-tabs" data-runnable="pagination">
          <div class="tab-buttons">
            <button class="tab-button active" data-lang="python">Python</button>
            <button class="tab-button" data-lang="r">R</button>
          </div>
          <div class="tab-content active" data-lang="python">
<pre><code><span class="code-comment"># Python: Handle pagination</span>
<span class="code-keyword">import</span> requests
<span class="code-keyword">from</span> bs4 <span class="code-keyword">import</span> BeautifulSoup
<span class="code-keyword">import</span> <span class="code-tooltip" data-tip="time.sleep() pauses execution - essential for polite scraping">time</span>

<span class="code-comment"># Store all results</span>
all_data = []

<span class="code-comment"># Loop through pages</span>
<span class="code-keyword">for</span> page_num <span class="code-keyword">in</span> <span class="code-function">range</span>(<span class="code-number">1</span>, <span class="code-number">11</span>):  <span class="code-comment"># Pages 1-10</span>
    url = <span class="code-string">f"https://example.com/data?page={page_num}"</span>

    <span class="code-comment"># Be polite: wait between requests</span>
    <span class="code-tooltip" data-tip="ALWAYS add delays between requests. 2+ seconds is polite.">time.sleep</span>(<span class="code-number">2</span>)  <span class="code-comment"># Wait 2 seconds</span>

    response = requests.get(url, headers=headers)
    <span class="code-keyword">if</span> response.status_code != <span class="code-number">200</span>:
        <span class="code-keyword">print</span>(<span class="code-string">f"Error on page {page_num}, stopping"</span>)
        <span class="code-keyword">break</span>

    soup = BeautifulSoup(response.text, <span class="code-string">'html.parser'</span>)

    <span class="code-comment"># Extract data from this page</span>
    items = soup.find_all(<span class="code-string">'div'</span>, class_=<span class="code-string">'item'</span>)

    <span class="code-comment"># Check if page is empty (end of data)</span>
    <span class="code-keyword">if</span> <span class="code-keyword">not</span> items:
        <span class="code-keyword">print</span>(<span class="code-string">f"No more data after page {page_num-1}"</span>)
        <span class="code-keyword">break</span>

    <span class="code-keyword">for</span> item <span class="code-keyword">in</span> items:
        all_data.append({
            <span class="code-string">'name'</span>: item.find(<span class="code-string">'h2'</span>).text,
            <span class="code-string">'value'</span>: item.find(<span class="code-string">'span'</span>, class_=<span class="code-string">'value'</span>).text
        })

    <span class="code-keyword">print</span>(<span class="code-string">f"Page {page_num}: {len(items)} items"</span>)

<span class="code-keyword">print</span>(<span class="code-string">f"Total: {len(all_data)} items collected"</span>)</code></pre>
            <button class="run-btn" data-lang="python">Run Code</button>
          </div>
          <div class="tab-content" data-lang="r">
<pre><code><span class="code-comment"># R: Handle pagination</span>
<span class="code-function">library</span>(rvest)
<span class="code-function">library</span>(purrr)

<span class="code-comment"># Function to scrape one page</span>
scrape_page <- <span class="code-keyword">function</span>(page_num) {
  <span class="code-comment"># Be polite: wait between requests</span>
  <span class="code-function"><span class="code-tooltip" data-tip="Sys.sleep() pauses R - ALWAYS use delays between requests">Sys.sleep</span></span>(<span class="code-number">2</span>)

  url <- <span class="code-function">paste0</span>(<span class="code-string">"https://example.com/data?page="</span>, page_num)
  page <- <span class="code-function">read_html</span>(url)

  <span class="code-comment"># Extract table or items</span>
  page %>%
    <span class="code-function">html_element</span>(<span class="code-string">"table.data-table"</span>) %>%
    <span class="code-function">html_table</span>()
}

<span class="code-comment"># Scrape pages 1-10</span>
<span class="code-tooltip" data-tip="map_dfr() applies function to each element and combines results into one data frame">all_data</span> <- <span class="code-function">map_dfr</span>(<span class="code-number">1</span>:<span class="code-number">10</span>, scrape_page)

<span class="code-function">print</span>(<span class="code-function">paste</span>(<span class="code-string">"Total rows collected:"</span>, <span class="code-function">nrow</span>(all_data)))</code></pre>
            <button class="run-btn" data-lang="r">Run Code</button>
          </div>
        </div>

        <div class="output-simulation" data-output="pagination" data-lang="python">
          <div class="output-header">
            <span>Python Output</span>
            <button class="close-output">&times;</button>
          </div>
          <div class="output-body">Page <span class="out-num">1</span>: <span class="out-num">20</span> items
Page <span class="out-num">2</span>: <span class="out-num">20</span> items
Page <span class="out-num">3</span>: <span class="out-num">20</span> items
Page <span class="out-num">4</span>: <span class="out-num">20</span> items
Page <span class="out-num">5</span>: <span class="out-num">20</span> items
Page <span class="out-num">6</span>: <span class="out-num">15</span> items
Page <span class="out-num">7</span>: <span class="out-num">0</span> items
No more data after page 6

<span class="out-green">Total: 115 items collected</span></div>
        </div>

        <div class="output-simulation" data-output="pagination" data-lang="r">
          <div class="output-header">
            <span>R Output</span>
            <button class="close-output">&times;</button>
          </div>
          <div class="output-body">Scraping page 1...
Scraping page 2...
Scraping page 3...
...
[1] <span class="out-green">"Total rows collected: 115"</span></div>
        </div>

        <h3>Handling Dynamic Content (JavaScript)</h3>

        <div class="info-box warning">
          <div class="info-box-title">When Pages Load Data with JavaScript</div>
          <p>Many modern websites load data dynamically using JavaScript. BeautifulSoup/rvest only see the initial HTML&mdash;not data loaded later. Solutions:</p>
          <ul style="margin-bottom: 0;">
            <li><strong>Check for hidden API:</strong> Open developer tools > Network tab > look for XHR/Fetch requests</li>
            <li><strong>Use Selenium/Playwright:</strong> These control a real browser that executes JavaScript</li>
            <li><strong>Check for static version:</strong> Some sites offer non-JS versions for accessibility</li>
          </ul>
        </div>

        <div class="code-tabs" data-runnable="selenium">
          <div class="tab-buttons">
            <button class="tab-button active" data-lang="python">Python</button>
          </div>
          <div class="tab-content active" data-lang="python">
<pre><code><span class="code-comment"># Python: Handle JavaScript with Selenium</span>
<span class="code-comment"># First: pip install selenium webdriver-manager</span>

<span class="code-keyword">from</span> selenium <span class="code-keyword">import</span> webdriver
<span class="code-keyword">from</span> selenium.webdriver.chrome.service <span class="code-keyword">import</span> Service
<span class="code-keyword">from</span> selenium.webdriver.common.by <span class="code-keyword">import</span> By
<span class="code-keyword">from</span> selenium.webdriver.support.ui <span class="code-keyword">import</span> WebDriverWait
<span class="code-keyword">from</span> selenium.webdriver.support <span class="code-keyword">import</span> expected_conditions <span class="code-keyword">as</span> EC
<span class="code-keyword">from</span> webdriver_manager.chrome <span class="code-keyword">import</span> ChromeDriverManager
<span class="code-keyword">from</span> bs4 <span class="code-keyword">import</span> BeautifulSoup

<span class="code-comment"># Set up Chrome in headless mode (no visible window)</span>
options = webdriver.ChromeOptions()
options.add_argument(<span class="code-string">'--headless'</span>)
<span class="code-tooltip" data-tip="webdriver-manager automatically downloads the right ChromeDriver version">driver</span> = webdriver.Chrome(
    service=Service(ChromeDriverManager().install()),
    options=options
)

<span class="code-keyword">try</span>:
    <span class="code-comment"># Load the page</span>
    driver.get(<span class="code-string">"https://example.com/dynamic-data"</span>)

    <span class="code-comment"># Wait for specific element to load (max 10 seconds)</span>
    <span class="code-tooltip" data-tip="WebDriverWait pauses until element appears - crucial for JS-heavy pages">wait</span> = WebDriverWait(driver, <span class="code-number">10</span>)
    wait.until(EC.presence_of_element_located((By.CLASS_NAME, <span class="code-string">"data-table"</span>)))

    <span class="code-comment"># Now page is fully loaded - get the HTML</span>
    html = driver.page_source
    soup = BeautifulSoup(html, <span class="code-string">'html.parser'</span>)

    <span class="code-comment"># Extract data as usual</span>
    table = soup.find(<span class="code-string">'table'</span>, class_=<span class="code-string">'data-table'</span>)
    <span class="code-keyword">print</span>(<span class="code-string">"Data extracted successfully!"</span>)

<span class="code-keyword">finally</span>:
    <span class="code-comment"># Always close the browser</span>
    driver.quit()</code></pre>
            <button class="run-btn" data-lang="python">Run Code</button>
          </div>
        </div>

        <div class="output-simulation" data-output="selenium" data-lang="python">
          <div class="output-header">
            <span>Python Output</span>
            <button class="close-output">&times;</button>
          </div>
          <div class="output-body"><span class="out-blue">Starting Chrome in headless mode...</span>
<span class="out-blue">Navigating to page...</span>
<span class="out-blue">Waiting for data-table to load...</span>
<span class="out-green">Element found after 2.3 seconds</span>
<span class="out-green">Data extracted successfully!</span></div>
        </div>

        <!-- Section 6: Best Practices -->
        <h2 id="best-practices">2c.6 Best Practices for Research</h2>

        <div class="checklist">
          <h4>The Responsible Scraper's Checklist</h4>
          <ul>
            <li><strong>Identify yourself:</strong> Use a clear User-Agent with contact info</li>
            <li><strong>Respect robots.txt:</strong> Don't access disallowed pages</li>
            <li><strong>Rate limit:</strong> Add delays (2+ seconds) between requests</li>
            <li><strong>Cache responses:</strong> Don't re-fetch pages you've already downloaded</li>
            <li><strong>Handle errors gracefully:</strong> Don't hammer a server if it returns errors</li>
            <li><strong>Scrape during off-hours:</strong> Minimize impact on the server</li>
            <li><strong>Only take what you need:</strong> Don't download entire websites</li>
            <li><strong>Store data securely:</strong> Especially if it contains personal information</li>
            <li><strong>Document your methodology:</strong> For reproducibility and ethics review</li>
            <li><strong>Consider reaching out:</strong> Website owners may provide data directly</li>
          </ul>
        </div>

        <h3>Rate Limiting and Caching</h3>

        <div class="code-tabs" data-runnable="polite">
          <div class="tab-buttons">
            <button class="tab-button active" data-lang="python">Python</button>
          </div>
          <div class="tab-content active" data-lang="python">
<pre><code><span class="code-comment"># Python: Polite scraping with rate limiting and caching</span>
<span class="code-keyword">import</span> requests
<span class="code-keyword">import</span> time
<span class="code-keyword">import</span> hashlib
<span class="code-keyword">import</span> os
<span class="code-keyword">from</span> pathlib <span class="code-keyword">import</span> Path

<span class="code-keyword">class</span> <span class="code-function">PoliteScraper</span>:
    <span class="code-keyword">def</span> <span class="code-function">__init__</span>(self, delay=<span class="code-number">2</span>, cache_dir=<span class="code-string">"scraper_cache"</span>):
        self.delay = delay
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(exist_ok=<span class="code-keyword">True</span>)
        self.last_request = <span class="code-number">0</span>
        self.session = requests.Session()
        self.session.headers.update({
            <span class="code-string">'User-Agent'</span>: <span class="code-string">'Research Scraper (contact@university.edu)'</span>
        })

    <span class="code-keyword">def</span> <span class="code-function">_get_cache_path</span>(self, url):
        <span class="code-comment"># Create unique filename from URL</span>
        url_hash = hashlib.md5(url.encode()).hexdigest()
        <span class="code-keyword">return</span> self.cache_dir / <span class="code-string">f"{url_hash}.html"</span>

    <span class="code-keyword">def</span> <span class="code-function">fetch</span>(self, url, use_cache=<span class="code-keyword">True</span>):
        cache_path = self._get_cache_path(url)

        <span class="code-comment"># Check cache first</span>
        <span class="code-keyword">if</span> use_cache <span class="code-keyword">and</span> cache_path.exists():
            <span class="code-keyword">print</span>(<span class="code-string">f"Using cached version of {url}"</span>)
            <span class="code-keyword">return</span> cache_path.read_text()

        <span class="code-comment"># Rate limiting</span>
        elapsed = time.time() - self.last_request
        <span class="code-keyword">if</span> elapsed < self.delay:
            <span class="code-tooltip" data-tip="Respects minimum delay between requests">time.sleep</span>(self.delay - elapsed)

        <span class="code-comment"># Make request</span>
        response = self.session.get(url, timeout=<span class="code-number">30</span>)
        self.last_request = time.time()

        <span class="code-keyword">if</span> response.status_code == <span class="code-number">200</span>:
            <span class="code-comment"># Cache the response</span>
            cache_path.write_text(response.text)
            <span class="code-keyword">return</span> response.text
        <span class="code-keyword">else</span>:
            <span class="code-keyword">raise</span> <span class="code-function">Exception</span>(<span class="code-string">f"HTTP {response.status_code}"</span>)

<span class="code-comment"># Usage</span>
scraper = PoliteScraper(delay=<span class="code-number">3</span>)
html = scraper.fetch(<span class="code-string">"https://example.com/page1"</span>)
html = scraper.fetch(<span class="code-string">"https://example.com/page2"</span>)</code></pre>
            <button class="run-btn" data-lang="python">Run Code</button>
          </div>
        </div>

        <div class="output-simulation" data-output="polite" data-lang="python">
          <div class="output-header">
            <span>Python Output</span>
            <button class="close-output">&times;</button>
          </div>
          <div class="output-body"><span class="out-blue">Fetching https://example.com/page1...</span>
<span class="out-green">Cached to scraper_cache/a1b2c3d4.html</span>

<span class="out-blue">Waiting 3 seconds...</span>

<span class="out-blue">Fetching https://example.com/page2...</span>
<span class="out-green">Cached to scraper_cache/e5f6g7h8.html</span>

<span class="out-str">Next run will use cached versions!</span></div>
        </div>

        <h3>Error Handling and Retries</h3>

        <div class="code-tabs" data-runnable="errors">
          <div class="tab-buttons">
            <button class="tab-button active" data-lang="python">Python</button>
          </div>
          <div class="tab-content active" data-lang="python">
<pre><code><span class="code-comment"># Python: Robust error handling</span>
<span class="code-keyword">import</span> requests
<span class="code-keyword">import</span> time
<span class="code-keyword">from</span> requests.exceptions <span class="code-keyword">import</span> RequestException

<span class="code-keyword">def</span> <span class="code-function">fetch_with_retry</span>(url, max_retries=<span class="code-number">3</span>, base_delay=<span class="code-number">5</span>):
    <span class="code-string">"""Fetch URL with exponential backoff on failure."""</span>

    <span class="code-keyword">for</span> attempt <span class="code-keyword">in</span> <span class="code-function">range</span>(max_retries):
        <span class="code-keyword">try</span>:
            response = requests.get(url, timeout=<span class="code-number">30</span>)

            <span class="code-comment"># Success</span>
            <span class="code-keyword">if</span> response.status_code == <span class="code-number">200</span>:
                <span class="code-keyword">return</span> response.text

            <span class="code-comment"># Rate limited - wait and retry</span>
            <span class="code-keyword">elif</span> response.status_code == <span class="code-number">429</span>:
                <span class="code-tooltip" data-tip="Retry-After header tells you how long to wait">wait_time</span> = int(response.headers.get(<span class="code-string">'Retry-After'</span>, base_delay))
                <span class="code-keyword">print</span>(<span class="code-string">f"Rate limited. Waiting {wait_time}s..."</span>)
                time.sleep(wait_time)

            <span class="code-comment"># Server error - wait and retry</span>
            <span class="code-keyword">elif</span> response.status_code >= <span class="code-number">500</span>:
                <span class="code-tooltip" data-tip="Exponential backoff: 5s, 10s, 20s...">delay</span> = base_delay * (<span class="code-number">2</span> ** attempt)
                <span class="code-keyword">print</span>(<span class="code-string">f"Server error. Retry in {delay}s..."</span>)
                time.sleep(delay)

            <span class="code-comment"># Client error - don't retry</span>
            <span class="code-keyword">else</span>:
                <span class="code-keyword">raise</span> <span class="code-function">Exception</span>(<span class="code-string">f"HTTP {response.status_code}"</span>)

        <span class="code-keyword">except</span> RequestException <span class="code-keyword">as</span> e:
            <span class="code-keyword">print</span>(<span class="code-string">f"Request failed: {e}"</span>)
            <span class="code-keyword">if</span> attempt < max_retries - <span class="code-number">1</span>:
                delay = base_delay * (<span class="code-number">2</span> ** attempt)
                <span class="code-keyword">print</span>(<span class="code-string">f"Retrying in {delay}s..."</span>)
                time.sleep(delay)

    <span class="code-keyword">raise</span> <span class="code-function">Exception</span>(<span class="code-string">f"Failed after {max_retries} attempts"</span>)

<span class="code-comment"># Usage</span>
html = fetch_with_retry(<span class="code-string">"https://example.com/data"</span>)</code></pre>
            <button class="run-btn" data-lang="python">Run Code</button>
          </div>
        </div>

        <div class="output-simulation" data-output="errors" data-lang="python">
          <div class="output-header">
            <span>Python Output</span>
            <button class="close-output">&times;</button>
          </div>
          <div class="output-body"><span class="out-str">Fetching https://example.com/data...</span>
<span class="out-yellow">Server error (503). Retry in 5s...</span>
<span class="out-str">Attempt 2...</span>
<span class="out-yellow">Server error (503). Retry in 10s...</span>
<span class="out-str">Attempt 3...</span>
<span class="out-green">Success!</span></div>
        </div>

        <div class="info-box tip">
          <div class="info-box-title">Save Your Work Incrementally</div>
          <p style="margin-bottom: 0;">When scraping large amounts of data, save to disk after each page. If your script crashes after 2 hours, you don't want to lose everything. Use caching (shown above) or append to a CSV/database as you go.</p>
        </div>

        <div class="nav-footer">
          <a href="02b-apis.html" class="nav-link prev">Working with APIs (02b)</a>
          <a href="03-data-exploration.html" class="nav-link next">Module 3: Data Exploration</a>
        </div>
      </div>
    </main>
  </div>

  <div id="chatbot-widget" class="chatbot-widget">
    <button id="chatbot-toggle" class="chatbot-toggle" aria-label="Open course assistant">
      <svg width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
        <path d="M21 15a2 2 0 0 1-2 2H7l-4 4V5a2 2 0 0 1 2-2h14a2 2 0 0 1 2 2z"></path>
      </svg>
    </button>
    <div id="chatbot-panel" class="chatbot-panel">
      <div class="chatbot-header">
        <h3>ProTools ER1 Assistant</h3>
        <button id="chatbot-close" class="chatbot-close">&times;</button>
      </div>
      <div id="chatbot-messages" class="chatbot-messages">
        <div class="chat-message assistant">
          <p>Questions about web scraping? I can help with HTML parsing, legal considerations, or troubleshooting your scraper.</p>
        </div>
      </div>
      <div class="chatbot-input-area">
        <textarea id="chatbot-input" placeholder="Ask a question..." rows="2"></textarea>
        <button id="chatbot-send">Send</button>
      </div>
    </div>
  </div>

  <button class="mobile-menu-toggle" aria-label="Toggle navigation menu">Menu</button>
  <script src="../js/main.js"></script>
  <script src="../js/password-protection.js"></script>
  <script src="../js/chatbot.js"></script>

  <script>
  document.addEventListener('DOMContentLoaded', function() {
    document.querySelectorAll('.run-btn').forEach(btn => {
      btn.addEventListener('click', function() {
        const lang = this.dataset.lang;
        const codeBlock = this.closest('.code-tabs');
        const outputId = codeBlock.dataset.runnable;
        document.querySelectorAll(`.output-simulation[data-output="${outputId}"]`).forEach(out => {
          out.classList.remove('visible');
        });
        const output = document.querySelector(`.output-simulation[data-output="${outputId}"][data-lang="${lang}"]`);
        if (output) {
          output.classList.add('visible');
          output.scrollIntoView({ behavior: 'smooth', block: 'nearest' });
        }
      });
    });

    document.querySelectorAll('.close-output').forEach(btn => {
      btn.addEventListener('click', function() {
        this.closest('.output-simulation').classList.remove('visible');
      });
    });

    document.querySelectorAll('.code-tabs .tab-button').forEach(btn => {
      btn.addEventListener('click', function() {
        const codeBlock = this.closest('.code-tabs');
        const outputId = codeBlock.dataset.runnable;
        if (outputId) {
          document.querySelectorAll(`.output-simulation[data-output="${outputId}"]`).forEach(out => {
            out.classList.remove('visible');
          });
        }
      });
    });
  });
  </script>
</body>
</html>
