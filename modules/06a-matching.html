<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>6A Matching | ProTools ER1</title>
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Crimson+Pro:ital,wght@0,400;0,600;0,700;1,400&family=Fira+Code:wght@400;500&family=Source+Sans+Pro:ital,wght@0,400;0,600;0,700;1,400&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="../css/style.css">
  <style>
    .protected-content { -webkit-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; }
    .protected-content pre, .protected-content code, .protected-content .code-block, .protected-content .code-tabs { -webkit-user-select: text; -moz-user-select: text; -ms-user-select: text; user-select: text; }
    .code-tooltip { position: relative; cursor: help; border-bottom: 1px dotted #888; text-decoration: none; }
    .tooltip-popup { position: fixed; background: #1f2937; color: white; padding: 0.5rem 0.75rem; border-radius: 6px; font-size: 0.75rem; white-space: normal; max-width: 300px; opacity: 0; pointer-events: none; transition: opacity 0.15s ease-in-out; z-index: 10000; }
    .tooltip-popup.visible { opacity: 1; }
  </style>
</head>
<body>
    <div id="password-overlay" class="password-overlay">
    <div class="password-modal">
      <h2>ProTools ER1</h2>
      <p>Programming Tools for Empirical Research</p>

      <div class="course-description">
        <h3>Course Modules</h3>
        <ul class="module-list">
          <li><strong>Module 0:</strong> Languages & Platforms ‚Äî Python, Stata, R setup; IDEs (RStudio, VS Code, Jupyter)</li>
          <li><strong>Module 1:</strong> Getting Started ‚Äî Installation, basic syntax, packages</li>
          <li><strong>Module 2:</strong> Data Harnessing ‚Äî File import, APIs, web scraping</li>
          <li><strong>Module 3:</strong> Data Exploration ‚Äî Inspection, summary statistics, visualization</li>
          <li><strong>Module 4:</strong> Data Cleaning ‚Äî Data quality, transformation, validation</li>
          <li><strong>Module 5:</strong> Data Analysis ‚Äî Statistical analysis, simulation, experimental design</li>
          <li><strong>Module 6:</strong> Causal Inference ‚Äî Matching, DiD, RDD, IV, Synthetic Control</li>
          <li><strong>Module 7:</strong> Estimation Methods ‚Äî Standard errors, panel data, MLE/GMM</li>
          <li><strong>Module 8:</strong> Replicability ‚Äî Project organization, documentation, replication packages</li>
          <li><strong>Module 9:</strong> Git & GitHub ‚Äî Version control, collaboration, branching</li>
          <li><strong>Module 10:</strong> History of NLP ‚Äî From ELIZA to Transformers</li>
          <li><strong>Module 11:</strong> Machine Learning ‚Äî Prediction, regularization, neural networks</li>
          <li><strong>Module 12:</strong> Large Language Models ‚Äî How LLMs work, prompting, APIs</li>
        </ul>
      </div>

      <div class="access-note">
        This course is currently open to <strong>students at Sciences Po</strong>. If you are not a Sciences Po student but would like access, please <a href="mailto:giulia.caprini@sciencespo.fr">email me</a> to request an invite token.
      </div>

      <div class="password-form">
        <input type="password" id="password-input" placeholder="Enter password" autocomplete="off">
        <button id="password-submit">Access Course</button>
        <p id="password-error" style="color: #e53e3e; font-size: 0.85rem; margin-top: 1rem; display: none;">Incorrect password. Please try again.</p>
      </div>
    </div>
  </div>

  <div class="page-wrapper protected-content">
    <aside class="sidebar">
      <a href="../index.html" class="sidebar-logo">ProTools ER1</a>
      <span class="sidebar-subtitle">Programming Tools for Empirical Research</span>
      <nav>
        <ul>
          <li><a href="../index.html"><span class="welcome-icon">üè†</span> Welcome</a></li>
          <li class="has-subnav">
            <a href="00-languages-platforms.html"><span class="module-number">0</span> Languages & Platforms</a>
            <ul class="sub-nav">
              <li><a href="00a-rstudio-guide.html">RStudio Guide</a></li>
              <li><a href="00b-stata-guide.html">Stata Guide</a></li>
              <li><a href="00c-vscode-guide.html">VS Code Guide</a></li>
              <li><a href="00d-notebooks-guide.html">Notebooks Guide</a></li>
            </ul>
          </li>
          <li><a href="01-getting-started.html"><span class="module-number">1</span> Getting Started</a></li>
          <li class="has-subnav">
            <a href="02-data-harnessing.html"><span class="module-number">2</span> Data Harnessing</a>
            <ul class="sub-nav">
              <li><a href="02a-file-import.html">File Import</a></li>
              <li><a href="02b-apis.html">APIs</a></li>
              <li><a href="02c-web-scraping.html">Web Scraping</a></li>
            </ul>
          </li>
          <li><a href="03-data-exploration.html"><span class="module-number">3</span> Data Exploration</a></li>
          <li><a href="04-data-cleaning.html"><span class="module-number">4</span> Data Cleaning</a></li>
          <li class="has-subnav">
            <a href="05-data-analysis.html"><span class="module-number">5</span> Data Analysis</a>
            <ul class="sub-nav">
              <li><a href="05a-data-simulation.html">Data Simulation</a></li>
            </ul>
          </li>
          <li class="has-subnav active">
            <a href="06-causal-inference.html"><span class="module-number">6</span> Causal Inference</a>
            <ul class="sub-nav">
              <li class="active"><a href="06a-matching.html">Matching</a></li>
              <li><a href="06b-did.html">Difference-in-Differences</a></li>
              <li><a href="06c-rdd.html">Regression Discontinuity</a></li>
              <li><a href="06d-iv.html">Instrumental Variables</a></li>
              <li><a href="06e-synthetic-control.html">Synthetic Control</a></li>
              <li><a href="05b-experiments.html">Experiments</a></li>
            </ul>
          </li>
          <li><a href="07-estimation.html"><span class="module-number">7</span> Estimation Methods</a></li>
          <li><a href="08-replicability.html"><span class="module-number">8</span> Replicability</a></li>
          <li><a href="09-github.html"><span class="module-number">9</span> Git & GitHub</a></li>
          <li class="has-subnav">
            <a href="10-nlp-history.html"><span class="module-number">10</span> History of NLP</a>
            <ul class="sub-nav">
              <li><a href="10a-text-analysis-today.html">Text Analysis Today</a></li>
            </ul>
          </li>
          <li class="has-subnav">
            <a href="11-machine-learning.html"><span class="module-number">11</span> Machine Learning</a>
            <ul class="sub-nav">
              <li><a href="11a-regularization.html">Regularization</a></li>
              <li><a href="11b-trees.html">Tree-Based Methods</a></li>
              <li><a href="11c-neural-networks.html">Neural Networks</a></li>
              <li><a href="11d-causal-ml.html">Causal ML</a></li>
              <li><a href="11e-model-evaluation.html">Model Evaluation</a></li>
            </ul>
          </li>          <li><a href="12-llms.html"><span class="module-number">12</span> Large Language Models</a></li>
          <li><a href="../resources.html">Resources</a></li>
          <li><a href="contact.html">Contact & Feedback</a></li>
        </ul>
      </nav>
    </aside>

    <main class="main-content">
      <div class="content">
        <nav class="breadcrumb" style="margin-bottom: 1rem; font-size: 0.9rem; color: #666;">
          <a href="06-causal-inference.html">6 Causal Inference</a> &raquo; Matching
        </nav>

        <div class="module-header">
          <h1>6A &nbsp;Matching</h1>
          <div class="module-meta">
            <span>~2 hours</span>
            <span>PSM, CEM, Nearest Neighbor</span>
          </div>
        </div>

        <div class="toc">
          <h3>Table of Contents</h3>
          <ul>
            <li><a href="#theory">The Logic of Matching</a></li>
            <li><a href="#psm">Propensity Score Matching</a></li>
            <li><a href="#cem">Coarsened Exact Matching</a></li>
            <li><a href="#nn">Nearest Neighbor Matching</a></li>
            <li><a href="#diagnostics">Balance Diagnostics</a></li>
            <li><a href="#doubly-robust">Doubly Robust Estimation</a></li>
          </ul>
        </div>

        <!-- Theory Introduction Section -->
        <h2 id="theory">The Logic of Matching</h2>

        <div class="prereq-box" style="background: linear-gradient(135deg, #eff6ff 0%, #dbeafe 100%); border: 1px solid #3b82f6;">
          <h3 style="color: #1e40af;">The Fundamental Problem</h3>
          <p>
            We want to estimate the effect of a treatment D on outcome Y. The problem: treated and untreated units may differ systematically in ways that also affect Y. For example, people who participate in job training programs (treatment) may be more motivated‚Äîand motivation affects employment (outcome) regardless of training.
          </p>
          <p style="margin-bottom: 0;">
            <strong>Matching solution:</strong> Find untreated units that "look like" treated units on observable characteristics X. If we can find comparison units with identical X values, comparing outcomes gives us a causal effect‚Äî<em>provided there are no unmeasured confounders</em>.
          </p>
        </div>

        <!-- Visual Demo: The Intuition -->
        <div style="background: #f8fafc; border: 1px solid #e2e8f0; border-radius: 8px; padding: 1.5rem; margin: 1.5rem 0;">
          <h4 style="margin-top: 0; color: #1e40af;">Visual Intuition: How Matching Works</h4>
          <div style="display: flex; gap: 1rem; flex-wrap: wrap; align-items: center; justify-content: center; margin: 1rem 0;">
            <div style="flex: 1; min-width: 280px; text-align: center;">
              <div style="font-weight: 600; margin-bottom: 0.5rem;">Step 1: Raw Data</div>
              <svg viewBox="0 0 200 150" style="max-width: 200px; height: auto;">
                <!-- Treated units (filled circles) - higher income cluster -->
                <circle cx="140" cy="30" r="8" fill="#ef4444" stroke="#b91c1c" stroke-width="1"/>
                <circle cx="160" cy="45" r="8" fill="#ef4444" stroke="#b91c1c" stroke-width="1"/>
                <circle cx="150" cy="55" r="8" fill="#ef4444" stroke="#b91c1c" stroke-width="1"/>
                <circle cx="170" cy="35" r="8" fill="#ef4444" stroke="#b91c1c" stroke-width="1"/>
                <circle cx="130" cy="50" r="8" fill="#ef4444" stroke="#b91c1c" stroke-width="1"/>
                <!-- Control units (hollow circles) - lower income cluster -->
                <circle cx="40" cy="100" r="8" fill="#3b82f6" stroke="#1d4ed8" stroke-width="1"/>
                <circle cx="60" cy="110" r="8" fill="#3b82f6" stroke="#1d4ed8" stroke-width="1"/>
                <circle cx="50" cy="120" r="8" fill="#3b82f6" stroke="#1d4ed8" stroke-width="1"/>
                <circle cx="70" cy="95" r="8" fill="#3b82f6" stroke="#1d4ed8" stroke-width="1"/>
                <circle cx="80" cy="105" r="8" fill="#3b82f6" stroke="#1d4ed8" stroke-width="1"/>
                <!-- Overlap region - both types -->
                <circle cx="100" cy="75" r="8" fill="#ef4444" stroke="#b91c1c" stroke-width="1"/>
                <circle cx="90" cy="85" r="8" fill="#3b82f6" stroke="#1d4ed8" stroke-width="1"/>
                <!-- Axes -->
                <line x1="20" y1="140" x2="190" y2="140" stroke="#94a3b8" stroke-width="1"/>
                <line x1="20" y1="140" x2="20" y2="10" stroke="#94a3b8" stroke-width="1"/>
                <text x="105" y="148" font-size="10" fill="#64748b" text-anchor="middle">Income</text>
                <text x="12" y="75" font-size="10" fill="#64748b" transform="rotate(-90 12 75)">Age</text>
              </svg>
              <p style="font-size: 0.85rem; color: #64748b;">Treated (red) and control (blue) differ systematically</p>
            </div>
            <div style="flex: 0; font-size: 2rem; color: #94a3b8;">‚Üí</div>
            <div style="flex: 1; min-width: 280px; text-align: center;">
              <div style="font-weight: 600; margin-bottom: 0.5rem;">Step 2: After Matching</div>
              <svg viewBox="0 0 200 150" style="max-width: 200px; height: auto;">
                <!-- Matched pairs in overlap region -->
                <circle cx="100" cy="75" r="8" fill="#ef4444" stroke="#b91c1c" stroke-width="1"/>
                <circle cx="90" cy="85" r="8" fill="#3b82f6" stroke="#1d4ed8" stroke-width="1"/>
                <!-- Connecting line showing match -->
                <line x1="100" y1="75" x2="90" y2="85" stroke="#10b981" stroke-width="2" stroke-dasharray="4"/>
                <!-- Faded unmatched units -->
                <circle cx="140" cy="30" r="8" fill="#fca5a5" stroke="#fca5a5" stroke-width="1" opacity="0.3"/>
                <circle cx="160" cy="45" r="8" fill="#fca5a5" stroke="#fca5a5" stroke-width="1" opacity="0.3"/>
                <circle cx="40" cy="100" r="8" fill="#93c5fd" stroke="#93c5fd" stroke-width="1" opacity="0.3"/>
                <circle cx="60" cy="110" r="8" fill="#93c5fd" stroke="#93c5fd" stroke-width="1" opacity="0.3"/>
                <!-- Axes -->
                <line x1="20" y1="140" x2="190" y2="140" stroke="#94a3b8" stroke-width="1"/>
                <line x1="20" y1="140" x2="20" y2="10" stroke="#94a3b8" stroke-width="1"/>
                <text x="105" y="148" font-size="10" fill="#64748b" text-anchor="middle">Income</text>
                <text x="12" y="75" font-size="10" fill="#64748b" transform="rotate(-90 12 75)">Age</text>
              </svg>
              <p style="font-size: 0.85rem; color: #64748b;">Compare only similar units (matched pairs)</p>
            </div>
          </div>
        </div>

        <div class="info-box note">
          <div class="info-box-title">Further Reading: Theory & Intuition</div>
          <ul style="margin-bottom: 0;">
            <li><a href="https://www.jstatsoft.org/article/view/v042i08" target="_blank">Ho et al. (2007)</a> - "Matching as Nonparametric Preprocessing" explains why matching is preprocessing, not a method itself</li>
            <li><a href="https://mixtape.scunning.com/05-matching_and_subclassification" target="_blank">Causal Inference: The Mixtape, Ch. 5</a> - Excellent intuitive treatment of matching</li>
            <li><a href="https://www.tandfonline.com/doi/abs/10.1198/016214504000001042" target="_blank">Rosenbaum & Rubin (1983)</a> - Original propensity score paper</li>
          </ul>
        </div>

        <h2 id="psm">Propensity Score Matching</h2>

        <p>
          The propensity score is the probability of treatment given observed covariates: <em>e(X) = P(D=1|X)</em>. The key insight (<a href="https://doi.org/10.1093/biomet/70.1.41" target="_blank">Rosenbaum & Rubin, 1983</a>) is that conditioning on the propensity score balances all covariates, reducing many dimensions to one.
        </p>

        <div class="info-box tip">
          <div class="info-box-title">What to look for in the code</div>
          <p style="margin-bottom: 0;">
            The process has 4 steps: (1) Estimate propensity scores using logistic regression, (2) Match treated to control units with similar scores, (3) Verify balance improved on all covariates, (4) Estimate treatment effect on matched sample. Watch for overlap/common support‚Äîif propensity scores for treated and control don't overlap, matching is impossible.
          </p>
        </div>

        <div class="code-tabs" data-runnable="match-1">
          <div class="tab-buttons">
            <button class="tab-button active" data-lang="python">Python</button>
            <button class="tab-button" data-lang="stata">Stata</button>
            <button class="tab-button" data-lang="r">R</button>
          </div>
          <div class="tab-content active" data-lang="python">
<pre><code><span class="code-comment"># Python: Propensity Score Matching</span>
<span class="code-keyword">import</span> pandas <span class="code-keyword">as</span> pd
<span class="code-keyword">import</span> numpy <span class="code-keyword">as</span> np
<span class="code-keyword">from</span> sklearn.linear_model <span class="code-keyword">import</span> LogisticRegression
<span class="code-keyword">from</span> sklearn.neighbors <span class="code-keyword">import</span> NearestNeighbors

<span class="code-comment"># Step 1: Estimate propensity scores</span>
X = df[[<span class="code-string">'age'</span>, <span class="code-string">'income'</span>, <span class="code-string">'education'</span>]]
y = df[<span class="code-string">'treatment'</span>]

<span class="code-tooltip" data-tip="Logistic regression predicts probability of treatment given covariates">model = LogisticRegression(max_iter=1000)
model.fit(X, y)</span>
df[<span class="code-string">'pscore'</span>] = model.predict_proba(X)[:, 1]

<span class="code-comment"># Step 2: Match treated to nearest control</span>
treated = df[df[<span class="code-string">'treatment'</span>] == 1]
control = df[df[<span class="code-string">'treatment'</span>] == 0]

<span class="code-tooltip" data-tip="Find nearest neighbor in control group for each treated unit">nn = NearestNeighbors(n_neighbors=1, metric=<span class="code-string">'euclidean'</span>)
nn.fit(control[[<span class="code-string">'pscore'</span>]])</span>
distances, indices = nn.kneighbors(treated[[<span class="code-string">'pscore'</span>]])

<span class="code-comment"># Step 3: Create matched sample</span>
matched_control = control.iloc[indices.flatten()]
matched_df = pd.concat([treated.reset_index(drop=True),
                        matched_control.reset_index(drop=True)],
                       keys=[<span class="code-string">'treated'</span>, <span class="code-string">'control'</span>])

<span class="code-comment"># Step 4: Estimate ATT</span>
att = treated[<span class="code-string">'outcome'</span>].mean() - matched_control[<span class="code-string">'outcome'</span>].mean()
print(f<span class="code-string">"ATT: {att:.3f}"</span>)</code></pre>
            <button class="run-btn" data-lang="python">Run Code</button>
          </div>
          <div class="tab-content" data-lang="stata">
<pre><code><span class="code-comment">* Stata: Propensity Score Matching with teffects</span>

<span class="code-comment">* Method 1: teffects psmatch (built-in, recommended)</span>
<span class="code-tooltip" data-tip="teffects psmatch estimates ATT using propensity score matching. Syntax: outcome (treatment) (covariates)">teffects psmatch (outcome) (treatment age income education), ///
    atet nn(1)</span>

<span class="code-comment">* With caliper (maximum allowed distance)</span>
teffects psmatch (outcome) (treatment age income education), ///
    atet nn(1) caliper(0.1)

<span class="code-comment">* Method 2: psmatch2 (community-contributed, more options)</span>
<span class="code-comment">* ssc install psmatch2</span>
<span class="code-tooltip" data-tip="psmatch2 offers more flexibility: logit/probit models, various matching algorithms">psmatch2 treatment age income education, ///
    outcome(outcome) logit common</span>

<span class="code-comment">* Check balance after matching</span>
pstest age income education, treated(treatment)</code></pre>
            <button class="run-btn" data-lang="stata">Run Code</button>
          </div>
          <div class="tab-content" data-lang="r">
<pre><code><span class="code-comment"># R: Propensity Score Matching with MatchIt</span>
<span class="code-keyword">library</span>(MatchIt)
<span class="code-keyword">library</span>(cobalt)

<span class="code-comment"># Estimate propensity scores and match</span>
<span class="code-tooltip" data-tip="MatchIt performs matching in one step. method='nearest' does 1:1 nearest neighbor matching.">m.out <- matchit(treatment ~ age + income + education,
                 data = df,
                 method = "nearest",
                 distance = "glm",  <span class="code-comment"># logistic regression</span>
                 caliper = 0.1)</span>

<span class="code-comment"># Check match quality</span>
summary(m.out)

<span class="code-comment"># Extract matched data</span>
matched_df <- match.data(m.out)

<span class="code-comment"># Estimate ATT on matched sample</span>
<span class="code-tooltip" data-tip="On matched data, simple difference in means gives the ATT">att_model <- lm(outcome ~ treatment, data = matched_df,
                weights = weights)
summary(att_model)</span></code></pre>
            <button class="run-btn" data-lang="r">Run Code</button>
          </div>
        </div>

        <div class="output-simulation" data-output="match-1" data-lang="python">
          <div class="output-header"><span>Python Output</span><button class="close-output">&times;</button></div>
          <div class="output-body">Propensity Score Summary:
  Mean (Treated):   0.724
  Mean (Control):   0.312
  Overlap region:   [0.08, 0.95]

Matching Results:
  Treated units:         247
  Matched controls:      247
  Avg. match distance:   0.023

ATT: 0.342</div>
        </div>

        <div class="output-simulation" data-output="match-1" data-lang="stata">
          <div class="output-header"><span>Stata Output</span><button class="close-output">&times;</button></div>
          <div class="output-body">Treatment-effects estimation                   Number of obs     =        500
Estimator      : propensity-score matching     Matches: requested =          1
Outcome model  : matching                                     min =          1
Treatment model: logit                                        max =          3
------------------------------------------------------------------------------
             |              AI Robust
     outcome |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
ATET         |
   treatment |
   (1 vs 0)  |   .3421587   .0893214     3.83   0.000     .1670919    .5172255
------------------------------------------------------------------------------

psmatch2: Treatment assignment
psmatch2: Common support
             |    Off support     On support |     Total
-------------+--------------------------------+----------
  Untreated  |              0            253 |       253
    Treated  |              5            242 |       247
-------------+--------------------------------+----------
      Total  |              5            495 |       500</div>
        </div>

        <div class="output-simulation" data-output="match-1" data-lang="r">
          <div class="output-header"><span>R Output</span><button class="close-output">&times;</button></div>
          <div class="output-body">Call:
matchit(formula = treatment ~ age + income + education, data = df,
    method = "nearest", distance = "glm", caliper = 0.1)

Summary of Balance for All Data:
           Means Treated Means Control Std. Mean Diff.
age               42.31         38.76           0.312
income         52847.23      45231.89           0.428
education         14.2          12.8           0.387

Summary of Balance for Matched Data:
           Means Treated Means Control Std. Mean Diff.
age               41.89         41.67           0.019
income         51234.56      50987.32           0.014
education         13.9          13.8           0.028

Sample Sizes:
          Control Treated
All           253     247
Matched       238     238
Unmatched      15       9

Coefficients:
            Estimate Std. Error t value Pr(>|t|)
(Intercept)   4.2341     0.0672  63.012   <2e-16 ***
treatment     0.3389     0.0891   3.803  0.00016 ***</div>
        </div>

        <!-- Results Interpretation Box -->
        <div style="background: #f0fdf4; border: 1px solid #86efac; border-radius: 8px; padding: 1.25rem; margin: 1.5rem 0;">
          <h4 style="margin-top: 0; color: #166534;">Interpreting PSM Results</h4>
          <p>
            <strong>Example output:</strong> <code>ATT: 0.342 (SE: 0.089)</code>
          </p>
          <p>
            This means: among those who received treatment, the average effect was a 0.342 unit increase in the outcome compared to what they would have experienced without treatment. The ATT (Average Treatment effect on the Treated) is the relevant estimand when you're evaluating a voluntary program‚Äîwe want to know whether the program helped those who participated.
          </p>
          <p style="margin-bottom: 0;">
            <strong>Key checks:</strong> (1) How many treated units were matched? (2) What's the average distance between matched pairs? (3) Did covariate balance improve? If you lost many treated units to trimming, your estimate applies only to the "matchable" population, not all treated units.
          </p>
        </div>

        <h2 id="cem">Coarsened Exact Matching</h2>

        <p>
          CEM (<a href="https://doi.org/10.1093/pan/mpr025" target="_blank">Iacus et al., 2012</a>) temporarily coarsens covariates into bins, performs exact matching within bins, then uses the original (non-coarsened) data for analysis. This avoids propensity score model dependence and guarantees a maximum imbalance bound.
        </p>

        <div class="info-box tip">
          <div class="info-box-title">When to use CEM vs PSM</div>
          <p style="margin-bottom: 0;">
            Use CEM when you have a clear sense of what covariate values should be "close enough" (e.g., ages 30-35 are comparable). CEM discards more data but provides stronger balance guarantees. Use PSM when covariates are numerous or continuous without natural groupings.
          </p>
        </div>

        <div class="code-tabs" data-runnable="match-2">
          <div class="tab-buttons">
            <button class="tab-button active" data-lang="python">Python</button>
            <button class="tab-button" data-lang="stata">Stata</button>
            <button class="tab-button" data-lang="r">R</button>
          </div>
          <div class="tab-content active" data-lang="python">
<pre><code><span class="code-comment"># Python: Coarsened Exact Matching</span>
<span class="code-keyword">import</span> pandas <span class="code-keyword">as</span> pd
<span class="code-keyword">import</span> numpy <span class="code-keyword">as</span> np

<span class="code-comment"># Step 1: Coarsen variables into bins</span>
<span class="code-tooltip" data-tip="Create categorical bins for each continuous variable">df[<span class="code-string">'age_bin'</span>] = pd.cut(df[<span class="code-string">'age'</span>], bins=[18, 30, 45, 60, 100])
df[<span class="code-string">'income_bin'</span>] = pd.cut(df[<span class="code-string">'income'</span>], bins=5)
df[<span class="code-string">'edu_bin'</span>] = df[<span class="code-string">'education'</span>]  <span class="code-comment"># already categorical</span></span>

<span class="code-comment"># Step 2: Create strata</span>
df[<span class="code-string">'strata'</span>] = df.groupby([<span class="code-string">'age_bin'</span>, <span class="code-string">'income_bin'</span>, <span class="code-string">'edu_bin'</span>]).ngroup()

<span class="code-comment"># Step 3: Keep only matched strata (both treated and control)</span>
strata_counts = df.groupby([<span class="code-string">'strata'</span>, <span class="code-string">'treatment'</span>]).size().unstack(fill_value=0)
<span class="code-tooltip" data-tip="Keep strata that have at least one treated AND one control unit">matched_strata = strata_counts[(strata_counts[0] > 0) & (strata_counts[1] > 0)].index
df_matched = df[df[<span class="code-string">'strata'</span>].isin(matched_strata)]</span>

<span class="code-comment"># Step 4: Calculate CEM weights</span>
strata_weights = df_matched.groupby([<span class="code-string">'strata'</span>, <span class="code-string">'treatment'</span>]).size().unstack()
df_matched[<span class="code-string">'cem_weight'</span>] = df_matched.apply(
    <span class="code-keyword">lambda</span> row: 1 / strata_weights.loc[row[<span class="code-string">'strata'</span>], row[<span class="code-string">'treatment'</span>]], axis=1
)

print(f<span class="code-string">"Matched: {len(df_matched)} of {len(df)} observations"</span>)</code></pre>
            <button class="run-btn" data-lang="python">Run Code</button>
          </div>
          <div class="tab-content" data-lang="stata">
<pre><code><span class="code-comment">* Stata: Coarsened Exact Matching</span>
<span class="code-comment">* ssc install cem</span>

<span class="code-comment">* Basic CEM with automatic coarsening</span>
<span class="code-tooltip" data-tip="CEM automatically bins continuous variables. treatment(treatment) specifies treatment indicator.">cem age income education, treatment(treatment)</span>

<span class="code-comment">* Custom cutpoints for coarsening</span>
cem age (#5) income (#4) education, treatment(treatment)
<span class="code-comment">* #5 means 5 equal-sized bins</span>

<span class="code-comment">* Estimate treatment effect with CEM weights</span>
<span class="code-tooltip" data-tip="Use cem_weights from matching as regression weights">reg outcome treatment age income education [pw=cem_weights]</span>

<span class="code-comment">* Check match quality</span>
imb age income education, treatment(treatment)</code></pre>
            <button class="run-btn" data-lang="stata">Run Code</button>
          </div>
          <div class="tab-content" data-lang="r">
<pre><code><span class="code-comment"># R: Coarsened Exact Matching with MatchIt</span>
<span class="code-keyword">library</span>(MatchIt)

<span class="code-comment"># CEM matching</span>
<span class="code-tooltip" data-tip="method='cem' performs coarsened exact matching">m.cem <- matchit(treatment ~ age + income + education,
                 data = df,
                 method = "cem")</span>

<span class="code-comment"># With custom cutpoints</span>
m.cem <- matchit(treatment ~ age + income + education,
                 data = df,
                 method = "cem",
                 cutpoints = list(age = c(30, 45, 60),
                                  income = "q4"))  <span class="code-comment"># quartiles</span>

<span class="code-comment"># Extract matched data with weights</span>
matched_df <- match.data(m.cem)

<span class="code-comment"># Estimate ATT using weights</span>
att_model <- lm(outcome ~ treatment + age + income + education,
                data = matched_df,
                weights = weights)
summary(att_model)</code></pre>
            <button class="run-btn" data-lang="r">Run Code</button>
          </div>
        </div>

        <div class="output-simulation" data-output="match-2" data-lang="python">
          <div class="output-header"><span>Python Output</span><button class="close-output">&times;</button></div>
          <div class="output-body">CEM Coarsening Summary:
  age:       4 bins (18-30, 30-45, 45-60, 60-100)
  income:    5 equal-frequency bins
  education: kept as-is (categorical)

Strata Summary:
  Total strata:        48
  Matched strata:      31 (64.6%)
  Unmatched strata:    17

Matched: 412 of 500 observations
  Treated matched:   198 of 247 (80.2%)
  Control matched:   214 of 253 (84.6%)</div>
        </div>

        <div class="output-simulation" data-output="match-2" data-lang="stata">
          <div class="output-header"><span>Stata Output</span><button class="close-output">&times;</button></div>
          <div class="output-body">Coarsened exact matching
Matching Summary:
---------------------------------------------------------
             |  All     Matched    Unmatched
-------------+-------------------------------------------
    Treated  |  247        198           49
  Untreated  |  253        214           39
-------------+-------------------------------------------
      Total  |  500        412           88
---------------------------------------------------------

Multivariate L1 distance: .28451

Univariate imbalance:
                          L1       mean       min       25%       50%       75%       max
-------------+-------------------------------------------------------------------------
         age          .0423      .0124    -.0021     .0089     .0156     .0187     .0234
      income          .0387      .0098    -.0012     .0067     .0112     .0145     .0189
   education          .0156      .0045    -.0008     .0023     .0051     .0067     .0089</div>
        </div>

        <div class="output-simulation" data-output="match-2" data-lang="r">
          <div class="output-header"><span>R Output</span><button class="close-output">&times;</button></div>
          <div class="output-body">Call:
matchit(formula = treatment ~ age + income + education, data = df,
    method = "cem", cutpoints = list(age = c(30, 45, 60), income = "q4"))

Summary of Balance for Matched Data:
           Means Treated Means Control Std. Mean Diff.
age               40.23         40.18           0.004
income         48234.12      48012.89           0.012
education         13.45         13.42           0.008

Sample Sizes:
          Control Treated
All           253     247
Matched       214     198
Unmatched      39      49

Coefficients:
              Estimate Std. Error t value Pr(>|t|)
(Intercept)    3.8912     0.1234  31.534   <2e-16 ***
treatment      0.3156     0.0823   3.836  0.00014 ***
age            0.0123     0.0034   3.618  0.00032 ***
income         0.0000     0.0000   2.145  0.03245 *
education      0.0456     0.0189   2.413  0.01612 *</div>
        </div>

        <h2 id="nn">Nearest Neighbor Matching</h2>

        <p>
          Match on Mahalanobis distance (accounts for covariance) or Euclidean distance directly on covariates.
        </p>

        <div class="code-tabs" data-runnable="match-3">
          <div class="tab-buttons">
            <button class="tab-button active" data-lang="python">Python</button>
            <button class="tab-button" data-lang="stata">Stata</button>
            <button class="tab-button" data-lang="r">R</button>
          </div>
          <div class="tab-content active" data-lang="python">
<pre><code><span class="code-comment"># Python: Mahalanobis Distance Matching</span>
<span class="code-keyword">from</span> scipy.spatial.distance <span class="code-keyword">import</span> cdist
<span class="code-keyword">import</span> numpy <span class="code-keyword">as</span> np

covariates = [<span class="code-string">'age'</span>, <span class="code-string">'income'</span>, <span class="code-string">'education'</span>]
X_treated = df.loc[df[<span class="code-string">'treatment'</span>] == 1, covariates].values
X_control = df.loc[df[<span class="code-string">'treatment'</span>] == 0, covariates].values

<span class="code-comment"># Calculate Mahalanobis distance matrix</span>
<span class="code-tooltip" data-tip="Mahalanobis distance accounts for correlation between variables">cov_matrix = np.cov(df[covariates].values.T)
VI = np.linalg.inv(cov_matrix)
distances = cdist(X_treated, X_control, metric=<span class="code-string">'mahalanobis'</span>, VI=VI)</span>

<span class="code-comment"># Find nearest neighbor for each treated</span>
matches = np.argmin(distances, axis=1)

<span class="code-comment"># Extract matched control outcomes</span>
control_indices = df[df[<span class="code-string">'treatment'</span>] == 0].index
matched_outcomes = df.loc[control_indices[matches], <span class="code-string">'outcome'</span>].values

<span class="code-comment"># ATT</span>
att = df.loc[df[<span class="code-string">'treatment'</span>] == 1, <span class="code-string">'outcome'</span>].mean() - matched_outcomes.mean()</code></pre>
            <button class="run-btn" data-lang="python">Run Code</button>
          </div>
          <div class="tab-content" data-lang="stata">
<pre><code><span class="code-comment">* Stata: Mahalanobis Distance Matching</span>

<span class="code-comment">* Using teffects nnmatch</span>
<span class="code-tooltip" data-tip="metric(maha) uses Mahalanobis distance instead of propensity scores">teffects nnmatch (outcome age income education) (treatment), ///
    atet metric(maha) nn(1)</span>

<span class="code-comment">* With bias adjustment (Abadie-Imbens)</span>
teffects nnmatch (outcome age income education) (treatment), ///
    atet metric(maha) nn(3) biasadj(age income education)

<span class="code-comment">* Multiple matches with replacement</span>
teffects nnmatch (outcome age income education) (treatment), ///
    atet metric(maha) nn(5)</code></pre>
            <button class="run-btn" data-lang="stata">Run Code</button>
          </div>
          <div class="tab-content" data-lang="r">
<pre><code><span class="code-comment"># R: Mahalanobis Distance Matching</span>
<span class="code-keyword">library</span>(MatchIt)

<span class="code-comment"># Mahalanobis distance matching</span>
<span class="code-tooltip" data-tip="distance='mahalanobis' uses Mahalanobis metric instead of propensity scores">m.maha <- matchit(treatment ~ age + income + education,
                  data = df,
                  method = "nearest",
                  distance = "mahalanobis")</span>

<span class="code-comment"># Multiple matches (k:1)</span>
m.maha <- matchit(treatment ~ age + income + education,
                  data = df,
                  method = "nearest",
                  distance = "mahalanobis",
                  ratio = 3)  <span class="code-comment"># 3 controls per treated</span>

<span class="code-comment"># With caliper on propensity score</span>
m.maha <- matchit(treatment ~ age + income + education,
                  data = df,
                  method = "nearest",
                  distance = "mahalanobis",
                  mahvars = ~ age + income + education,
                  caliper = 0.25,
                  std.caliper = TRUE)</code></pre>
            <button class="run-btn" data-lang="r">Run Code</button>
          </div>
        </div>

        <div class="output-simulation" data-output="match-3" data-lang="python">
          <div class="output-header"><span>Python Output</span><button class="close-output">&times;</button></div>
          <div class="output-body">Covariance Matrix:
              age       income    education
age        156.234    2341.56      12.45
income    2341.56   89234567.12   1234.56
education   12.45     1234.56       4.89

Mahalanobis Distance Summary:
  Min distance:      0.087
  Mean distance:     0.456
  Max distance:      2.341
  Median distance:   0.389

Matching Results:
  Treated units:     247
  Matched controls:  247 (with replacement: 189 unique)

ATT (Mahalanobis): 0.328</div>
        </div>

        <div class="output-simulation" data-output="match-3" data-lang="stata">
          <div class="output-header"><span>Stata Output</span><button class="close-output">&times;</button></div>
          <div class="output-body">Treatment-effects estimation                    Number of obs     =        500
Estimator      : nearest-neighbor matching      Matches: requested =          1
Outcome model  : matching                                      min =          1
Distance metric: Mahalanobis                                   max =          4
------------------------------------------------------------------------------
             |              AI Robust
     outcome |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
ATET         |
   treatment |
   (1 vs 0)  |   .3276453   .0912345     3.59   0.000     .1488289    .5064617
------------------------------------------------------------------------------

Matching with bias adjustment (nn=3):
------------------------------------------------------------------------------
             |              AI Robust
     outcome |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
ATET         |
   treatment |
   (1 vs 0)  |   .3312187   .0823456     4.02   0.000     .1698241    .4926133
------------------------------------------------------------------------------</div>
        </div>

        <div class="output-simulation" data-output="match-3" data-lang="r">
          <div class="output-header"><span>R Output</span><button class="close-output">&times;</button></div>
          <div class="output-body">Call:
matchit(formula = treatment ~ age + income + education, data = df,
    method = "nearest", distance = "mahalanobis", ratio = 3)

Summary of Balance for All Data:
           Means Treated Means Control Std. Mean Diff.
age               42.31         38.76           0.312
income         52847.23      45231.89           0.428
education         14.2          12.8           0.387

Summary of Balance for Matched Data:
           Means Treated Means Control Std. Mean Diff.
age               42.31         42.08           0.020
income         52847.23      52134.56           0.040
education         14.2          14.1           0.028

Sample Sizes:
              Control Treated
All               253     247
Matched (Ratio)   741     247
Unmatched           0       0

Effective Sample Sizes:
          Control Treated
All        253.00   247
Matched    698.23   247</div>
        </div>

        <h2 id="diagnostics">Balance Diagnostics</h2>

        <p>
          Always check that matching improved covariate balance. Report standardized mean differences (SMD) and variance ratios.
        </p>

        <div class="code-tabs" data-runnable="match-4">
          <div class="tab-buttons">
            <button class="tab-button active" data-lang="python">Python</button>
            <button class="tab-button" data-lang="stata">Stata</button>
            <button class="tab-button" data-lang="r">R</button>
          </div>
          <div class="tab-content active" data-lang="python">
<pre><code><span class="code-comment"># Python: Balance Diagnostics</span>
<span class="code-keyword">import</span> matplotlib.pyplot <span class="code-keyword">as</span> plt

<span class="code-keyword">def</span> <span class="code-function">calc_smd</span>(df, var, treatment_col):
    <span class="code-string">"""Calculate standardized mean difference."""</span>
    treated = df[df[treatment_col] == 1][var]
    control = df[df[treatment_col] == 0][var]
    pooled_std = np.sqrt((treated.var() + control.var()) / 2)
    <span class="code-keyword">return</span> (treated.mean() - control.mean()) / pooled_std

<span class="code-comment"># Before and after matching</span>
covariates = [<span class="code-string">'age'</span>, <span class="code-string">'income'</span>, <span class="code-string">'education'</span>]
smd_before = [calc_smd(df, v, <span class="code-string">'treatment'</span>) <span class="code-keyword">for</span> v <span class="code-keyword">in</span> covariates]
smd_after = [calc_smd(matched_df, v, <span class="code-string">'treatment'</span>) <span class="code-keyword">for</span> v <span class="code-keyword">in</span> covariates]

<span class="code-comment"># Love plot</span>
<span class="code-tooltip" data-tip="Love plots visualize balance improvement. SMD < 0.1 is generally acceptable.">fig, ax = plt.subplots(figsize=(8, 5))
y_pos = np.arange(len(covariates))
ax.scatter(smd_before, y_pos, marker=<span class="code-string">'o'</span>, label=<span class="code-string">'Before'</span>, s=100)
ax.scatter(smd_after, y_pos, marker=<span class="code-string">'s'</span>, label=<span class="code-string">'After'</span>, s=100)
ax.axvline(x=0.1, color=<span class="code-string">'r'</span>, linestyle=<span class="code-string">'--'</span>, alpha=0.5)
ax.axvline(x=-0.1, color=<span class="code-string">'r'</span>, linestyle=<span class="code-string">'--'</span>, alpha=0.5)
ax.set_yticks(y_pos)
ax.set_yticklabels(covariates)
ax.set_xlabel(<span class="code-string">'Standardized Mean Difference'</span>)
ax.legend()
plt.tight_layout()
plt.show()</span></code></pre>
            <button class="run-btn" data-lang="python">Run Code</button>
          </div>
          <div class="tab-content" data-lang="stata">
<pre><code><span class="code-comment">* Stata: Balance Diagnostics</span>

<span class="code-comment">* After psmatch2</span>
pstest age income education, treated(treatment) both graph

<span class="code-comment">* Standardized differences table</span>
<span class="code-tooltip" data-tip="tebalance summarize shows SMD and variance ratios for each covariate">tebalance summarize</span>

<span class="code-comment">* Density plots of propensity scores</span>
tebalance density

<span class="code-comment">* Overidentification test for balance</span>
tebalance overid</code></pre>
            <button class="run-btn" data-lang="stata">Run Code</button>
          </div>
          <div class="tab-content" data-lang="r">
<pre><code><span class="code-comment"># R: Balance Diagnostics with cobalt</span>
<span class="code-keyword">library</span>(cobalt)

<span class="code-comment"># Balance table</span>
<span class="code-tooltip" data-tip="bal.tab shows SMD, variance ratios, and other balance statistics">bal.tab(m.out, un = TRUE, thresholds = c(m = 0.1))</span>

<span class="code-comment"># Love plot (visual balance check)</span>
<span class="code-tooltip" data-tip="Love plots show SMD before/after matching. Points inside threshold lines indicate good balance.">love.plot(m.out,
          binary = "std",
          thresholds = c(m = 0.1),
          var.order = "unadjusted")</span>

<span class="code-comment"># Density plots</span>
bal.plot(m.out, var.name = "age", which = "both")

<span class="code-comment"># Full balance summary</span>
summary(m.out)</code></pre>
            <button class="run-btn" data-lang="r">Run Code</button>
          </div>
        </div>

        <div class="output-simulation" data-output="match-4" data-lang="python">
          <div class="output-header"><span>Python Output</span><button class="close-output">&times;</button></div>
          <div class="output-body">Balance Diagnostics
==================

Standardized Mean Differences:
                Before    After    Threshold
Variable        Matching  Matching   (0.1)
-----------     --------  --------  ---------
age               0.312     0.019      PASS
income            0.428     0.014      PASS
education         0.387     0.028      PASS

Variance Ratios:
                Before    After    Acceptable
Variable        Matching  Matching  (0.5-2.0)
-----------     --------  --------  ---------
age               1.342     1.023      PASS
income            1.567     1.089      PASS
education         1.234     0.987      PASS

[Love Plot displayed showing improvement in balance]</div>
        </div>

        <div class="output-simulation" data-output="match-4" data-lang="stata">
          <div class="output-header"><span>Stata Output</span><button class="close-output">&times;</button></div>
          <div class="output-body">. tebalance summarize

Covariate balance summary
                                              Raw      Matched
------------------------------------------------------------------
Number of obs =                               500          476
Treated obs =                                 247          238
Control obs =                                 253          238
------------------------------------------------------------------

                          Standardized differences            Variance ratio
                          --------------------------    --------------------------
                             Raw       Matched            Raw       Matched
                          ----------  ----------       ----------  ----------
age                          0.312       0.019           1.342       1.023
income                       0.428       0.014           1.567       1.089
education                    0.387       0.028           1.234       0.987

. tebalance overid

Overidentification test for covariate balance
    chi2(3) =    2.14
    Prob > chi2 = 0.5436

Balance is adequate (fail to reject null of balance)</div>
        </div>

        <div class="output-simulation" data-output="match-4" data-lang="r">
          <div class="output-header"><span>R Output</span><button class="close-output">&times;</button></div>
          <div class="output-body">Call:
bal.tab(m.out, un = TRUE, thresholds = c(m = 0.1))

Balance Measures
                Type Diff.Un Diff.Adj  M.Threshold
age          Contin.   0.312    0.019      Balanced
income       Contin.   0.428    0.014      Balanced
education    Contin.   0.387    0.028      Balanced

Balance tally for mean differences
                   count
Balanced, <0.1         3
Not Balanced, >0.1     0

Variable with most imbalance
 Variable Diff.Adj        M.Threshold
 education   0.028          Balanced

Sample sizes
          Control Treated
All           253     247
Matched       238     238
Unmatched      15       9

[Love plot displayed with all variables within 0.1 threshold]</div>
        </div>

        <!-- Balance Results Interpretation -->
        <div style="background: #f0fdf4; border: 1px solid #86efac; border-radius: 8px; padding: 1.25rem; margin: 1.5rem 0;">
          <h4 style="margin-top: 0; color: #166534;">Interpreting Balance Diagnostics</h4>
          <p>
            <strong>Standardized Mean Difference (SMD):</strong> The difference in means between treated and control, divided by the pooled standard deviation. Rule of thumb: SMD &lt; 0.1 indicates good balance; SMD &lt; 0.25 is acceptable.
          </p>
          <p>
            <strong>Variance Ratio:</strong> Ratio of variances between groups. Should be close to 1.0 (range 0.5-2.0 is acceptable).
          </p>
          <p style="margin-bottom: 0;">
            <strong>What to report:</strong> Always show a balance table or Love plot comparing before/after matching. If balance is poor on key covariates, your matching has failed and you need to: (1) try different matching specifications, (2) include additional covariates, or (3) acknowledge the limitation.
          </p>
        </div>

        <h2 id="doubly-robust">Doubly Robust Estimation</h2>

        <p>
          Doubly robust methods (<a href="https://doi.org/10.1080/01621459.1994.10476818" target="_blank">Robins et al., 1994</a>) combine propensity score weighting with outcome regression. The estimator is consistent if <em>either</em> the propensity score model OR the outcome model is correctly specified‚Äîyou get "two chances" to get it right.
        </p>

        <div class="info-box tip">
          <div class="info-box-title">Why doubly robust?</div>
          <p style="margin-bottom: 0;">
            Standard matching relies entirely on the propensity score model. If it's misspecified, your estimate is biased. Doubly robust methods add an outcome model as insurance. With modern machine learning (SuperLearner, random forests), you can flexibly estimate both models without imposing restrictive functional forms.
          </p>
        </div>

        <div class="code-tabs" data-runnable="match-5">
          <div class="tab-buttons">
            <button class="tab-button active" data-lang="python">Python</button>
            <button class="tab-button" data-lang="stata">Stata</button>
            <button class="tab-button" data-lang="r">R</button>
          </div>
          <div class="tab-content active" data-lang="python">
<pre><code><span class="code-comment"># Python: Doubly Robust Estimation (AIPW)</span>
<span class="code-keyword">from</span> sklearn.linear_model <span class="code-keyword">import</span> LogisticRegression, LinearRegression
<span class="code-keyword">import</span> numpy <span class="code-keyword">as</span> np

covariates = [<span class="code-string">'age'</span>, <span class="code-string">'income'</span>, <span class="code-string">'education'</span>]
X = df[covariates].values
D = df[<span class="code-string">'treatment'</span>].values
Y = df[<span class="code-string">'outcome'</span>].values

<span class="code-comment"># Step 1: Estimate propensity scores</span>
ps_model = LogisticRegression(max_iter=1000)
ps_model.fit(X, D)
pscore = ps_model.predict_proba(X)[:, 1]

<span class="code-comment"># Step 2: Estimate outcome models</span>
<span class="code-tooltip" data-tip="Fit separate outcome models for treated and control groups">mu1_model = LinearRegression()
mu0_model = LinearRegression()
mu1_model.fit(X[D == 1], Y[D == 1])
mu0_model.fit(X[D == 0], Y[D == 0])</span>

mu1 = mu1_model.predict(X)  <span class="code-comment"># E[Y(1)|X]</span>
mu0 = mu0_model.predict(X)  <span class="code-comment"># E[Y(0)|X]</span>

<span class="code-comment"># Step 3: AIPW estimator</span>
<span class="code-tooltip" data-tip="AIPW combines IPW and regression: consistent if either model is correct">aipw_1 = mu1 + D * (Y - mu1) / pscore
aipw_0 = mu0 + (1 - D) * (Y - mu0) / (1 - pscore)
ate_aipw = np.mean(aipw_1 - aipw_0)</span>

print(f<span class="code-string">"ATE (AIPW): {ate_aipw:.3f}"</span>)</code></pre>
            <button class="run-btn" data-lang="python">Run Code</button>
          </div>
          <div class="tab-content" data-lang="stata">
<pre><code><span class="code-comment">* Stata: Doubly Robust with teffects</span>

<span class="code-comment">* AIPW (Augmented IPW)</span>
<span class="code-tooltip" data-tip="teffects aipw is doubly robust: combines outcome model with propensity weighting">teffects aipw (outcome age income education) ///
    (treatment age income education), atet</span>

<span class="code-comment">* IPWRA (IPW + Regression Adjustment)</span>
teffects ipwra (outcome age income education) ///
    (treatment age income education), atet

<span class="code-comment">* With different link functions</span>
teffects aipw (outcome age income education, poisson) ///
    (treatment age income education, probit), atet</code></pre>
            <button class="run-btn" data-lang="stata">Run Code</button>
          </div>
          <div class="tab-content" data-lang="r">
<pre><code><span class="code-comment"># R: Doubly Robust with AIPW package</span>
<span class="code-keyword">library</span>(AIPW)

<span class="code-comment"># Basic AIPW</span>
<span class="code-tooltip" data-tip="AIPW package implements augmented inverse probability weighting">aipw_obj <- AIPW$new(
  Y = df$outcome,
  A = df$treatment,
  W = df[, c("age", "income", "education")],
  Q.SL.library = "SL.glm",   <span class="code-comment"># outcome model</span>
  g.SL.library = "SL.glm"    <span class="code-comment"># propensity model</span>
)</span>

<span class="code-comment"># Fit and summarize</span>
aipw_obj$fit()
aipw_obj$summary()

<span class="code-comment"># With SuperLearner (ML ensemble)</span>
<span class="code-keyword">library</span>(SuperLearner)
aipw_ml <- AIPW$new(
  Y = df$outcome,
  A = df$treatment,
  W = df[, c("age", "income", "education")],
  Q.SL.library = c("SL.glm", "SL.ranger", "SL.xgboost"),
  g.SL.library = c("SL.glm", "SL.ranger")
)
aipw_ml$fit()
aipw_ml$summary()</code></pre>
            <button class="run-btn" data-lang="r">Run Code</button>
          </div>
        </div>

        <div class="output-simulation" data-output="match-5" data-lang="python">
          <div class="output-header"><span>Python Output</span><button class="close-output">&times;</button></div>
          <div class="output-body">Propensity Score Model:
  Logistic Regression, AUC: 0.78

Outcome Model (Treated):
  R-squared: 0.342
  Coefficients: age=0.012, income=0.00001, education=0.089

Outcome Model (Control):
  R-squared: 0.318
  Coefficients: age=0.010, income=0.00001, education=0.078

AIPW Estimates:
  E[Y(1)]: 4.587 (SE: 0.067)
  E[Y(0)]: 4.243 (SE: 0.058)

ATE (AIPW): 0.344
  Standard Error: 0.089
  95% CI: [0.170, 0.518]
  p-value: 0.0001</div>
        </div>

        <div class="output-simulation" data-output="match-5" data-lang="stata">
          <div class="output-header"><span>Stata Output</span><button class="close-output">&times;</button></div>
          <div class="output-body">Treatment-effects estimation                   Number of obs      =       500
Estimator      : augmented IPW
Outcome model  : linear
Treatment model: logit
------------------------------------------------------------------------------
             |               Robust
     outcome |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
ATET         |
   treatment |
   (1 vs 0)  |   .3445672   .0879234     3.92   0.000     .1722404    .5168940
-------------+----------------------------------------------------------------
POmean       |
   treatment |
          0  |   4.243128   .0581234    73.01   0.000     4.129209    4.357047
------------------------------------------------------------------------------

Note: Potential outcome means are computed at covariate means in the
      estimation sample.

teffects ipwra:
------------------------------------------------------------------------------
             |               Robust
     outcome |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
ATET         |
   treatment |
   (1 vs 0)  |   .3412345   .0867123     3.94   0.000     .1712822    .5111868
------------------------------------------------------------------------------</div>
        </div>

        <div class="output-simulation" data-output="match-5" data-lang="r">
          <div class="output-header"><span>R Output</span><button class="close-output">&times;</button></div>
          <div class="output-body">                  Estimate Std.Error 95%LCL 95%UCL
Risk of Y(1)        4.5867    0.0672 4.4550 4.7184
Risk of Y(0)        4.2431    0.0584 4.1286 4.3576
Risk Difference     0.3436    0.0889 0.1694 0.5178
Risk Ratio          1.0810    0.0214 1.0390 1.1246

ATE: 0.3436 (SE: 0.0889)
95% Confidence Interval: [0.169, 0.518]

With SuperLearner ensemble:
                  Estimate Std.Error 95%LCL 95%UCL
Risk Difference     0.3389    0.0856 0.1711 0.5067

Cross-validated risks:
  Outcome model: SL.ranger selected (CV-risk: 0.234)
  Propensity model: SL.glm selected (CV-risk: 0.312)</div>
        </div>

        <div class="info-box warning">
          <div class="info-box-title">Key Assumption: Selection on Observables</div>
          <p style="margin-bottom: 0;">
            All matching methods assume no unmeasured confounders‚Äîthat once you condition on observed covariates, treatment assignment is as good as random. This is untestable. Use sensitivity analysis (e.g., Rosenbaum bounds) to assess robustness to hidden bias.
          </p>
        </div>

        <div class="citation">
          <div class="citation-title">References</div>
          <ul>
            <li><strong>Iacus, S., King, G., & Porro, G.</strong> (2012). "Causal Inference without Balance Checking: Coarsened Exact Matching." <em>Political Analysis</em>.</li>
            <li><strong>Ho, D., Imai, K., King, G., & Stuart, E.</strong> (2007). "Matching as Nonparametric Preprocessing." <em>Political Analysis</em>.</li>
            <li><strong>Abadie, A. & Imbens, G.</strong> (2006). "Large Sample Properties of Matching Estimators." <em>Econometrica</em>.</li>
          </ul>
        </div>

        <div class="nav-footer">
          <a href="06-causal-inference.html" class="nav-link prev">6: Causal Inference Overview</a>
          <a href="06b-did.html" class="nav-link next">6B: Difference-in-Differences</a>
        </div>
      </div>
    </main>
  </div>

  <button class="mobile-menu-toggle" aria-label="Toggle navigation menu">Menu</button>
  <script src="../js/main.js"></script>
  <script src="../js/password-protection.js"></script>
</body>
</html>
